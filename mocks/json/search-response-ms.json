{
  "results": [
    {
      "hits": [
        {
          "url": "https://til.swfz.io//entries/msw_mock_svg/",
          "text": "\n本ブログでPixelaのグラフを表示させるようにした\n\n表示するだけなら下記にあるようにiframeで呼び出すだけでOK\n\n[草グラフを iframe タグで簡単に埋め込む（Pixela v1.12.1） - えいのうにっき](https://blog.a-know.me/entry/2019/06/16/210915)\n\nが、Gatsbyなどで開発しているときなどは特にリクエストを外部に送る必要がないためURLを出し分けするなりモックするなどできたら良いなと思っていた\n\nこれができていればuseEffectでミスって無限ループしてしまったときなども特に心配せずに開発できる\n\nmswを使えば外部リクエストをモックできるので行けそう?だったがiframeの中身のコンテンツのモックはできないようなのでSVGを表示する方法にする\n\nということでmswを使ってSVGをモックするようにしてみた\n\n## install\n\n[Install - Getting Started - Mock Service Worker Docs](https://mswjs.io/docs/getting-started/install)\n\n基本的にはドキュメントを見て進めるでOKそう\n\n```shell\nyarn add --dev msw\nmkdir src/mocks\ntouch src/mocks/handlers.ts\n```\n\npublicディレクトリに作成する\n\ngatsbyなので`static/`\n\n```\nnpx msw init static/ --save\n```\n\nすると`static/mockServiceWorker.js`というファイルが生成される\n\n\n## svgファイルをモックする\n\n必要な修正をする\n\n- gatsby-browser.js\n\n```javascript\nconst startWorker = async () => {\n  const { worker } = require(\"./src/mocks/browser\")\n  await worker.start({\n    ServiceWorker: {\n      url: \"/pixela-mock\",\n    },\n  })\n}\n\nexport const onClientEntry = () => {\n  if (process.env.NODE_ENV === \"development\") {\n    startWorker()\n  }\n}\n```\n\nGatsbyのレンダリング初期にモック処理ができるか調べてみた\n\n[Gatsbyドキュメント Doc -> Recipes ざっくりまとめ - 奇をてらったテクノロジー](https://kiotera-tech.com/gatsby_doc_recipes_summary)\n\n[https://kiotera-tech.com/gatsby_doc_recipes_summary:embed:cite]\n\nGatsbyのライフサイクル`onClientEntry`を使うことで可能っぽい\n\n`onClientEntry`の処理時に`startWorker`を動かすようにした\n\nこのライフサイクルを考慮せず`startWorker`を書いてしまうとタイミングによってはモックされたりされなかったり…という現象に見舞われた\n\n- src/mocks/browser.js\n\n```javascript\n// src/mocks/browser.js\nimport { setupWorker } from 'msw'\nimport { handlers } from './handler'\n// This configures a Service Worker with the given request handlers.\nexport const worker = setupWorker(...handlers)\n```\n\n- src/mocks/handler.ts\n\n```typescript\nimport { rest } from 'msw'\nimport svgImage from './pixela.svg'\n\nexport const handlers = [\n  rest.get('https://pixe.la/v1/users/swfz/graphs/til-pageviews', async (req, res, ctx) => {\n    const svgBuffer = await fetch(svgImage).then((res) => res.arrayBuffer())\n\n    return res(ctx.status(200), ctx.body(svgBuffer))\n  }),\n  rest.post('https://undefined-1.algolianet.com/1/indexes/*/queries', (req, res, ctx) => {\n    return res(ctx.status(200), ctx.json({results: {hits: []}}))\n  })\n]\n```\n\nsvgファイルは一度curlなり何なりでローカルに持ってきて保存しておく→`./pixela.svg`\n\nおまけでalgoliaへのリクエストも開発時はほとんど使わないので定義した\n\n## SVGのモック処理\n\nsvgをモックするのどうすれば良いのかと思ったが\n\n画像と同じような感じでOKだったので`arrayBuffer`を使う\n\n[Possible to mock an img src url? · Issue #461 · mswjs/msw](https://github.com/mswjs/msw/issues/461)\n\nモックできているかどうかの確認はモック用のSVGはPixelaの色を変えてからローカルに保存したのでdev用は赤、本番は青といった感じで別れている\n\n## まとめ\n\nmswを使って開発時はpixelaへのSVGリクエストをモックして開発時はアクセスが行かないようにした\n\nリクエスト先のURLを出し分けせずにモックできるのは非常に体験が良い\n\n外部のサービスやツールを使っていてsandbox用とかで分けられていない場合などいろんな用途に使えそう\n\n他にも用途いろいろありそうなので使っていこうと思った",
          "date": "2021-12-29",
          "title": "mswでSVGをモックする",
          "tags": ["JavaScript", "TypeScript", "Gatsby", "msw"],
          "description": "Pixelaを題材としてモックしてみた",
          "slug": "/entries/msw_mock_svg/",
          "timeToRead": 3,
          "objectID": "75a9abd2-0b34-54b0-b919-36e1513da0ed",
          "_snippetResult": {
            "text": {
              "value": "ような感じでOKだったので`arrayBuffer`を使う\n\n[Possible to mock an img src url? · Issue #461 · <em>ms</em>wjs/<em>ms</em>w](https://github.com/<em>ms</em>wjs/<em>ms</em>w/issues/461)\n\nモックできているかどうかの確認は",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/<em>ms</em>w_mock_svg/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "text": {
              "value": "\n本ブログでPixelaのグラフを表示させるようにした\n\n表示するだけなら下記にあるようにiframeで呼び出すだけでOK\n\n[草グラフを iframe タグで簡単に埋め込む（Pixela v1.12.1） - えいのうにっき](https://blog.a-know.me/entry/2019/06/16/210915)\n\nが、Gatsbyなどで開発しているときなどは特にリクエストを外部に送る必要がないためURLを出し分けするなりモックするなどできたら良いなと思っていた\n\nこれができていればuseEffectでミスって無限ループしてしまったときなども特に心配せずに開発できる\n\n<em>ms</em>wを使えば外部リクエストをモックできるので行けそう?だったがiframeの中身のコンテンツのモックはできないようなのでSVGを表示する方法にする\n\nということで<em>ms</em>wを使ってSVGをモックするようにしてみた\n\n## install\n\n[Install - Getting Started - Mock Service Worker Docs](https://<em>ms</em>wjs.io/docs/getting-started/install)\n\n基本的にはドキュメントを見て進めるでOKそう\n\n```shell\nyarn add --dev <em>ms</em>w\nmkdir src/mocks\ntouch src/mocks/handlers.ts\n```\n\npublicディレクトリに作成する\n\ngatsbyなので`static/`\n\n```\nnpx <em>ms</em>w init static/ --save\n```\n\nすると`static/mockServiceWorker.js`というファイルが生成される\n\n\n## svgファイルをモックする\n\n必要な修正をする\n\n- gatsby-browser.js\n\n```javascript\nconst startWorker = async () => {\n  const { worker } = require(\"./src/mocks/browser\")\n  await worker.start({\n    ServiceWorker: {\n      url: \"/pixela-mock\",\n    },\n  })\n}\n\nexport const onClientEntry = () => {\n  if (process.env.NODE_ENV === \"development\") {\n    startWorker()\n  }\n}\n```\n\nGatsbyのレンダリング初期にモック処理ができるか調べてみた\n\n[Gatsbyドキュメント Doc -> Recipes ざっくりまとめ - 奇をてらったテクノロジー](https://kiotera-tech.com/gatsby_doc_recipes_summary)\n\n[https://kiotera-tech.com/gatsby_doc_recipes_summary:embed:cite]\n\nGatsbyのライフサイクル`onClientEntry`を使うことで可能っぽい\n\n`onClientEntry`の処理時に`startWorker`を動かすようにした\n\nこのライフサイクルを考慮せず`startWorker`を書いてしまうとタイミングによってはモックされたりされなかったり…という現象に見舞われた\n\n- src/mocks/browser.js\n\n```javascript\n// src/mocks/browser.js\nimport { setupWorker } from '<em>ms</em>w'\nimport { handlers } from './handler'\n// This configures a Service Worker with the given request handlers.\nexport const worker = setupWorker(...handlers)\n```\n\n- src/mocks/handler.ts\n\n```typescript\nimport { rest } from '<em>ms</em>w'\nimport svgImage from './pixela.svg'\n\nexport const handlers = [\n  rest.get('https://pixe.la/v1/users/swfz/graphs/til-pageviews', async (req, res, ctx) => {\n    const svgBuffer = await fetch(svgImage).then((res) => res.arrayBuffer())\n\n    return res(ctx.status(200), ctx.body(svgBuffer))\n  }),\n  rest.post('https://undefined-1.algolianet.com/1/indexes/*/queries', (req, res, ctx) => {\n    return res(ctx.status(200), ctx.json({results: {hits: []}}))\n  })\n]\n```\n\nsvgファイルは一度curlなり何なりでローカルに持ってきて保存しておく→`./pixela.svg`\n\nおまけでalgoliaへのリクエストも開発時はほとんど使わないので定義した\n\n## SVGのモック処理\n\nsvgをモックするのどうすれば良いのかと思ったが\n\n画像と同じような感じでOKだったので`arrayBuffer`を使う\n\n[Possible to mock an img src url? · Issue #461 · <em>ms</em>wjs/<em>ms</em>w](https://github.com/<em>ms</em>wjs/<em>ms</em>w/issues/461)\n\nモックできているかどうかの確認はモック用のSVGはPixelaの色を変えてからローカルに保存したのでdev用は赤、本番は青といった感じで別れている\n\n## まとめ\n\n<em>ms</em>wを使って開発時はpixelaへのSVGリクエストをモックして開発時はアクセスが行かないようにした\n\nリクエスト先のURLを出し分けせずにモックできるのは非常に体験が良い\n\n外部のサービスやツールを使っていてsandbox用とかで分けられていない場合などいろんな用途に使えそう\n\n他にも用途いろいろありそうなので使っていこうと思った",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-12-29",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "<em>ms</em>wでSVGをモックする",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "tags": [
              {
                "value": "JavaScript",
                "matchLevel": "none",
                "matchedWords": []
              },
              {
                "value": "TypeScript",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "Gatsby", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "<em>ms</em>w",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["ms"]
              }
            ],
            "description": {
              "value": "Pixelaを題材としてモックしてみた",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/<em>ms</em>w_mock_svg/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/jest_with_msw/",
          "text": "\n開発用に定義したmswの設定をJestでも使いたい案件\n\n参考のまんまだけどめちゃくちゃ簡単だった\n\nテスト用のファイルに下記のように書くだけ\n\n- search.tsx\n\n```tsx\nimport { handlers } from \"../../mocks/handler\"\ndescribe(\"Search\", () => {\n  const user = userEvent.setup()\n  const server = setupServer(...handlers)\n\n  beforeEach(() => {\n    server.listen()\n  })\n\n  afterEach(() => {\n    server.close()\n  })\n\n  it(\"検索UIのテスト\", async () => {\n    // mswでのモックレスポンスが適用される\n    .....\n    .....\n    .....\n    .....\n  })\n})\n```\n\n- handler.ts\n\n```ts\nimport { rest } from \"msw\"\nimport { setupServer } from \"msw/node\"\n\nexport const handlers = [\n  rest.post(\"https://example.com/*\", (req, res, ctx) => {\n    return res(\n      ctx.status(200),\n      ctx.json({})\n    )\n  }),\n]\n```\n\n`setupServer`で事前定義した`handlers`を読ませ`beforeEach`で各テストの実行前にサーバ起動する\n\n終わったら落とすようにしている\n\nこれだけでよい\n\nとても楽\n\n開発時とテスト時で同じ設定を使えるのもメンテナンス上とてもよい\n\n外部へのリクエストが発生する機能はどんどん活用していくモチベーションが上がった\n\n### 参考\n- [Jest + @testing-library/react + mswのtips - Qiita](https://qiita.com/shibukawa/items/4d431ee4f98c80b682ec)\n",
          "date": "2022-08-19",
          "title": "mswのモックをjestのテストでも使う",
          "tags": ["Jest", "msw", "TypeScript"],
          "description": "開発時と同様",
          "slug": "/entries/jest_with_msw/",
          "timeToRead": 1,
          "objectID": "3cb05eab-dd49-525f-9761-98eaccf45fa7",
          "_snippetResult": {
            "text": {
              "value": "ト\", async () => {\n    // <em>ms</em>wでのモックレスポンスが適用される\n    .....\n    .....\n    .....\n    .....\n  })\n})\n```\n\n- handler.ts\n\n```ts\nimport { rest } from \"<em>ms</em>w\"\nimport { setupServer } from \"<em>ms</em>w/node\"\n\nexport const handlers = [\n  rest.post(\"https://example.com/*\", (req, res, ctx) => {\n    return res(\n      ctx.status(200),\n      ctx.json({})\n    )\n  }),\n]\n```\n\n`setupServer",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/jest_with_<em>ms</em>w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "text": {
              "value": "\n開発用に定義した<em>ms</em>wの設定をJestでも使いたい案件\n\n参考のまんまだけどめちゃくちゃ簡単だった\n\nテスト用のファイルに下記のように書くだけ\n\n- search.tsx\n\n```tsx\nimport { handlers } from \"../../mocks/handler\"\ndescribe(\"Search\", () => {\n  const user = userEvent.setup()\n  const server = setupServer(...handlers)\n\n  beforeEach(() => {\n    server.listen()\n  })\n\n  afterEach(() => {\n    server.close()\n  })\n\n  it(\"検索UIのテスト\", async () => {\n    // <em>ms</em>wでのモックレスポンスが適用される\n    .....\n    .....\n    .....\n    .....\n  })\n})\n```\n\n- handler.ts\n\n```ts\nimport { rest } from \"<em>ms</em>w\"\nimport { setupServer } from \"<em>ms</em>w/node\"\n\nexport const handlers = [\n  rest.post(\"https://example.com/*\", (req, res, ctx) => {\n    return res(\n      ctx.status(200),\n      ctx.json({})\n    )\n  }),\n]\n```\n\n`setupServer`で事前定義した`handlers`を読ませ`beforeEach`で各テストの実行前にサーバ起動する\n\n終わったら落とすようにしている\n\nこれだけでよい\n\nとても楽\n\n開発時とテスト時で同じ設定を使えるのもメンテナンス上とてもよい\n\n外部へのリクエストが発生する機能はどんどん活用していくモチベーションが上がった\n\n### 参考\n- [Jest + @testing-library/react + <em>ms</em>wのtips - Qiita](https://qiita.com/shibukawa/items/4d431ee4f98c80b682ec)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2022-08-19",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "<em>ms</em>wのモックをjestのテストでも使う",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "tags": [
              { "value": "Jest", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "<em>ms</em>w",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["ms"]
              },
              {
                "value": "TypeScript",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "開発時と同様",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/jest_with_<em>ms</em>w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/algolia_mock_with_msw/",
          "text": "\nAlgoliaの検索リクエストをmswでモックした\n\n開発時は検索用のAPIキーを登録せずにインデックスへのアクセスもしないようにすれば良くない？\n\n空レスポンスを返すようにしておけば良くない？\n\nみたいな話はあるものの、検索にかかるUI部分を開発するならある程度実際にリクエストした時のレスポンスが欲しくなる\n\nかと言ってAlgoliaに毎度リクエストさせてしまうと無料枠がどんどん減っていく…\n\nということで、mswで解決した\n\n## やっていること\n- 実際のレスポンスデータをdev toolsのNetworkからレスポンス内容を取得してきてJSONに保存\n    - 特定文字列(`BigQuery`)を順次入力した場合のレスポンスを逐次取得\n        - `B`と入力した際のレスポンス\n        - `Bi`と入力した際のレスポンス\n        - `Big`と入力した際のレスポンス\n        - `BigQ`と入力した際のレスポンス\n        - `BigQu`と入力した際のレスポンス\n        - `BigQue`と入力した際のレスポンス\n        - `BigQuer`と入力した際のレスポンス\n        - `BigQuery`と入力した際のレスポンス\n- 先工程で保存したJSONをmswを用いて返すように設定する\n\n「検索文字列の変化によっって返ってくる件数や内容が変わる」というのを再現したかったので固定値ではあるが検索文字列が変化した場合は文字数にあったレスポンスがmsw経由で返るようにした\n\n実際のコードは下記\n\n- handler.ts\n\n```typescript\nimport { rest } from \"msw\"\nimport query0Words from \"./algolia-search-response-0-words.json\"\nimport query1Words from \"./algolia-search-response-1-words.json\"\nimport query2Words from \"./algolia-search-response-2-words.json\"\nimport query3Words from \"./algolia-search-response-3-words.json\"\nimport query4Words from \"./algolia-search-response-4-words.json\"\nimport query5Words from \"./algolia-search-response-5-words.json\"\nimport query6Words from \"./algolia-search-response-6-words.json\"\nimport query7Words from \"./algolia-search-response-7-words.json\"\nimport query8Words from \"./algolia-search-response-8-words.json\"\n\nexport const handlers = [\n  rest.post(\"https://*.algolia.net/1/indexes/*/queries\", (req, res, ctx) => {\n    const empty = query0Words\n\n    const wordCountResponseMap = [\n      empty,       // 空\n      query1Words, // B\n      query2Words, // Bi\n      query3Words, // Big\n      query4Words, // BigQ\n      query5Words, // BigQu\n      query6Words, // BigQue\n      query7Words, // BigQuer\n      query8Words, // BigQuery\n    ]\n\n    const bodyString = req.body as string\n\n    if (bodyString.length === 0) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    const body = JSON.parse(bodyString)\n    const params = [\n      ...new URLSearchParams(body.requests[0].params).entries(),\n    ].reduce((obj, e) => ({ ...obj, [e[0]]: e[1] }), {} as { query: string })\n\n    if (\n      !params.query ||\n      params.query.length === 0 ||\n      params.query.length > wordCountResponseMap.length\n    ) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    return res(\n      ctx.status(200),\n      ctx.json(wordCountResponseMap[params.query.length])\n    )\n  }),\n]\n```\n\n`import`している実際のレスポンスを保存したJSONはAlgoliaでの設定などにより変わるのでここでは割愛する\n\nAlgoliaのレスポンスを完全再現はできないので次のような挙動にしている\n\n<!-- textlint-disable prh -->\n- どの文字列を入力したとしても開発時は`BigQuery`と入力した場合のレスポンスを返す\n- 検索文字列の入力文字数によってモック用のレスポンスを返す\n    - 1文字入力時は`B`が入力された時のモック用レスポンスを返す\n    - 2文字入力時は`Bi`が入力された時のモック用レスポンスを返す\n    - 3文字入力時は`Big`が入力された時のモック用レスポンスを返す\n    - 8文字まで同様\n- 検索文字列が用意している文字列以上入力された場合は何も文字を入力していない場合のレスポンスを返す(`query0Words`)\n<!-- textlint-enable prh -->\n\nこれで検索UIの開発はかなり捗ったのでメモとして残しておく\n",
          "date": "2022-08-12",
          "title": "Algoliaのレスポンスをmswでモックして開発ではダミーレスポンスを扱う",
          "tags": ["Algolia", "msw", "TypeScript"],
          "description": "実際のJSONを用意する",
          "slug": "/entries/algolia_mock_with_msw/",
          "timeToRead": 3,
          "objectID": "c8728ebf-22ac-5299-ba20-c595cab71ff1",
          "_snippetResult": {
            "text": {
              "value": "\nAlgoliaの検索リクエストを<em>ms</em>wでモックした\n\n開発時は検索用のAPIキーを登録せずにインデックスへのアクセスもしな",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/algolia_mock_with_<em>ms</em>w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "text": {
              "value": "\nAlgoliaの検索リクエストを<em>ms</em>wでモックした\n\n開発時は検索用のAPIキーを登録せずにインデックスへのアクセスもしないようにすれば良くない？\n\n空レスポンスを返すようにしておけば良くない？\n\nみたいな話はあるものの、検索にかかるUI部分を開発するならある程度実際にリクエストした時のレスポンスが欲しくなる\n\nかと言ってAlgoliaに毎度リクエストさせてしまうと無料枠がどんどん減っていく…\n\nということで、<em>ms</em>wで解決した\n\n## やっていること\n- 実際のレスポンスデータをdev toolsのNetworkからレスポンス内容を取得してきてJSONに保存\n    - 特定文字列(`BigQuery`)を順次入力した場合のレスポンスを逐次取得\n        - `B`と入力した際のレスポンス\n        - `Bi`と入力した際のレスポンス\n        - `Big`と入力した際のレスポンス\n        - `BigQ`と入力した際のレスポンス\n        - `BigQu`と入力した際のレスポンス\n        - `BigQue`と入力した際のレスポンス\n        - `BigQuer`と入力した際のレスポンス\n        - `BigQuery`と入力した際のレスポンス\n- 先工程で保存したJSONを<em>ms</em>wを用いて返すように設定する\n\n「検索文字列の変化によっって返ってくる件数や内容が変わる」というのを再現したかったので固定値ではあるが検索文字列が変化した場合は文字数にあったレスポンスが<em>ms</em>w経由で返るようにした\n\n実際のコードは下記\n\n- handler.ts\n\n```typescript\nimport { rest } from \"<em>ms</em>w\"\nimport query0Words from \"./algolia-search-response-0-words.json\"\nimport query1Words from \"./algolia-search-response-1-words.json\"\nimport query2Words from \"./algolia-search-response-2-words.json\"\nimport query3Words from \"./algolia-search-response-3-words.json\"\nimport query4Words from \"./algolia-search-response-4-words.json\"\nimport query5Words from \"./algolia-search-response-5-words.json\"\nimport query6Words from \"./algolia-search-response-6-words.json\"\nimport query7Words from \"./algolia-search-response-7-words.json\"\nimport query8Words from \"./algolia-search-response-8-words.json\"\n\nexport const handlers = [\n  rest.post(\"https://*.algolia.net/1/indexes/*/queries\", (req, res, ctx) => {\n    const empty = query0Words\n\n    const wordCountResponseMap = [\n      empty,       // 空\n      query1Words, // B\n      query2Words, // Bi\n      query3Words, // Big\n      query4Words, // BigQ\n      query5Words, // BigQu\n      query6Words, // BigQue\n      query7Words, // BigQuer\n      query8Words, // BigQuery\n    ]\n\n    const bodyString = req.body as string\n\n    if (bodyString.length === 0) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    const body = JSON.parse(bodyString)\n    const params = [\n      ...new URLSearchParams(body.requests[0].params).entries(),\n    ].reduce((obj, e) => ({ ...obj, [e[0]]: e[1] }), {} as { query: string })\n\n    if (\n      !params.query ||\n      params.query.length === 0 ||\n      params.query.length > wordCountResponseMap.length\n    ) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    return res(\n      ctx.status(200),\n      ctx.json(wordCountResponseMap[params.query.length])\n    )\n  }),\n]\n```\n\n`import`している実際のレスポンスを保存したJSONはAlgoliaでの設定などにより変わるのでここでは割愛する\n\nAlgoliaのレスポンスを完全再現はできないので次のような挙動にしている\n\n<!-- textlint-disable prh -->\n- どの文字列を入力したとしても開発時は`BigQuery`と入力した場合のレスポンスを返す\n- 検索文字列の入力文字数によってモック用のレスポンスを返す\n    - 1文字入力時は`B`が入力された時のモック用レスポンスを返す\n    - 2文字入力時は`Bi`が入力された時のモック用レスポンスを返す\n    - 3文字入力時は`Big`が入力された時のモック用レスポンスを返す\n    - 8文字まで同様\n- 検索文字列が用意している文字列以上入力された場合は何も文字を入力していない場合のレスポンスを返す(`query0Words`)\n<!-- textlint-enable prh -->\n\nこれで検索UIの開発はかなり捗ったのでメモとして残しておく\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2022-08-12",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Algoliaのレスポンスを<em>ms</em>wでモックして開発ではダミーレスポンスを扱う",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "tags": [
              { "value": "Algolia", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "<em>ms</em>w",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["ms"]
              },
              {
                "value": "TypeScript",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "実際のJSONを用意する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/algolia_mock_with_<em>ms</em>w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/ansible_with_python3/",
          "text": "\r\nなんとなくAnsibleの実行環境をPython3にして実行してみたら見事エラーで死亡したのでその際の対応ログ\r\n\r\n```\r\nfatal: [localhost]: FAILED! => {\"msg\": \"The conditional check 'ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"' failed. The error was: error while evaluating conditional (ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"): 'dict object' has no attribute 'has_key'\\n\\nThe error appears to be in '/usr/local/src/ansible/roles/common/tasks/redhat.yml': line 63, column 3, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n\\n- name: disable SELinux\\n  ^ here\\n\"}\r\n```\r\n\r\nhas_keyがない\r\n\r\nということで\r\n\r\nPython3での実行に対応するには\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ 'CI' in ansible_env\r\n```\r\n\r\nもしくは\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ ansible_env.get('CI', None)\r\n```\r\n\r\nの対応が必要\r\n\r\n",
          "date": "2020-06-24",
          "title": "Python3でAnsibleを実行する際のエラー対応",
          "tags": ["Ansible", "Python"],
          "description": "has_key",
          "slug": "/entries/ansible_with_python3/",
          "timeToRead": 1,
          "objectID": "6014c47b-213e-502d-a64d-ce386474aedf",
          "_snippetResult": {
            "text": {
              "value": "\r\nなんとなくAnsibleの実行環境をPython3にして実行してみたら見事エラーで死亡したのでその際の対応ログ\r\n\r\n```\r\nfatal: [localhost]: FAILED! => {\"<em>ms</em>g\": \"The conditional",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/ansible_with_python3/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\r\nなんとなくAnsibleの実行環境をPython3にして実行してみたら見事エラーで死亡したのでその際の対応ログ\r\n\r\n```\r\nfatal: [localhost]: FAILED! => {\"<em>ms</em>g\": \"The conditional check 'ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"' failed. The error was: error while evaluating conditional (ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"): 'dict object' has no attribute 'has_key'\\n\\nThe error appears to be in '/usr/local/src/ansible/roles/common/tasks/redhat.yml': line 63, column 3, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n\\n- name: disable SELinux\\n  ^ here\\n\"}\r\n```\r\n\r\nhas_keyがない\r\n\r\nということで\r\n\r\nPython3での実行に対応するには\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ 'CI' in ansible_env\r\n```\r\n\r\nもしくは\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ ansible_env.get('CI', None)\r\n```\r\n\r\nの対応が必要\r\n\r\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2020-06-24",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Python3でAnsibleを実行する際のエラー対応",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Ansible", "matchLevel": "none", "matchedWords": [] },
              { "value": "Python", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "has_key",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ansible_with_python3/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/docker_compose_dns/",
          "text": "\n新しい開発環境ではAnsibleでローカル環境を作るようにしているが次のようにansibleの`get_url`実行に失敗してしまっていた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"Failed to connect to objects.githubusercontent.com at port 443: [Errno -5] No address associated with hostname\"}\n```\n\n名前解決ができていないという状態のようだったのでDNSサーバを指定してあげれば良い\n\n- docker-compose.yml\n\n```yaml\nversion: \"3\"\nservices:\n  app:\n    build:\n      context: ./ansible\n    dns:\n      - 8.8.8.8\n```\n\n上記のように`dns`を指定することで解決した\n\n",
          "date": "2022-01-10",
          "title": "Docker環境でAnsibleのget_url実行が失敗する",
          "tags": ["Docker", "docker-compose"],
          "description": "docker-composeでDNSの指定",
          "slug": "/entries/docker_compose_dns/",
          "timeToRead": 1,
          "objectID": "ce38bab6-5daa-5658-8137-b6c2ec1c60c5",
          "_snippetResult": {
            "text": {
              "value": "ようにansibleの`get_url`実行に失敗してしまっていた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"<em>ms</em>g\": \"Failed to connect to objects.githubusercontent.com at port 443: [Errno -5] No address associated with hostname\"}\n```\n\n名前解決ができ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/docker_compose_dns/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n新しい開発環境ではAnsibleでローカル環境を作るようにしているが次のようにansibleの`get_url`実行に失敗してしまっていた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"<em>ms</em>g\": \"Failed to connect to objects.githubusercontent.com at port 443: [Errno -5] No address associated with hostname\"}\n```\n\n名前解決ができていないという状態のようだったのでDNSサーバを指定してあげれば良い\n\n- docker-compose.yml\n\n```yaml\nversion: \"3\"\nservices:\n  app:\n    build:\n      context: ./ansible\n    dns:\n      - 8.8.8.8\n```\n\n上記のように`dns`を指定することで解決した\n\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2022-01-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Docker環境でAnsibleのget_url実行が失敗する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Docker", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "docker-compose",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "docker-composeでDNSの指定",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/docker_compose_dns/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/require_ca_certificate_in_ansible_centos7/",
          "text": "\nCentOS7のイメージ中でAnsibleを使って`get_url`でGitをソースからインストールしている処理があったがそこで問題が発生していた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"dest\": \"/tmp/git-2.33.0.tar.gz\", \"elapsed\": 0, \"msg\": \"Request failed: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)>\", \"url\": \"https://www.kernel.org/pub/software/scm/git/git-2.33.0.tar.gz\"}\n```\n\n証明書関連かーというのはすぐ分かるが、じゃどうすれば良いのってことで\n\nAnsibleだとrequestsかcertificateモジュールを更新すればよいのかと思って更新してみたものの解決されず\n\n証明書リストを追加すればOK?みたいな感じで探していたら次の記事に助けられた\n\n[Let's EncryptのルートCA期限切れで OpenSSL 1.0.2が思わぬ事故を起こす件 | ワルブリックス株式会社](https://www.walbrix.co.jp/article/openssl-102-letsencrypt-crisis.html)\n\n`www.kernel.org`を見に行ったらLet's Encryptと`ISRG Root X1`の組み合わせだった\n\n最新のOSバージョンでは解決しているとのことだったので今一度更新してから試そうとしてみた\n\ndockerでイメージビルドするときは最新を指定してたはずなのでどうかなと思ったもののいったん`yum update`で更新して試してみた\n\n```\n$ yum update\n===============================================================================================================================================================================\n Package                                       Arch                              Version                                              Repository                          Size\n===============================================================================================================================================================================\nUpdating:\n bind-license                                  noarch                            32:9.11.4-26.P2.el7_9.7                              updates                             91 k\n ca-certificates                               noarch                            2021.2.50-72.el7_9                                   updates                            379 k\n centos-release                                x86_64                            7-9.2009.1.el7.centos                                updates                             27 k\n coreutils                                     x86_64                            8.22-24.el7_9.2                                      updates                            3.3 M\n device-mapper                                 x86_64                            7:1.02.170-6.el7_9.5                                 updates                            297 k\n device-mapper-libs                            x86_64                            7:1.02.170-6.el7_9.5                                 updates                            325 k\n epel-release                                  noarch                            7-14                                                 epel                                15 k\n glib2                                         x86_64                            2.56.1-9.el7_9                                       updates                            2.5 M\n glibc                                         x86_64                            2.17-325.el7_9                                       updates                            3.6 M\n glibc-common                                  x86_64                            2.17-325.el7_9                                       updates                             12 M\n glibc-devel                                   x86_64                            2.17-325.el7_9                                       updates                            1.1 M\n glibc-headers                                 x86_64                            2.17-325.el7_9                                       updates                            691 k\n kernel-headers                                x86_64                            3.10.0-1160.45.1.el7                                 updates                            9.0 M\n kpartx                                        x86_64                            0.4.9-135.el7_9                                      updates                             81 k\n libblkid                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            183 k\n libmount                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            185 k\n libsmartcols                                  x86_64                            2.23.2-65.el7_9.1                                    updates                            143 k\n libuuid                                       x86_64                            2.23.2-65.el7_9.1                                    updates                             84 k\n nspr                                          x86_64                            4.32.0-1.el7_9                                       updates                            127 k\n nss                                           x86_64                            3.67.0-3.el7_9                                       updates                            882 k\n nss-softokn                                   x86_64                            3.67.0-3.el7_9                                       updates                            358 k\n nss-softokn-freebl                            x86_64                            3.67.0-3.el7_9                                       updates                            337 k\n nss-sysinit                                   x86_64                            3.67.0-3.el7_9                                       updates                             66 k\n nss-tools                                     x86_64                            3.67.0-3.el7_9                                       updates                            549 k\n nss-util                                      x86_64                            3.67.0-1.el7_9                                       updates                             79 k\n openldap                                      x86_64                            2.4.44-24.el7_9                                      updates                            356 k\n python                                        x86_64                            2.7.5-90.el7                                         updates                             96 k\n python-libs                                   x86_64                            2.7.5-90.el7                                         updates                            5.6 M\n rpm                                           x86_64                            4.11.3-46.el7_9                                      updates                            1.2 M\n rpm-build-libs                                x86_64                            4.11.3-46.el7_9                                      updates                            108 k\n rpm-libs                                      x86_64                            4.11.3-46.el7_9                                      updates                            279 k\n rpm-python                                    x86_64                            4.11.3-46.el7_9                                      updates                             84 k\n sudo                                          x86_64                            1.8.23-10.el7_9.2                                    updates                            843 k\n systemd                                       x86_64                            219-78.el7_9.3                                       updates                            5.1 M\n systemd-libs                                  x86_64                            219-78.el7_9.3                                       updates                            418 k\n tzdata                                        noarch                            2021c-1.el7                                          updates                            502 k\n util-linux                                    x86_64                            2.23.2-65.el7_9.1                                    updates                            2.0 M\n vim-minimal                                   x86_64                            2:7.4.629-8.el7_9                                    updates                            443 k\n\nTransaction Summary\n===============================================================================================================================================================================\nUpgrade  38 Packages\n```\n\nこのあとでのansible実行は問題なく実行できた\n\nということでこの中のどれかのパッケージを更新すれば問題なさそうという感じ\n\n`ca-certificates`かな?CA証明書のリスト\n\nということで`ca-certificates`のみlatestにするようなAnsibleを書いて再実行したところ無事成功した\n\n※参考の記事中にもよく読んだら`ca-certificate`パッケージを上げると書いてあった\n\nパッケージすべてlatestだと勝手に更新されて失敗してしまったりしたら困るよねっていう認識だったが逆にlatestのほうが良いものもあるんだなというのが今回の気付きでした\n\n最近ちょいちょいこのパータンにはまっている気がするので残しておく",
          "date": "2021-11-10",
          "title": "CentOS7でAnsible実行時にCERTIFICATE_VERIFY_FAILED",
          "tags": ["Ansible", "CentOS7", "Python"],
          "description": "ca-certificateを更新",
          "slug": "/entries/require_ca_certificate_in_ansible_centos7/",
          "timeToRead": 4,
          "objectID": "a5491716-3045-589f-b0d9-63fd56de439c",
          "_snippetResult": {
            "text": {
              "value": "で問題が発生していた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"dest\": \"/tmp/git-2.33.0.tar.gz\", \"elapsed\": 0, \"<em>ms</em>g\": \"Request failed: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)>\", \"url\": \"https://www.kernel.org/pub/software/scm/git/git",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/require_ca_certificate_in_ansible_centos7/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nCentOS7のイメージ中でAnsibleを使って`get_url`でGitをソースからインストールしている処理があったがそこで問題が発生していた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"dest\": \"/tmp/git-2.33.0.tar.gz\", \"elapsed\": 0, \"<em>ms</em>g\": \"Request failed: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)>\", \"url\": \"https://www.kernel.org/pub/software/scm/git/git-2.33.0.tar.gz\"}\n```\n\n証明書関連かーというのはすぐ分かるが、じゃどうすれば良いのってことで\n\nAnsibleだとrequestsかcertificateモジュールを更新すればよいのかと思って更新してみたものの解決されず\n\n証明書リストを追加すればOK?みたいな感じで探していたら次の記事に助けられた\n\n[Let's EncryptのルートCA期限切れで OpenSSL 1.0.2が思わぬ事故を起こす件 | ワルブリックス株式会社](https://www.walbrix.co.jp/article/openssl-102-letsencrypt-crisis.html)\n\n`www.kernel.org`を見に行ったらLet's Encryptと`ISRG Root X1`の組み合わせだった\n\n最新のOSバージョンでは解決しているとのことだったので今一度更新してから試そうとしてみた\n\ndockerでイメージビルドするときは最新を指定してたはずなのでどうかなと思ったもののいったん`yum update`で更新して試してみた\n\n```\n$ yum update\n===============================================================================================================================================================================\n Package                                       Arch                              Version                                              Repository                          Size\n===============================================================================================================================================================================\nUpdating:\n bind-license                                  noarch                            32:9.11.4-26.P2.el7_9.7                              updates                             91 k\n ca-certificates                               noarch                            2021.2.50-72.el7_9                                   updates                            379 k\n centos-release                                x86_64                            7-9.2009.1.el7.centos                                updates                             27 k\n coreutils                                     x86_64                            8.22-24.el7_9.2                                      updates                            3.3 M\n device-mapper                                 x86_64                            7:1.02.170-6.el7_9.5                                 updates                            297 k\n device-mapper-libs                            x86_64                            7:1.02.170-6.el7_9.5                                 updates                            325 k\n epel-release                                  noarch                            7-14                                                 epel                                15 k\n glib2                                         x86_64                            2.56.1-9.el7_9                                       updates                            2.5 M\n glibc                                         x86_64                            2.17-325.el7_9                                       updates                            3.6 M\n glibc-common                                  x86_64                            2.17-325.el7_9                                       updates                             12 M\n glibc-devel                                   x86_64                            2.17-325.el7_9                                       updates                            1.1 M\n glibc-headers                                 x86_64                            2.17-325.el7_9                                       updates                            691 k\n kernel-headers                                x86_64                            3.10.0-1160.45.1.el7                                 updates                            9.0 M\n kpartx                                        x86_64                            0.4.9-135.el7_9                                      updates                             81 k\n libblkid                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            183 k\n libmount                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            185 k\n libsmartcols                                  x86_64                            2.23.2-65.el7_9.1                                    updates                            143 k\n libuuid                                       x86_64                            2.23.2-65.el7_9.1                                    updates                             84 k\n nspr                                          x86_64                            4.32.0-1.el7_9                                       updates                            127 k\n nss                                           x86_64                            3.67.0-3.el7_9                                       updates                            882 k\n nss-softokn                                   x86_64                            3.67.0-3.el7_9                                       updates                            358 k\n nss-softokn-freebl                            x86_64                            3.67.0-3.el7_9                                       updates                            337 k\n nss-sysinit                                   x86_64                            3.67.0-3.el7_9                                       updates                             66 k\n nss-tools                                     x86_64                            3.67.0-3.el7_9                                       updates                            549 k\n nss-util                                      x86_64                            3.67.0-1.el7_9                                       updates                             79 k\n openldap                                      x86_64                            2.4.44-24.el7_9                                      updates                            356 k\n python                                        x86_64                            2.7.5-90.el7                                         updates                             96 k\n python-libs                                   x86_64                            2.7.5-90.el7                                         updates                            5.6 M\n rpm                                           x86_64                            4.11.3-46.el7_9                                      updates                            1.2 M\n rpm-build-libs                                x86_64                            4.11.3-46.el7_9                                      updates                            108 k\n rpm-libs                                      x86_64                            4.11.3-46.el7_9                                      updates                            279 k\n rpm-python                                    x86_64                            4.11.3-46.el7_9                                      updates                             84 k\n sudo                                          x86_64                            1.8.23-10.el7_9.2                                    updates                            843 k\n systemd                                       x86_64                            219-78.el7_9.3                                       updates                            5.1 M\n systemd-libs                                  x86_64                            219-78.el7_9.3                                       updates                            418 k\n tzdata                                        noarch                            2021c-1.el7                                          updates                            502 k\n util-linux                                    x86_64                            2.23.2-65.el7_9.1                                    updates                            2.0 M\n vim-minimal                                   x86_64                            2:7.4.629-8.el7_9                                    updates                            443 k\n\nTransaction Summary\n===============================================================================================================================================================================\nUpgrade  38 Packages\n```\n\nこのあとでのansible実行は問題なく実行できた\n\nということでこの中のどれかのパッケージを更新すれば問題なさそうという感じ\n\n`ca-certificates`かな?CA証明書のリスト\n\nということで`ca-certificates`のみlatestにするようなAnsibleを書いて再実行したところ無事成功した\n\n※参考の記事中にもよく読んだら`ca-certificate`パッケージを上げると書いてあった\n\nパッケージすべてlatestだと勝手に更新されて失敗してしまったりしたら困るよねっていう認識だったが逆にlatestのほうが良いものもあるんだなというのが今回の気付きでした\n\n最近ちょいちょいこのパータンにはまっている気がするので残しておく",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-11-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "CentOS7でAnsible実行時にCERTIFICATE_VERIFY_FAILED",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Ansible", "matchLevel": "none", "matchedWords": [] },
              { "value": "CentOS7", "matchLevel": "none", "matchedWords": [] },
              { "value": "Python", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "ca-certificateを更新",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/require_ca_certificate_in_ansible_centos7/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "4",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/toc_bookmarklet/",
          "text": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + body + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(msg)%20=>%20{%20console.log(msg)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(body)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
          "date": "2021-06-10",
          "title": "TOCを抽出するためのブックマークレット",
          "tags": ["Bookmarklet"],
          "description": "TOC",
          "slug": "/entries/toc_bookmarklet/",
          "timeToRead": 1,
          "objectID": "49593c1a-0da8-5fdf-ad6b-84aa473c7dbf",
          "_snippetResult": {
            "text": {
              "value": "ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (<em>ms</em>g) => { console.log(<em>ms</em>g) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC' + body + '');\n    d.close();\n  };\n\n  const toc = Array",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/toc_bookmarklet/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (<em>ms</em>g) => { console.log(<em>ms</em>g) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + body + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(<em>ms</em>g)%20=>%20{%20console.log(<em>ms</em>g)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(body)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-06-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "TOCを抽出するためのブックマークレット",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "Bookmarklet",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "TOC",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/toc_bookmarklet/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
          "text": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 ms)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
          "date": "2021-07-19",
          "title": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
          "tags": ["Jest", "Gatsby", "TestingLibrary"],
          "description": "jsdom使う",
          "slug": "/entries/introduction_jest_and_testing_library_to_gatsby/",
          "timeToRead": 2,
          "objectID": "6fca825c-1e53-5398-b057-6f44e9a29349",
          "_snippetResult": {
            "text": {
              "value": "拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 <em>ms</em>)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 <em>ms</em>)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 <em>ms</em>)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-07-19",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Jest", "matchLevel": "none", "matchedWords": [] },
              { "value": "Gatsby", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "TestingLibrary",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "jsdom使う",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 8,
      "page": 0,
      "nbPages": 1,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "exhaustive": { "nbHits": true, "typo": true },
      "query": "ms",
      "params": "facets=%5B%5D&query=ms&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 4,
      "processingTimingsMS": {
        "afterFetch": {
          "format": { "highlighting": 1, "snippeting": 2, "total": 4 },
          "total": 4
        },
        "total": 4
      }
    },
    {
      "hits": [
        {
          "title": "mongoDBでクエリログを流す",
          "date": "2016-09-14",
          "slug": "mongoDB/slow_log",
          "url": "http://localhost:8001/mongoDB/slow_log",
          "section": "mongoDB/slow_log",
          "tags": ["MongoDB"],
          "text": "# mongoDBでクエリログを流す\n\n## mongoDB起動時\n\n下記をつけて起動させればOK\n\n```\n/urr/bin/mongod --profile=2 --slowms=1\n```\n\n--profile\n\nプロファイルのレベル\n\n- 1: 閾値以上の時間のかかったクエリを残す\n- 2: すべてのクエリを残す\n\n--slowms\n\n閾値(ms)\n\n\n## コンソールから\n\n```\n$ mongo\ndb.setProfilingLevel(2,1)\n{ \"was\" : 0, \"slowms\" : 20, \"ok\" : 1 }\n> db.system.profile.find()\n.....\n.....\n```\n\n第一引数がプロファイルのレベル\n\n第二引数が閾値\n\nどちらで行っても出力先はmongoDBの`system.profile`コレクションに出力される模様\n\n[Database Profiler Output — MongoDB Manual 3.2](https://docs.mongodb.com/manual/reference/database-profiler/)\n\n[https://docs.mongodb.com/manual/reference/database-profiler/:embed:cite]\n\n一生懸命ファイルを探しても見つからないわけですね\n\n### mongotail\n\nいちいちシェルに入ってコマンドたたくのも面倒ですね\n\nmongoDBでslowlogをとるようにしておけばmongotailというコマンドを使ってクエリログを閲覧や垂れ流しできます\n\n[mrsarm/mongotail](https://github.com/mrsarm/mongotail )\n\n[https://github.com/mrsarm/mongotail:embed:cite]\n\n- install\n\n```\npip install mongotail\n```\n\npipでインストール可能\n\n- tailしてみる\n\nこちらもDBのアドレスとデータベース名を入れてコマンドを実行するだけです\n\n`-f`で `tail -f` と同様な感じに、`-v`(verboseモード)ですべてのログを出力してくれるようです\n\n```\nmongotail 192.168.30.93:27017/database -v -f\n```\n\n簡単!\n\n",
          "objectID": "mongoDB/slow_log",
          "_snippetResult": {
            "text": {
              "value": "のかかったクエリを残す\n- 2: すべてのクエリを残す\n\n--slowms\n\n閾値(__ais-highlight__ms__/ais-highlight__)\n\n\n## コンソールから\n\n```\n$ mongo\ndb.setProfilingLevel(2,1)\n{ \"was\" : 0, \"slowms\" : 20, \"ok\" : 1 }\n> db.system.profile.find()\n.....\n.....\n```\n\n第",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "mongoDBでクエリログを流す",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2016-09-14",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "mongoDB/slow_log",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/mongoDB/slow_log",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "mongoDB/slow_log",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "MongoDB", "matchLevel": "none", "matchedWords": [] }
            ],
            "text": {
              "value": "# mongoDBでクエリログを流す\n\n## mongoDB起動時\n\n下記をつけて起動させればOK\n\n```\n/urr/bin/mongod --profile=2 --slowms=1\n```\n\n--profile\n\nプロファイルのレベル\n\n- 1: 閾値以上の時間のかかったクエリを残す\n- 2: すべてのクエリを残す\n\n--slowms\n\n閾値(__ais-highlight__ms__/ais-highlight__)\n\n\n## コンソールから\n\n```\n$ mongo\ndb.setProfilingLevel(2,1)\n{ \"was\" : 0, \"slowms\" : 20, \"ok\" : 1 }\n> db.system.profile.find()\n.....\n.....\n```\n\n第一引数がプロファイルのレベル\n\n第二引数が閾値\n\nどちらで行っても出力先はmongoDBの`system.profile`コレクションに出力される模様\n\n[Database Profiler Output — MongoDB Manual 3.2](https://docs.mongodb.com/manual/reference/database-profiler/)\n\n[https://docs.mongodb.com/manual/reference/database-profiler/:embed:cite]\n\n一生懸命ファイルを探しても見つからないわけですね\n\n### mongotail\n\nいちいちシェルに入ってコマンドたたくのも面倒ですね\n\nmongoDBでslowlogをとるようにしておけばmongotailというコマンドを使ってクエリログを閲覧や垂れ流しできます\n\n[mrsarm/mongotail](https://github.com/mrsarm/mongotail )\n\n[https://github.com/mrsarm/mongotail:embed:cite]\n\n- install\n\n```\npip install mongotail\n```\n\npipでインストール可能\n\n- tailしてみる\n\nこちらもDBのアドレスとデータベース名を入れてコマンドを実行するだけです\n\n`-f`で `tail -f` と同様な感じに、`-v`(verboseモード)ですべてのログを出力してくれるようです\n\n```\nmongotail 192.168.30.93:27017/database -v -f\n```\n\n簡単!\n\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        },
        {
          "title": "PixelaのグラフをGatsby製のブログに埋め込む",
          "date": "2021-10-15",
          "slug": "react/gatsby_pixela_direct_execution",
          "url": "http://localhost:8001/react/gatsby_pixela_direct_execution",
          "section": "react/gatsby_pixela_direct_execution",
          "tags": ["React", "Gatsby", "Pixela"],
          "text": "# PixelaのグラフをGatsby製のブログに埋め込む\n\nPixelaのグラフをGatsby(React)で表示させたい\n\n素直にsvgをobjectタグで読み込むだけだとツールチップが表示されないのでせっかくなら表示させたい\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\n（※前提の参考リンクをよく読めばiframeで良くないか?という話になるが、今回はmswを使って開発しているときはローカルだけで完結させたい、がiframeはmswではモックできないという事情により色々面倒なことをやっている）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n\nなので完全な自分用のメモである\n\n## 前提知識\n\n[はてなブログに Pixela グラフを埋め込んで、さらにツールチップを表示させる方法 - えいのうにっき](https://blog.a-know.me/entry/2018/11/20/220257)\n\n[https://blog.a-know.me/entry/2018/11/20/220257:embed:cite]\n\nはてなブログへの埋め込み方法は上記\n\npopoverを表示するためのライブラリとして`tippyjs`を使うことを前提としている\n\nPixelaが返すSVGの中のrectタグ中に`data-tippy-content`というプロパティがありその中にpopoverで表示されるコンテンツが入っている\n\ntippyjs側では特定の属性の内容をツールチップの内容とする仕様になっている\n\n- popoverの中身\n\n頑張って一瞬でコピーした\n\n```html\n<div class=\"tippy-popper\" role=\"tooltip\" id=\"tippy-92\" x-placement=\"top\" style=\"z-index: 9999; visibility: hidden; transition-duration: 0ms; position: absolute; will-change: transform; top: 0px; left: 0px; transform: translate3d(542px, 6020px, 0px);\"><div class=\"tippy-tooltip dark-theme\" data-size=\"regular\" data-animation=\"shift-away\" data-state=\"hidden\" style=\"transition-duration: 275ms; top: 0px;\"><div class=\"tippy-arrow\" style=\"left: 77px;\"></div><div class=\"tippy-content\" data-state=\"hidden\" style=\"transition-duration: 275ms;\"><div>143 views on 2021-09-19</div></div></div></div>\n```\n\n- rect(当日)\n\n```html\n<rect class=\"each-day\" rx=\"2\" ry=\"2\" width=\"10\" height=\"10\" x=\"0\" y=\"0\" fill=\"#d5eaff\" data-count=\"6\" data-date=\"2021-09-19\" data-unit=\"view(s)\" data-retina=\"true\" data-retinaday=\"20210919\" data-index=\"1\" tabindex=\"0\"></rect>\n```\n\n一個不具合というかわからないが当日のデータは`data-tippy-content`にデータが入ってこないっぽい\n\n- rect(昨日以前)\n\n```html\n<rect data-tippy-content=\"6 view(s) on 2021-09-18\" class=\"each-day\" rx=\"2\" ry=\"2\" width=\"10\" height=\"10\" x=\"1\" y=\"72\" fill=\"#d5eaff\" data-count=\"6\" data-date=\"2021-09-18\" data-unit=\"view(s)\" data-retina=\"true\" data-retinaday=\"20210918\" data-index=\"2\" tabindex=\"0\"></rect>\n```\n\nなるほど\n\n## Reactでどうやってツールチップを実現するか\n\ntippyjsを前提としているならreactでtippyjsを使えるようなライブラリがあれば良さそう\n\ntippyjs作者と同じ方がReact用のライブラリも作っているようなのでそれを見にいってREADMEをいくつか試してみた\n\n[atomiks/tippyjs-react: React component for Tippy.js (official)](https://github.com/atomiks/tippyjs-react)\n\n[https://github.com/atomiks/tippyjs-react:embed:cite]\n\ntippyjs単体での使用方法は下記\n\n[Constructor | Tippy.js](https://atomiks.github.io/tippyjs/v6/constructor/)\n\n[https://atomiks.github.io/tippyjs/v6/constructor/:embed:cite]\n\n色々試してみたが力不足のためtippyjs-reactを用いてPixelaのグラフの中のデータをツールチップに表示させるところまで実装できなかった\n\n下記読んで見たissue\n\n[Question - Programmatically create tippies on spans inserted with 'dangerouslySetInnerHTML' · Issue #98 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/98)\n\n[Is there a way to use css selectors like with tippy.js? · Issue #170 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/170)\n\n[Doesn't accept target property · Issue #39 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/39)\n\n`tippy`を呼び出して直接実行することはできそう\n\nということで、useEffect内でtippyを実行するよう試してみたが\n\n```tsx\nimport {tippy} from '@tippyjs/react'\n.....\n.....\n\n  useEffect(() => {\n    tippy('.each-day', {arrow: true})\n  })\n\n.....\n.....\n\nreturn (\n    <>\n      <div>\n        <div className=\"each-day\" data-tippy-content=\"aaaa 1\">a</div>\n        <div className=\"each-day\" data-tippy-content=\"bbbb 1\">b</div>\n        <div className=\"each-day\" data-tippy-content=\"cccc 1\">c</div>\n      </div>\n      <object\n        type=\"image/svg+xml\"\n        data=\"https://pixe.la/v1/users/swfz/graphs/til-pv-dev?mode=short\"\n      ></object>\n    </>\n)\n```\n\nSVGで呼び出した各rectには`each-day`クラスが存在するはずだが反応せず…\n\n同様のCSSクラス名を設定した子要素には反応した\n\nこれはobjectで読み込んだSVGがiframeなどと同様に子コンテンツ扱いされているからのよう\n\n[Doesn't accept target property · Issue #39 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/39)\n\nCSSセレクタで中身を取得したい場合次のような感じで取得できる\n\n```javascript\nconst element = document.querySelector('.selector-in-parent-content').contentWindow.document.querySelector('.selector-in-child-content');\n```\n\nこれをCSSセレクタ一発で取得できるか少し調べたが見つからなかったので断念\n\nということでどうしたもんかなと考えたが次の案くらいしか思い浮かばなかった\n\n## 案1 fetchとdangerouslySetInnerHTMLでSVGのレスポンスをそのまま突っ込む\n- fetchでSVGデータを取得する\n- dangerouslySetInnerHTMLでHTMLを入れ込む\n- jQueryなどでの使用法と同様に`tippy`を実行する\n\nツールチップの要素などは`tippy`が実行してDOM操作する形になるのでReactの管理対象外になるはず\n\nなので正直気持ちの良いものではない\n\n## 案2 fetchとcloneElementなどを使ってDOMを書き換えツールチップを動作させる\n- fetchでSVGデータを取得する\n- cloneElementなどを駆使し、Tippyタグが動作するようにDOMを書き換える\n\n工夫すればできそうだけどsvgの中身まで把握しておかないといけないし結構たいへんそう…\n\n## 案3 objectタグでレンダリングしているSVGの中でtippyjsを実行する\n- そもそもできるのか不明\n\nこのへんまで調べてそんなに時間使えないし案1で良いか…ということで\n\nまずは動かすところまで持っていく!!\n\n結局次のような感じになった\n\n## 案1でやってみた\n\n```typescript\nimport React, { useState, useEffect } from \"react\"\nimport fetch from \"node-fetch\"\nimport { tippy } from \"@tippyjs/react\"\nimport \"tippy.js/dist/tippy.css\"\nimport DOMPurify from \"dompurify\"\n\nconst Pixela = () => {\n  const [pixelaSvg, setPixelaSvg] = useState(\"\")\n\n  useEffect(() => {\n    const fetchPixelaSvg = async () => {\n      const res = await fetch(\n        \"https://pixe.la/v1/users/swfz/graphs/til-pageviews?mode=short\"\n      )\n      const html: string = await res.text()\n\n      setPixelaSvg(DOMPurify.sanitize(html))\n      tippy(\".each-day\", { arrow: true })\n    }\n    fetchPixelaSvg()\n  }, [])\n\n  return (\n    <>\n      <div\n        dangerouslySetInnerHTML={{\n          __html: pixelaSvg,\n        }}\n      ></div>\n      <div\n        style={{\n          textAlign: `right`,\n        }}\n      >\n        Powered by{\" \"}\n        <a href=\"https://pixe.la/\" target=\"_blank\">\n          Pixela\n        </a>\n      </div>\n    </>\n  )\n}\n```\n\n![alt](gatsby_pixela_direct_execution01.png)\n\n### まとめ\n- PixelaのグラフをGatsby(React)で表示してツールチップまで表示できるようにした\n- Reactの中の世界でツールチップを管理することを断念した\n- 他案はまた別な機会で挑戦したい",
          "objectID": "react/gatsby_pixela_direct_execution",
          "_snippetResult": {
            "text": {
              "value": "クをよく読めばiframeで良くないか?という話になるが、今回は__ais-highlight__ms__/ais-highlight__wを使って開発しているときはローカルだけで完結させ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "PixelaのグラフをGatsby製のブログに埋め込む",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2021-10-15",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "react/gatsby_pixela_direct_execution",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/react/gatsby_pixela_direct_execution",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "react/gatsby_pixela_direct_execution",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "React", "matchLevel": "none", "matchedWords": [] },
              { "value": "Gatsby", "matchLevel": "none", "matchedWords": [] },
              { "value": "Pixela", "matchLevel": "none", "matchedWords": [] }
            ],
            "text": {
              "value": "# PixelaのグラフをGatsby製のブログに埋め込む\n\nPixelaのグラフをGatsby(React)で表示させたい\n\n素直にsvgをobjectタグで読み込むだけだとツールチップが表示されないのでせっかくなら表示させたい\n\n<!-- textlint-disable ja-technical-writing/sentence-length -->\n（※前提の参考リンクをよく読めばiframeで良くないか?という話になるが、今回は__ais-highlight__ms__/ais-highlight__wを使って開発しているときはローカルだけで完結させたい、がiframeは__ais-highlight__ms__/ais-highlight__wではモックできないという事情により色々面倒なことをやっている）\n<!-- textlint-enable ja-technical-writing/sentence-length -->\n\nなので完全な自分用のメモである\n\n## 前提知識\n\n[はてなブログに Pixela グラフを埋め込んで、さらにツールチップを表示させる方法 - えいのうにっき](https://blog.a-know.me/entry/2018/11/20/220257)\n\n[https://blog.a-know.me/entry/2018/11/20/220257:embed:cite]\n\nはてなブログへの埋め込み方法は上記\n\npopoverを表示するためのライブラリとして`tippyjs`を使うことを前提としている\n\nPixelaが返すSVGの中のrectタグ中に`data-tippy-content`というプロパティがありその中にpopoverで表示されるコンテンツが入っている\n\ntippyjs側では特定の属性の内容をツールチップの内容とする仕様になっている\n\n- popoverの中身\n\n頑張って一瞬でコピーした\n\n```html\n<div class=\"tippy-popper\" role=\"tooltip\" id=\"tippy-92\" x-placement=\"top\" style=\"z-index: 9999; visibility: hidden; transition-duration: 0ms; position: absolute; will-change: transform; top: 0px; left: 0px; transform: translate3d(542px, 6020px, 0px);\"><div class=\"tippy-tooltip dark-theme\" data-size=\"regular\" data-animation=\"shift-away\" data-state=\"hidden\" style=\"transition-duration: 275ms; top: 0px;\"><div class=\"tippy-arrow\" style=\"left: 77px;\"></div><div class=\"tippy-content\" data-state=\"hidden\" style=\"transition-duration: 275ms;\"><div>143 views on 2021-09-19</div></div></div></div>\n```\n\n- rect(当日)\n\n```html\n<rect class=\"each-day\" rx=\"2\" ry=\"2\" width=\"10\" height=\"10\" x=\"0\" y=\"0\" fill=\"#d5eaff\" data-count=\"6\" data-date=\"2021-09-19\" data-unit=\"view(s)\" data-retina=\"true\" data-retinaday=\"20210919\" data-index=\"1\" tabindex=\"0\"></rect>\n```\n\n一個不具合というかわからないが当日のデータは`data-tippy-content`にデータが入ってこないっぽい\n\n- rect(昨日以前)\n\n```html\n<rect data-tippy-content=\"6 view(s) on 2021-09-18\" class=\"each-day\" rx=\"2\" ry=\"2\" width=\"10\" height=\"10\" x=\"1\" y=\"72\" fill=\"#d5eaff\" data-count=\"6\" data-date=\"2021-09-18\" data-unit=\"view(s)\" data-retina=\"true\" data-retinaday=\"20210918\" data-index=\"2\" tabindex=\"0\"></rect>\n```\n\nなるほど\n\n## Reactでどうやってツールチップを実現するか\n\ntippyjsを前提としているならreactでtippyjsを使えるようなライブラリがあれば良さそう\n\ntippyjs作者と同じ方がReact用のライブラリも作っているようなのでそれを見にいってREADMEをいくつか試してみた\n\n[atomiks/tippyjs-react: React component for Tippy.js (official)](https://github.com/atomiks/tippyjs-react)\n\n[https://github.com/atomiks/tippyjs-react:embed:cite]\n\ntippyjs単体での使用方法は下記\n\n[Constructor | Tippy.js](https://atomiks.github.io/tippyjs/v6/constructor/)\n\n[https://atomiks.github.io/tippyjs/v6/constructor/:embed:cite]\n\n色々試してみたが力不足のためtippyjs-reactを用いてPixelaのグラフの中のデータをツールチップに表示させるところまで実装できなかった\n\n下記読んで見たissue\n\n[Question - Programmatically create tippies on spans inserted with 'dangerouslySetInnerHTML' · Issue #98 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/98)\n\n[Is there a way to use css selectors like with tippy.js? · Issue #170 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/170)\n\n[Doesn't accept target property · Issue #39 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/39)\n\n`tippy`を呼び出して直接実行することはできそう\n\nということで、useEffect内でtippyを実行するよう試してみたが\n\n```tsx\nimport {tippy} from '@tippyjs/react'\n.....\n.....\n\n  useEffect(() => {\n    tippy('.each-day', {arrow: true})\n  })\n\n.....\n.....\n\nreturn (\n    <>\n      <div>\n        <div className=\"each-day\" data-tippy-content=\"aaaa 1\">a</div>\n        <div className=\"each-day\" data-tippy-content=\"bbbb 1\">b</div>\n        <div className=\"each-day\" data-tippy-content=\"cccc 1\">c</div>\n      </div>\n      <object\n        type=\"image/svg+xml\"\n        data=\"https://pixe.la/v1/users/swfz/graphs/til-pv-dev?mode=short\"\n      ></object>\n    </>\n)\n```\n\nSVGで呼び出した各rectには`each-day`クラスが存在するはずだが反応せず…\n\n同様のCSSクラス名を設定した子要素には反応した\n\nこれはobjectで読み込んだSVGがiframeなどと同様に子コンテンツ扱いされているからのよう\n\n[Doesn't accept target property · Issue #39 · atomiks/tippyjs-react](https://github.com/atomiks/tippyjs-react/issues/39)\n\nCSSセレクタで中身を取得したい場合次のような感じで取得できる\n\n```javascript\nconst element = document.querySelector('.selector-in-parent-content').contentWindow.document.querySelector('.selector-in-child-content');\n```\n\nこれをCSSセレクタ一発で取得できるか少し調べたが見つからなかったので断念\n\nということでどうしたもんかなと考えたが次の案くらいしか思い浮かばなかった\n\n## 案1 fetchとdangerouslySetInnerHTMLでSVGのレスポンスをそのまま突っ込む\n- fetchでSVGデータを取得する\n- dangerouslySetInnerHTMLでHTMLを入れ込む\n- jQueryなどでの使用法と同様に`tippy`を実行する\n\nツールチップの要素などは`tippy`が実行してDOM操作する形になるのでReactの管理対象外になるはず\n\nなので正直気持ちの良いものではない\n\n## 案2 fetchとcloneElementなどを使ってDOMを書き換えツールチップを動作させる\n- fetchでSVGデータを取得する\n- cloneElementなどを駆使し、Tippyタグが動作するようにDOMを書き換える\n\n工夫すればできそうだけどsvgの中身まで把握しておかないといけないし結構たいへんそう…\n\n## 案3 objectタグでレンダリングしているSVGの中でtippyjsを実行する\n- そもそもできるのか不明\n\nこのへんまで調べてそんなに時間使えないし案1で良いか…ということで\n\nまずは動かすところまで持っていく!!\n\n結局次のような感じになった\n\n## 案1でやってみた\n\n```typescript\nimport React, { useState, useEffect } from \"react\"\nimport fetch from \"node-fetch\"\nimport { tippy } from \"@tippyjs/react\"\nimport \"tippy.js/dist/tippy.css\"\nimport DOMPurify from \"dompurify\"\n\nconst Pixela = () => {\n  const [pixelaSvg, setPixelaSvg] = useState(\"\")\n\n  useEffect(() => {\n    const fetchPixelaSvg = async () => {\n      const res = await fetch(\n        \"https://pixe.la/v1/users/swfz/graphs/til-pageviews?mode=short\"\n      )\n      const html: string = await res.text()\n\n      setPixelaSvg(DOMPurify.sanitize(html))\n      tippy(\".each-day\", { arrow: true })\n    }\n    fetchPixelaSvg()\n  }, [])\n\n  return (\n    <>\n      <div\n        dangerouslySetInnerHTML={{\n          __html: pixelaSvg,\n        }}\n      ></div>\n      <div\n        style={{\n          textAlign: `right`,\n        }}\n      >\n        Powered by{\" \"}\n        <a href=\"https://pixe.la/\" target=\"_blank\">\n          Pixela\n        </a>\n      </div>\n    </>\n  )\n}\n```\n\n![alt](gatsby_pixela_direct_execution01.png)\n\n### まとめ\n- PixelaのグラフをGatsby(React)で表示してツールチップまで表示できるようにした\n- Reactの中の世界でツールチップを管理することを断念した\n- 他案はまた別な機会で挑戦したい",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        },
        {
          "title": "じぶん Release Notes (ver 0.35.0)",
          "date": "2022-10-09",
          "slug": "release_notes/2022_10-0_35_0",
          "url": "http://localhost:8001/release_notes/2022_10-0_35_0",
          "section": "release_notes/2022_10-0_35_0",
          "tags": ["じぶんリリースノート"],
          "text": "# じぶん Release Notes (ver 0.35.0)\n\nswfz (ver 0.35.0) がリリースされました、更新内容は次のとおりです\n\n## 技術\n\n### やったこと\n- プライベートのブログ環境のmkdocs更新\n- [kusa](https://tools.swfz.io/kusa)関連\n    - Renovate,dependabot系のアクティビティを除けるようにした\n    - octiconを入れた\n    - コメント系イベントを表示できるようにした\n- 既存のprivateのActionsでGCP(bq, gsutil)を使っている箇所をOIDCで実行できるようにした\n- [article-search](https://github.com/swfz/article-search)\n    - テストコードを書いた\n    - mswを入れた\n    - Cloudflareにデプロイした\n    - CloudflareAccessで制限を掛けた\n\n## 読んだ本\n\n- インプット大全(Audible)\n\n<iframe sandbox=\"allow-popups allow-scripts allow-modals allow-forms allow-same-origin\" style=\"width:120px;height:240px;\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" frameborder=\"0\" src=\"//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=swfz-22&language=ja_JP&o=9&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=B07SR28M94&linkId=92ee63e16420b14a37b1a8e77d74991d\"></iframe>\n\n## 勉強会\n\nなし\n\n## ブログ\n\nリリースノートを除き、次の3エントリを書いた\n\n- [BigQueryにAPIのデータを定期的に同期して、削除されたレコードを検出する](https://swfz.hatenablog.com/entry/2022/09/09/203039)\n- [CloudFlare Access + Pagesで自分のみアクセスできるようにする](https://swfz.hatenablog.com/entry/2022/09/30/193552)\n- [VS Code Markdown CheckboxプラグインでToDo管理](https://swfz.hatenablog.com/entry/2022/09/21/190153)\n\n### 指標\n\n購読者数： 76(`+0`)\n\n月間PV： 8482(`-108`)\n\nはてなブックマーク： 1108(`+1`)\n\nいつも通りって感じ\n\n## 生活\n\n色々でかけた\n\n<!-- textlint-disable jtf-style/2.1.2.漢字 -->\n黒たまごを食べるためだけに大涌谷へいったり\n<!-- textlint-enable prh -->\n\nソラマチでプラネタリウム見たり\n\nあとは、まだ歯の治療が終わらない…\n\n担当が日曜だけしかいないようで予定合わないと平気で1ヵ月空いたりするので全然進まない\n\nそろそろ焼肉を何も気にせず食べたい…\n\n## 仕事\n\nQの末なので目標振り返りやら金額の話だったり締め的な仕事が多かった\n\n組織の目標の金額の集計だったりレポートだったりを自分で作業したので状況把握という意味だと今まで以上に解像度は上がった\n\nそして実際にやってみるとコスト意識は高まる?かなと感じた\n\n今までふんわり認識していた部分が具体的数値として認識でき「この金額ってこんなに掛かっているのか！」という気付きが多かった\n\n恥ずかしい話あんまりそういうところ意識してこなかったなというのが正直なところだったのでやってよかった\n\nただ、あまり整備されているわけではないのでかなり手作業が多くたいへんだった\n\n今後は効率化する予定\n\n### 有給消化した\n\n9月終わったら消えてしまう有給が残り1.5日というところまで消化した\n\n今までかなりの日数のこしてしまっていて結局使わず消滅させてしまっていたが今回はなるべく消化することにした\n\n結果かなり消化できたが仕事は進まなかった\n\nそのぶんプライベートでコードを結構書けたのでそれはそれで良かった\n\n## 時間の使い方\n\n直近半年の勉強の指標は次のような感じ\n\n| 月          |    平均 |   前月比 |\n| :--------- | ----: | ----: |\n| 2022-04-01 | 2.35h | +0.16 |\n| 2022-05-01 |  3.0h | +0.65 |\n| 2022-06-01 | 2.55h | -0.46 |\n| 2022-07-01 | 3.98h | +1.43 |\n| 2022-08-01 | 3.56h | -0.42 |\n| 2022-09-01 | 3.18h | -0.37 |\n\n直近3ヵ月くらいは有給消化があったためある程度時間確保できたが10月以降もこのペースで行けるか不安が残る…\n\n直近半年の睡眠の指標は次のような感じ\n\n| 月          |    平均 |   前月比 | 標準偏差 |\n| :--------- | ----: | ----: | ---: |\n| 2022-04-01 | 6.61h | -0.23 | 1.65 |\n| 2022-05-01 | 6.13h | -0.48 | 2.01 |\n| 2022-06-01 | 6.28h | +0.15 | 1.68 |\n| 2022-07-01 | 6.24h | -0.04 | 1.89 |\n| 2022-08-01 | 6.33h | +0.09 | 1.61 |\n| 2022-09-01 | 6.26h | -0.07 |  1.9 |\n\n## 振り返り\n\n### K\n- コード書く時間はそれなりに取れた\n- ステッパーは引き続き続けられている\n- ある程度有給消化できた\n- GitHubの草継続して毎日生やすことができている\n- 毎日の振り返り週間はできているかどうかをいったん可視化した\n\n### P\n- 引き続き気持ちがのらずぐだっている\n- 筋トレできていない\n- やろうとしてタスクに積んだあと崩せていない\n- Pocketに積むだけ積んだ後読んでいない\n- 毎日その日中に振り返りできていない(56%)\n\n### T\n- 筋トレの習慣化再考\n- 本読む時間を増やす\n- 新しい刺激になることをやる\n- 何か1つ決めてタスクを崩す機会と時間を作る\n- Pocket積読は目標決めて取り組む\n",
          "objectID": "release_notes/2022_10-0_35_0",
          "_snippetResult": {
            "text": {
              "value": "きるようにした\n- [article-search](https://github.com/swfz/article-search)\n    - テストコードを書いた\n    - __ais-highlight__ms__/ais-highlight__wを入れた\n    - Cloudflareにデプロイした\n    - CloudflareAccessで制限を掛けた\n\n## 読んだ本",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "じぶん Release Notes (ver 0.35.0)",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2022-10-09",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "release_notes/2022_10-0_35_0",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/release_notes/2022_10-0_35_0",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "release_notes/2022_10-0_35_0",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "じぶんリリースノート",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "text": {
              "value": "# じぶん Release Notes (ver 0.35.0)\n\nswfz (ver 0.35.0) がリリースされました、更新内容は次のとおりです\n\n## 技術\n\n### やったこと\n- プライベートのブログ環境のmkdocs更新\n- [kusa](https://tools.swfz.io/kusa)関連\n    - Renovate,dependabot系のアクティビティを除けるようにした\n    - octiconを入れた\n    - コメント系イベントを表示できるようにした\n- 既存のprivateのActionsでGCP(bq, gsutil)を使っている箇所をOIDCで実行できるようにした\n- [article-search](https://github.com/swfz/article-search)\n    - テストコードを書いた\n    - __ais-highlight__ms__/ais-highlight__wを入れた\n    - Cloudflareにデプロイした\n    - CloudflareAccessで制限を掛けた\n\n## 読んだ本\n\n- インプット大全(Audible)\n\n<iframe sandbox=\"allow-popups allow-scripts allow-modals allow-forms allow-same-origin\" style=\"width:120px;height:240px;\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" frameborder=\"0\" src=\"//rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=swfz-22&language=ja_JP&o=9&p=8&l=as4&m=amazon&f=ifr&ref=as_ss_li_til&asins=B07SR28M94&linkId=92ee63e16420b14a37b1a8e77d74991d\"></iframe>\n\n## 勉強会\n\nなし\n\n## ブログ\n\nリリースノートを除き、次の3エントリを書いた\n\n- [BigQueryにAPIのデータを定期的に同期して、削除されたレコードを検出する](https://swfz.hatenablog.com/entry/2022/09/09/203039)\n- [CloudFlare Access + Pagesで自分のみアクセスできるようにする](https://swfz.hatenablog.com/entry/2022/09/30/193552)\n- [VS Code Markdown CheckboxプラグインでToDo管理](https://swfz.hatenablog.com/entry/2022/09/21/190153)\n\n### 指標\n\n購読者数： 76(`+0`)\n\n月間PV： 8482(`-108`)\n\nはてなブックマーク： 1108(`+1`)\n\nいつも通りって感じ\n\n## 生活\n\n色々でかけた\n\n<!-- textlint-disable jtf-style/2.1.2.漢字 -->\n黒たまごを食べるためだけに大涌谷へいったり\n<!-- textlint-enable prh -->\n\nソラマチでプラネタリウム見たり\n\nあとは、まだ歯の治療が終わらない…\n\n担当が日曜だけしかいないようで予定合わないと平気で1ヵ月空いたりするので全然進まない\n\nそろそろ焼肉を何も気にせず食べたい…\n\n## 仕事\n\nQの末なので目標振り返りやら金額の話だったり締め的な仕事が多かった\n\n組織の目標の金額の集計だったりレポートだったりを自分で作業したので状況把握という意味だと今まで以上に解像度は上がった\n\nそして実際にやってみるとコスト意識は高まる?かなと感じた\n\n今までふんわり認識していた部分が具体的数値として認識でき「この金額ってこんなに掛かっているのか！」という気付きが多かった\n\n恥ずかしい話あんまりそういうところ意識してこなかったなというのが正直なところだったのでやってよかった\n\nただ、あまり整備されているわけではないのでかなり手作業が多くたいへんだった\n\n今後は効率化する予定\n\n### 有給消化した\n\n9月終わったら消えてしまう有給が残り1.5日というところまで消化した\n\n今までかなりの日数のこしてしまっていて結局使わず消滅させてしまっていたが今回はなるべく消化することにした\n\n結果かなり消化できたが仕事は進まなかった\n\nそのぶんプライベートでコードを結構書けたのでそれはそれで良かった\n\n## 時間の使い方\n\n直近半年の勉強の指標は次のような感じ\n\n| 月          |    平均 |   前月比 |\n| :--------- | ----: | ----: |\n| 2022-04-01 | 2.35h | +0.16 |\n| 2022-05-01 |  3.0h | +0.65 |\n| 2022-06-01 | 2.55h | -0.46 |\n| 2022-07-01 | 3.98h | +1.43 |\n| 2022-08-01 | 3.56h | -0.42 |\n| 2022-09-01 | 3.18h | -0.37 |\n\n直近3ヵ月くらいは有給消化があったためある程度時間確保できたが10月以降もこのペースで行けるか不安が残る…\n\n直近半年の睡眠の指標は次のような感じ\n\n| 月          |    平均 |   前月比 | 標準偏差 |\n| :--------- | ----: | ----: | ---: |\n| 2022-04-01 | 6.61h | -0.23 | 1.65 |\n| 2022-05-01 | 6.13h | -0.48 | 2.01 |\n| 2022-06-01 | 6.28h | +0.15 | 1.68 |\n| 2022-07-01 | 6.24h | -0.04 | 1.89 |\n| 2022-08-01 | 6.33h | +0.09 | 1.61 |\n| 2022-09-01 | 6.26h | -0.07 |  1.9 |\n\n## 振り返り\n\n### K\n- コード書く時間はそれなりに取れた\n- ステッパーは引き続き続けられている\n- ある程度有給消化できた\n- GitHubの草継続して毎日生やすことができている\n- 毎日の振り返り週間はできているかどうかをいったん可視化した\n\n### P\n- 引き続き気持ちがのらずぐだっている\n- 筋トレできていない\n- やろうとしてタスクに積んだあと崩せていない\n- Pocketに積むだけ積んだ後読んでいない\n- 毎日その日中に振り返りできていない(56%)\n\n### T\n- 筋トレの習慣化再考\n- 本読む時間を増やす\n- 新しい刺激になることをやる\n- 何か1つ決めてタスクを崩す機会と時間を作る\n- Pocket積読は目標決めて取り組む\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        },
        {
          "title": "gitをソースコードからインストールする",
          "date": "2016-03-31",
          "slug": "git/install_source",
          "url": "http://localhost:8001/git/install_source",
          "section": "git/install_source",
          "tags": ["Git"],
          "text": "# Gitをソースコードからインストールする\n\nCentOC6系だとyumからインストールできるGitのバージョンが1.7...\n\nすでに最新は2.7とかなり離れているのでいろいろ使えないオプションがあったり…。\n\nということでソースからインストール\n\n下記からソースを取得\n\n[https://www.kernel.org/pub/software/scm/git/](https://www.kernel.org/pub/software/scm/git/)\n\n```\nwget https://www.kernel.org/pub/software/scm/git/git-2.7.4.tar.gz\ncd git-2.7.4\n./configure\nmake\n```\n\nエラーが出ました\n\n```\n/usr/bin/perl Makefile.PL PREFIX='/usr/local' INSTALL_BASE='' --localedir='/usr/local/share/locale'\nCan't locate ExtUtils/MakeMaker.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at Makefile.PL line 3.\nBEGIN failed--compilation aborted at Makefile.PL line 3.\nmake[1]: *** [perl.mak] Error 2\nmake: *** [perl/perl.mak] Error 2\n```\n\nPerlモジュールがないようなのでインストールします\n\n```\nyum install perl-ExtUtils-MakeMaker\n```\n再度make\n\n```\n/bin/sh: msgfmt: command not found\nmake: *** [po/build/locale/bg/LC_MESSAGES/git.mo] Error 127\n```\n\nまたもエラー、今度はgettextというパッケージ\n\n```\nyum install gettext\n```\n\n今度は無事インストールできました\n\n```\nmake\nmake install\n```\n\nこれでOK\n\n\n",
          "objectID": "git/install_source",
          "_snippetResult": {
            "text": {
              "value": "いようなのでインストールします\n\n```\nyum install perl-ExtUtils-MakeMaker\n```\n再度make\n\n```\n/bin/sh: __ais-highlight__ms__/ais-highlight__gfmt: command not found\nmake: *** [po/build/locale/bg/LC_MESSAGES/git.mo] Error 127\n```\n\nまたもエラー、今度はgettext",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "gitをソースコードからインストールする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2016-03-31",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "git/install_source",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/git/install_source",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "git/install_source",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Git", "matchLevel": "none", "matchedWords": [] }
            ],
            "text": {
              "value": "# Gitをソースコードからインストールする\n\nCentOC6系だとyumからインストールできるGitのバージョンが1.7...\n\nすでに最新は2.7とかなり離れているのでいろいろ使えないオプションがあったり…。\n\nということでソースからインストール\n\n下記からソースを取得\n\n[https://www.kernel.org/pub/software/scm/git/](https://www.kernel.org/pub/software/scm/git/)\n\n```\nwget https://www.kernel.org/pub/software/scm/git/git-2.7.4.tar.gz\ncd git-2.7.4\n./configure\nmake\n```\n\nエラーが出ました\n\n```\n/usr/bin/perl Makefile.PL PREFIX='/usr/local' INSTALL_BASE='' --localedir='/usr/local/share/locale'\nCan't locate ExtUtils/MakeMaker.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at Makefile.PL line 3.\nBEGIN failed--compilation aborted at Makefile.PL line 3.\nmake[1]: *** [perl.mak] Error 2\nmake: *** [perl/perl.mak] Error 2\n```\n\nPerlモジュールがないようなのでインストールします\n\n```\nyum install perl-ExtUtils-MakeMaker\n```\n再度make\n\n```\n/bin/sh: __ais-highlight__ms__/ais-highlight__gfmt: command not found\nmake: *** [po/build/locale/bg/LC_MESSAGES/git.mo] Error 127\n```\n\nまたもエラー、今度はgettextというパッケージ\n\n```\nyum install gettext\n```\n\n今度は無事インストールできました\n\n```\nmake\nmake install\n```\n\nこれでOK\n\n\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        },
        {
          "title": "apexを使ってlambda functionの管理",
          "date": "2016-06-15",
          "slug": "aws/apex_lambda",
          "url": "http://localhost:8001/aws/apex_lambda",
          "section": "aws/apex_lambda",
          "tags": ["AWS"],
          "text": "# apexを使ってlambda functionの管理\n\nserverlessとapexがあるようですがなんとなくapexを使ってみます\n\n[apex/apex: Build, deploy, and manage AWS Lambda functions with ease.](https://github.com/apex/apex)\n\n# インストール\n\n```\ncurl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh\n```\n\n# プロジェクトの作成\n\n```\napex init\n  Enter the name of your project. It should be machine-friendly, as this\n  is used to prefix your functions in Lambda.\n\n    Project name: sample\n\n  Enter an optional description of your project.\n\n    Project description: sample function\n\n  Would you like to manage infrastructure with Terraform? (yes/no) no\n\n  Enter IAM role used by Lambda functions.\n\n    IAM role: arn:aws:iam::111111111111:role/lambda_dynamo_streams\n  [+] creating ./project.json\n  [+] creating ./functions\n\n  Setup complete!\n\n  Next step:\n    - apex deploy - deploy example function\n```\n\nそれぞれ入力していきます\n\n- プロジェクト名\n- 説明\n- IAM role\n\n# 認証情報を設定する\n\n`~/.aws/config`, `~/.aws/credentials`に情報を設定する\n\n\n# デプロイ\n\n```\napex --profile swfz --region ap-northeast-1 deploy\n   • creating function         function=hello\n   • created alias current     function=hello version=1\n   • function created          function=hello name=sample_hello version=1\n\n```\n\n# 実行\n\nlambdaでのイベントソースを`event.json`に記述して実行してみる\n\n```\napex --profile swfz --region ap-northeast-1 invoke hello < event.json\n{\"hello\":\"world\"}\n```\n\n# ログ\n\n```\n$ apex --profile swfz --region ap-northeast-1 logs hello\n/aws/lambda/sample_hello 2016-05-27T15:12:28.460Z       k1ciy2kwf2lzbiex        starting function\n/aws/lambda/sample_hello START RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0 Version: 1\n/aws/lambda/sample_hello 2016-05-27T15:12:28.480Z       6c72c10e-241d-11e6-9db7-cde4beb156f0    processing event: {\"hello\":\"world\"}\n/aws/lambda/sample_hello 2016-05-27T15:12:28.482Z       6c72c10e-241d-11e6-9db7-cde4beb156f0    TypeError: undefined is not a function\n    at exports.handle (/var/task/index.js:4:3)\n/aws/lambda/sample_hello END RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0\n/aws/lambda/sample_hello REPORT RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0 Duration: 98.27 ms      Billed Duration: 100 ms         Memory Size: 128 MB     Max Memory Used: 31 MB\n/aws/lambda/sample_hello Process exited before completing request\n\n/aws/lambda/sample_hello 2016-05-27T15:13:46.444Z       hjicp0nm6diweaxj        starting function\n/aws/lambda/sample_hello START RequestId: 9b833e6c-241d-11e6-89f8-6f4d3cf57009 Version: 2\n/aws/lambda/sample_hello 2016-05-27T15:13:46.460Z       9b833e6c-241d-11e6-89f8-6f4d3cf57009    processing event: {\"hello\":\"world\"}\n/aws/lambda/sample_hello END RequestId: 9b833e6c-241d-11e6-89f8-6f4d3cf57009\n/aws/lambda/sample_hello REPORT RequestId: 9b833e6c-241d-11e6-89f8-6f4d3cf57009 Duration: 15.14 ms      Billed Duration: 100 ms         Memory Size: 128 MB     Max Memory Used: 13 MB\n```\n\n# メトリクス\n\n```\n$ apex --profile swfz --region ap-northeast-1 metrics hello\n\n  hello\n    total cost: $0.00\n    invocations: 2 ($0.00)\n    duration: 113ms ($0.00)\n    throttles: 0\n    errors: 1\n    memory: 128\n```\n\n費用も確認できる模様!\n\n# プロジェクトをデプロイしてみる\n\nある程度触ってみたので実際のプロジェクトをデプロイしてみます\n\n今回は自分のTwitterのタイムラインをslackに流すだけのfunctionです\n\n## timeline2slack\n- 15分ごとにfunctionを実行\n- 最後に流したツイートのIDをDynamoDBに保存\n    - 次回実行時に差分のみslackに流す\n\n![timeline2slack](apex_lambda04.png)\n\n[swfz/timeline2slack](https://github.com/swfz/timeline2slack) を `functions/timeline`ディレクトリに配置します\n\n```\n$ git clone https://github.com/swfz/timeline2slack.git functions/timeline\n```\n\n## 設定を変更\n\n単体で実行していたときと比べて下記設定が必要なので追加\n\n- sample.js\n    - lambda funcgtion実行時に`exports.handle`で設定した関数が呼ばれるので関数呼び出し部分を追加\n    - context.succeedを追加\n\n```\n+ exports.handle = function(event, context) {\n.....\n.....\n+ context.succeed(\"success\")\n.....\n.....\n+ }\n```\n\n## 中身を見てみる\n\n実際にどんなファイルがアップロードされているのか`apex build`でzipを取得して確認します\n\n```\n$ apex build timeline > /tmp/out.zip\n$ cd ../\n$ unzip /tmp/out.zip\n$ ls\nREADME.md _apex_index.js config/  node_modules/  package.json  sample.js\n```\n\nインストールしたモジュールが`node_modules`に入っている\n\nさらに、プロジェクトのファイルに追加して`_apex_index.js`というファイルが増えています\n\n_apex_index.jsの中身を見てみると\n\n```\ntry {\n  var config = require('./.env.json')\n  for (var key in config) {\n    process.env[key] = config[key]\n  }\n} catch (err) {\n  // ignore\n}\n\nexports.handle = require('./index').handle\n```\n\nこのようになっていました\n\n![text](apex_lambda01.PNG)\n\n設定のhandlerの箇所とひもづいています\n\nなのでsample.jsをindex.jsに変更し、exports.handleを加える、もしくは設定できれば設定で解決すればよいですね\n\n今回はfunction.jsonを変えました\n\n- function.json\n```\n{\n  description: twitter to slack function,\n  runtime: nodejs4.3,\n  timeout: 300,\n  handler: sample.handle\n}\n```\n\n## DynamoDB\n\ndynamoDBは事前にテーブルを作っておきますが、特に難しいことはないので今回は割愛します\n\n## デプロイ、確認\n\n```\napex --profile swfz --region ap-northeast-1 deploy\napex --profile swfz --region ap-northeast-1 invoke timeline\napex --profile swfz --region ap-northeast-1 logs -f\n```\n\n今回はevent sourceとして何かデータが必要なわけではないのでjsonファイルは用意しません\n\nlogを見ながら処理がされているか確認する\n\n```\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:31.703Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    736278495840632800\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:31.941Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    736585313405931500\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:33.303Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    {}\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.041Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:07:23 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:29:02 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.061Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:40:56 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:45:27 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.160Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:30:15 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:33:06 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.161Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:33:06 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:37:25 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.161Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:10:32 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:25:01 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.393Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:25:43 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:28:27 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.399Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:37:25 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:49:58 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.410Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:35:34 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:39:56 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.493Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:47:36 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:01:18 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.533Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:28:40 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:35:34 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline END RequestId: 730e56dd-24ec-11e6-a70a-13fd412f23fe\n/aws/lambda/twitter2slack_timeline REPORT RequestId: 730e56dd-24ec-11e6-a70a-13fd412f23fe     Duration: 9344.78 ms    Billed Duration: 9400 ms    Memory Size: 128 MB     Max Memory Used: 66 MB\n```\n\n成功!\n\n## Event Sourceの設定\n\nlambda functionの定期実行なのでcloudwatch eventsの設定をします\n\n`Add Event Source`タブをクリックして設定します\n\n![text](apex_lambda02.PNG)\n\n今回は`15分ごとに実行する`を選択しました\n\ncrontabと同様の記述もできるのでより細かなスケジューリングも可能\n\n\n## 確認\n\n最後に、Slackにpostされているのを確認して完了!\n\n![text](apex_lambda03.PNG)\n\n# まとめ\n## apex\n- 特に難しいことはなかった\n- logまで出してくれるのでデプロイ後の確認しやすい\n- buildコマンドで確認できるのが便利\n- 試してないもの\n    - rollback\n    - apex infra (terraform). これでEventSource,DynamoDBの構築まで行えるようにできたら完璧ですね\n\n以前マネジメントコンソールでコード書いて確認して…といったフローでlambda functionを作成していたのでそれに比べてとても楽に管理できるなと思いました\n\nlambdaに関する設定関連もjsonで管理できてしまうのですべてバージョン管理しておけばさらに管理しやすそう\n\n試してないものに関しても今後試していきたいです\n\n[swfz/twitter2slack: lambda functions in twitter to slack. managed by apex.](https://github.com/swfz/twitter2slack)\n\n\n",
          "objectID": "aws/apex_lambda",
          "_snippetResult": {
            "text": {
              "value": "aws/lambda/sample_hello END RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0\n/aws/lambda/sample_hello REPORT RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0 Duration: 98.27 __ais-highlight__ms__/ais-highlight__      Billed Duration: 100 __ais-highlight__ms__/ais-highlight__         Memory Size: 128 MB     Max Memory Used: 31 MB\n/aws/lambda/sample_hello Process exited before completing request\n\n/aws/lambda",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "apexを使ってlambda functionの管理",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2016-06-15",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "aws/apex_lambda",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/aws/apex_lambda",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "aws/apex_lambda",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "AWS", "matchLevel": "none", "matchedWords": [] }
            ],
            "text": {
              "value": "# apexを使ってlambda functionの管理\n\nserverlessとapexがあるようですがなんとなくapexを使ってみます\n\n[apex/apex: Build, deploy, and manage AWS Lambda functions with ease.](https://github.com/apex/apex)\n\n# インストール\n\n```\ncurl https://raw.githubusercontent.com/apex/apex/master/install.sh | sh\n```\n\n# プロジェクトの作成\n\n```\napex init\n  Enter the name of your project. It should be machine-friendly, as this\n  is used to prefix your functions in Lambda.\n\n    Project name: sample\n\n  Enter an optional description of your project.\n\n    Project description: sample function\n\n  Would you like to manage infrastructure with Terraform? (yes/no) no\n\n  Enter IAM role used by Lambda functions.\n\n    IAM role: arn:aws:iam::111111111111:role/lambda_dynamo_streams\n  [+] creating ./project.json\n  [+] creating ./functions\n\n  Setup complete!\n\n  Next step:\n    - apex deploy - deploy example function\n```\n\nそれぞれ入力していきます\n\n- プロジェクト名\n- 説明\n- IAM role\n\n# 認証情報を設定する\n\n`~/.aws/config`, `~/.aws/credentials`に情報を設定する\n\n\n# デプロイ\n\n```\napex --profile swfz --region ap-northeast-1 deploy\n   • creating function         function=hello\n   • created alias current     function=hello version=1\n   • function created          function=hello name=sample_hello version=1\n\n```\n\n# 実行\n\nlambdaでのイベントソースを`event.json`に記述して実行してみる\n\n```\napex --profile swfz --region ap-northeast-1 invoke hello < event.json\n{\"hello\":\"world\"}\n```\n\n# ログ\n\n```\n$ apex --profile swfz --region ap-northeast-1 logs hello\n/aws/lambda/sample_hello 2016-05-27T15:12:28.460Z       k1ciy2kwf2lzbiex        starting function\n/aws/lambda/sample_hello START RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0 Version: 1\n/aws/lambda/sample_hello 2016-05-27T15:12:28.480Z       6c72c10e-241d-11e6-9db7-cde4beb156f0    processing event: {\"hello\":\"world\"}\n/aws/lambda/sample_hello 2016-05-27T15:12:28.482Z       6c72c10e-241d-11e6-9db7-cde4beb156f0    TypeError: undefined is not a function\n    at exports.handle (/var/task/index.js:4:3)\n/aws/lambda/sample_hello END RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0\n/aws/lambda/sample_hello REPORT RequestId: 6c72c10e-241d-11e6-9db7-cde4beb156f0 Duration: 98.27 __ais-highlight__ms__/ais-highlight__      Billed Duration: 100 __ais-highlight__ms__/ais-highlight__         Memory Size: 128 MB     Max Memory Used: 31 MB\n/aws/lambda/sample_hello Process exited before completing request\n\n/aws/lambda/sample_hello 2016-05-27T15:13:46.444Z       hjicp0nm6diweaxj        starting function\n/aws/lambda/sample_hello START RequestId: 9b833e6c-241d-11e6-89f8-6f4d3cf57009 Version: 2\n/aws/lambda/sample_hello 2016-05-27T15:13:46.460Z       9b833e6c-241d-11e6-89f8-6f4d3cf57009    processing event: {\"hello\":\"world\"}\n/aws/lambda/sample_hello END RequestId: 9b833e6c-241d-11e6-89f8-6f4d3cf57009\n/aws/lambda/sample_hello REPORT RequestId: 9b833e6c-241d-11e6-89f8-6f4d3cf57009 Duration: 15.14 __ais-highlight__ms__/ais-highlight__      Billed Duration: 100 __ais-highlight__ms__/ais-highlight__         Memory Size: 128 MB     Max Memory Used: 13 MB\n```\n\n# メトリクス\n\n```\n$ apex --profile swfz --region ap-northeast-1 metrics hello\n\n  hello\n    total cost: $0.00\n    invocations: 2 ($0.00)\n    duration: 113ms ($0.00)\n    throttles: 0\n    errors: 1\n    memory: 128\n```\n\n費用も確認できる模様!\n\n# プロジェクトをデプロイしてみる\n\nある程度触ってみたので実際のプロジェクトをデプロイしてみます\n\n今回は自分のTwitterのタイムラインをslackに流すだけのfunctionです\n\n## timeline2slack\n- 15分ごとにfunctionを実行\n- 最後に流したツイートのIDをDynamoDBに保存\n    - 次回実行時に差分のみslackに流す\n\n![timeline2slack](apex_lambda04.png)\n\n[swfz/timeline2slack](https://github.com/swfz/timeline2slack) を `functions/timeline`ディレクトリに配置します\n\n```\n$ git clone https://github.com/swfz/timeline2slack.git functions/timeline\n```\n\n## 設定を変更\n\n単体で実行していたときと比べて下記設定が必要なので追加\n\n- sample.js\n    - lambda funcgtion実行時に`exports.handle`で設定した関数が呼ばれるので関数呼び出し部分を追加\n    - context.succeedを追加\n\n```\n+ exports.handle = function(event, context) {\n.....\n.....\n+ context.succeed(\"success\")\n.....\n.....\n+ }\n```\n\n## 中身を見てみる\n\n実際にどんなファイルがアップロードされているのか`apex build`でzipを取得して確認します\n\n```\n$ apex build timeline > /tmp/out.zip\n$ cd ../\n$ unzip /tmp/out.zip\n$ ls\nREADME.md _apex_index.js config/  node_modules/  package.json  sample.js\n```\n\nインストールしたモジュールが`node_modules`に入っている\n\nさらに、プロジェクトのファイルに追加して`_apex_index.js`というファイルが増えています\n\n_apex_index.jsの中身を見てみると\n\n```\ntry {\n  var config = require('./.env.json')\n  for (var key in config) {\n    process.env[key] = config[key]\n  }\n} catch (err) {\n  // ignore\n}\n\nexports.handle = require('./index').handle\n```\n\nこのようになっていました\n\n![text](apex_lambda01.PNG)\n\n設定のhandlerの箇所とひもづいています\n\nなのでsample.jsをindex.jsに変更し、exports.handleを加える、もしくは設定できれば設定で解決すればよいですね\n\n今回はfunction.jsonを変えました\n\n- function.json\n```\n{\n  description: twitter to slack function,\n  runtime: nodejs4.3,\n  timeout: 300,\n  handler: sample.handle\n}\n```\n\n## DynamoDB\n\ndynamoDBは事前にテーブルを作っておきますが、特に難しいことはないので今回は割愛します\n\n## デプロイ、確認\n\n```\napex --profile swfz --region ap-northeast-1 deploy\napex --profile swfz --region ap-northeast-1 invoke timeline\napex --profile swfz --region ap-northeast-1 logs -f\n```\n\n今回はevent sourceとして何かデータが必要なわけではないのでjsonファイルは用意しません\n\nlogを見ながら処理がされているか確認する\n\n```\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:31.703Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    736278495840632800\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:31.941Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    736585313405931500\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:33.303Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    {}\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.041Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:07:23 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:29:02 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.061Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:40:56 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:45:27 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.160Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:30:15 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:33:06 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.161Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:33:06 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:37:25 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.161Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:10:32 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:25:01 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.393Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:25:43 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:28:27 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.399Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 15:37:25 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:49:58 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.410Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:35:34 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:39:56 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.493Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:47:36 GMT+0000 (UTC) TO Posted: Sat May 28 2016 15:01:18 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline 2016-05-28T15:54:34.533Z   730e56dd-24ec-11e6-a70a-13fd412f23fe    posted 5 tweet. Posted: Sat May 28 2016 14:28:40 GMT+0000 (UTC) TO Posted: Sat May 28 2016 14:35:34 GMT+0000 (UTC)\n/aws/lambda/twitter2slack_timeline END RequestId: 730e56dd-24ec-11e6-a70a-13fd412f23fe\n/aws/lambda/twitter2slack_timeline REPORT RequestId: 730e56dd-24ec-11e6-a70a-13fd412f23fe     Duration: 9344.78 __ais-highlight__ms__/ais-highlight__    Billed Duration: 9400 __ais-highlight__ms__/ais-highlight__    Memory Size: 128 MB     Max Memory Used: 66 MB\n```\n\n成功!\n\n## Event Sourceの設定\n\nlambda functionの定期実行なのでcloudwatch eventsの設定をします\n\n`Add Event Source`タブをクリックして設定します\n\n![text](apex_lambda02.PNG)\n\n今回は`15分ごとに実行する`を選択しました\n\ncrontabと同様の記述もできるのでより細かなスケジューリングも可能\n\n\n## 確認\n\n最後に、Slackにpostされているのを確認して完了!\n\n![text](apex_lambda03.PNG)\n\n# まとめ\n## apex\n- 特に難しいことはなかった\n- logまで出してくれるのでデプロイ後の確認しやすい\n- buildコマンドで確認できるのが便利\n- 試してないもの\n    - rollback\n    - apex infra (terraform). これでEventSource,DynamoDBの構築まで行えるようにできたら完璧ですね\n\n以前マネジメントコンソールでコード書いて確認して…といったフローでlambda functionを作成していたのでそれに比べてとても楽に管理できるなと思いました\n\nlambdaに関する設定関連もjsonで管理できてしまうのですべてバージョン管理しておけばさらに管理しやすそう\n\n試してないものに関しても今後試していきたいです\n\n[swfz/twitter2slack: lambda functions in twitter to slack. managed by apex.](https://github.com/swfz/twitter2slack)\n\n\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        },
        {
          "title": "windowsでscala開発のためにやったこと",
          "date": "2017-08-31",
          "slug": "scala/develop_for_win",
          "url": "http://localhost:8001/scala/develop_for_win",
          "section": "scala/develop_for_win",
          "tags": ["Scala"],
          "text": "# Windowsでscala開発のためにやったこと\n\nちょっと前のメモだけど掘り出してきました\n\nまずコンソールが微妙だと話にならないので下記と同じようにいろいろインストールする\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\n[僕が思う最強のWindowsコマンドプロンプト - 猫にWeb](http://d.hatena.ne.jp/necoyama3/20140313/1394689366)\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->\n\n- gow\n- clink\n- Git\n- conemu\n\n\n# activator\n## activatorのインストール\n[Build Reactive Applications with Lightbend Activator | @lightbend](http://www.lightbend.com/activator/download)\n\nからインストール\n\nactivator.batへのパスを環境変数へ追加する\n\n## jdkのインストール\n\n[Java SE Development Kit 8 - Downloads](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n\nJDKをインストールする\n\njava.exeへのパスを環境変数へ追加する\n\n- sbt\n- scala\n\n# chocolatey\n\n下記を参考にインストール\n\n[Windows での開発環境構築は、Chocolatey を使おう! - はしくれエンジニアもどきのメモ](http://cartman0.hatenablog.com/entry/2015/10/09/211022)\n\n- インストール\n\n```\npowershell -NoProfile -ExecutionPolicy unrestricted  -Command \"iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))\" && SET PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\n```\n\n- 確認\n\n```\n> choco -v\n0.9.9.12\n```\n\n# sbt\n\n```\n> choco install sbt\nInstalling the following packages:\nsbt\nBy installing you accept licenses for the packages.\n\nsbt v0.13.9\nThe package sbt wants to run 'chocolateyInstall.ps1'.\nNote: If you don't run this script, the installation will fail.\nNote: To confirm automatically next time, use '-y' or consider setting\n 'allowGlobalConfirmation'. Run 'choco feature -h' for more details.\nDo you want to run the script?\n 1) yes\n 2) no\n 3) print\nyes\n Downloading sbt 32 bit\n   from 'https://dl.bintray.com/sbt/native-packages/sbt/0.13.9/sbt-0.13.9.msi'\n Installing sbt...\n sbt has been installed.\n The install of sbt was successful.\n\nChocolatey installed 1/1 package(s). 0 package(s) failed.\n See the log for details (C:\\ProgramData\\chocolatey\\logs\\chocolatey.log).\n```\n\nインストーラを実行して良いか効かれるのでyesを選択\n\nChocolateyでsbtをインストールしたら64bitのPCなのに32bitをインストールしてきた\n\nちょっと不安になったのでやめた\n\n# 環境変数の修正\n\n[Download - Rapid Environment Editor](http://www.rapidee.com/en/download)\n\n## scalaのREPL\n\n```\nactivator shell\n> console\nscala>\n```\n\nこれでscalaになじむための環境が整った?\n\n### 文字化け\n\nactivatorシェルのhistoryをたどると文字化けする\n\n- ~/.activator/activatorconfig.txt\n\n```\n-Dinput.encoding=Cp1252\n```\n\n\n## Intellij関連\n\nactivatorでプロジェクトを作って実際に走らせようとして`build`なり`run`なりをしようとするとエラーが\n\n```\nError:Internal error: (java.net.SocketException) Socket is not connected: connect\njava.net.SocketException: Socket is not connected: connect\n\tat java.net.TwoStacksPlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat java.net.Socket.connect(Socket.java:538)\n\tat java.net.Socket.<init>(Socket.java:434)\n\tat java.net.Socket.<init>(Socket.java:244)\n\tat org.jetbrains.jps.incremental.scala.remote.RemoteResourceOwner$class.send(RemoteResourceOwner.scala:24)\n\tat org.jetbrains.jps.incremental.scala.remote.RemoteServer.send(RemoteServer.scala:12)\n\tat org.jetbrains.jps.incremental.scala.remote.RemoteServer.compile(RemoteServer.scala:17)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1$$anonfun$apply$2.apply(ScalaBuilder.scala:47)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1$$anonfun$apply$2.apply(ScalaBuilder.scala:41)\n\tat scala.util.Either$RightProjection.map(Either.scala:535)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1.apply(ScalaBuilder.scala:41)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1.apply(ScalaBuilder.scala:40)\n\tat scala.util.Either$RightProjection.flatMap(Either.scala:522)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1.apply(ScalaBuilder.scala:40)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1.apply(ScalaBuilder.scala:39)\n\tat scala.util.Either$RightProjection.flatMap(Either.scala:522)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$.compile(ScalaBuilder.scala:39)\n\tat org.jetbrains.jps.incremental.scala.IdeaIncrementalBuilder.build(IdeaIncrementalBuilder.scala:86)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.runModuleLevelBuilders(IncProjectBuilder.java:1238)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.runBuildersForChunk(IncProjectBuilder.java:912)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.buildTargetsChunk(IncProjectBuilder.java:984)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.buildChunkIfAffected(IncProjectBuilder.java:871)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.buildChunks(IncProjectBuilder.java:696)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.runBuild(IncProjectBuilder.java:387)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.build(IncProjectBuilder.java:194)\n\tat org.jetbrains.jps.cmdline.BuildRunner.runBuild(BuildRunner.java:137)\n\tat org.jetbrains.jps.cmdline.BuildSession.runBuild(BuildSession.java:294)\n\tat org.jetbrains.jps.cmdline.BuildSession.run(BuildSession.java:125)\n\tat org.jetbrains.jps.cmdline.BuildMain$MyMessageHandler$1.run(BuildMain.java:232)\n\tat org.jetbrains.jps.service.impl.SharedThreadPoolImpl$1.run(SharedThreadPoolImpl.java:44)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nPlease perform full project rebuild (Build | Rebuild Project)\n```\n\n調べた結果ファイアウォールの設定で解決できる模様\n\nコントロールパネル -> システムとセキュリティ -> Windowsファイアウォールによるプログラムの許可\n\n- JAVAの構成\n- Intellij IDEA Community Edition\n\nを追加します\n\n![text](develop_for_win01.PNG \"alt\")\n\nドメイン、ホーム、パブリックすべてに対して許可をします\n\n![text](develop_for_win02.PNG \"alt\")\n\nrunさせてみます\n\n無事起動できました\n\n![text](develop_for_win03.PNG \"alt\")\n\n",
          "objectID": "scala/develop_for_win",
          "_snippetResult": {
            "text": {
              "value": "2) no\n 3) print\nyes\n Downloading sbt 32 bit\n   from 'https://dl.bintray.com/sbt/native-packages/sbt/0.13.9/sbt-0.13.9.__ais-highlight__ms__/ais-highlight__i'\n Installing sbt...\n sbt has been installed.\n The install of sbt was successful.\n\nChocolatey installed 1/1 package(s). 0 package(s) failed.\n See the",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "windowsでscala開発のためにやったこと",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2017-08-31",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "scala/develop_for_win",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/scala/develop_for_win",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "scala/develop_for_win",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Scala", "matchLevel": "none", "matchedWords": [] }
            ],
            "text": {
              "value": "# Windowsでscala開発のためにやったこと\n\nちょっと前のメモだけど掘り出してきました\n\nまずコンソールが微妙だと話にならないので下記と同じようにいろいろインストールする\n\n<!-- textlint-disable ja-technical-writing/ja-no-weak-phrase -->\n[僕が思う最強のWindowsコマンドプロンプト - 猫にWeb](http://d.hatena.ne.jp/necoyama3/20140313/1394689366)\n<!-- textlint-enable ja-technical-writing/ja-no-weak-phrase -->\n\n- gow\n- clink\n- Git\n- conemu\n\n\n# activator\n## activatorのインストール\n[Build Reactive Applications with Lightbend Activator | @lightbend](http://www.lightbend.com/activator/download)\n\nからインストール\n\nactivator.batへのパスを環境変数へ追加する\n\n## jdkのインストール\n\n[Java SE Development Kit 8 - Downloads](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n\nJDKをインストールする\n\njava.exeへのパスを環境変数へ追加する\n\n- sbt\n- scala\n\n# chocolatey\n\n下記を参考にインストール\n\n[Windows での開発環境構築は、Chocolatey を使おう! - はしくれエンジニアもどきのメモ](http://cartman0.hatenablog.com/entry/2015/10/09/211022)\n\n- インストール\n\n```\npowershell -NoProfile -ExecutionPolicy unrestricted  -Command \"iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))\" && SET PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\n```\n\n- 確認\n\n```\n> choco -v\n0.9.9.12\n```\n\n# sbt\n\n```\n> choco install sbt\nInstalling the following packages:\nsbt\nBy installing you accept licenses for the packages.\n\nsbt v0.13.9\nThe package sbt wants to run 'chocolateyInstall.ps1'.\nNote: If you don't run this script, the installation will fail.\nNote: To confirm automatically next time, use '-y' or consider setting\n 'allowGlobalConfirmation'. Run 'choco feature -h' for more details.\nDo you want to run the script?\n 1) yes\n 2) no\n 3) print\nyes\n Downloading sbt 32 bit\n   from 'https://dl.bintray.com/sbt/native-packages/sbt/0.13.9/sbt-0.13.9.__ais-highlight__ms__/ais-highlight__i'\n Installing sbt...\n sbt has been installed.\n The install of sbt was successful.\n\nChocolatey installed 1/1 package(s). 0 package(s) failed.\n See the log for details (C:\\ProgramData\\chocolatey\\logs\\chocolatey.log).\n```\n\nインストーラを実行して良いか効かれるのでyesを選択\n\nChocolateyでsbtをインストールしたら64bitのPCなのに32bitをインストールしてきた\n\nちょっと不安になったのでやめた\n\n# 環境変数の修正\n\n[Download - Rapid Environment Editor](http://www.rapidee.com/en/download)\n\n## scalaのREPL\n\n```\nactivator shell\n> console\nscala>\n```\n\nこれでscalaになじむための環境が整った?\n\n### 文字化け\n\nactivatorシェルのhistoryをたどると文字化けする\n\n- ~/.activator/activatorconfig.txt\n\n```\n-Dinput.encoding=Cp1252\n```\n\n\n## Intellij関連\n\nactivatorでプロジェクトを作って実際に走らせようとして`build`なり`run`なりをしようとするとエラーが\n\n```\nError:Internal error: (java.net.SocketException) Socket is not connected: connect\njava.net.SocketException: Socket is not connected: connect\n\tat java.net.TwoStacksPlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat java.net.Socket.connect(Socket.java:538)\n\tat java.net.Socket.<init>(Socket.java:434)\n\tat java.net.Socket.<init>(Socket.java:244)\n\tat org.jetbrains.jps.incremental.scala.remote.RemoteResourceOwner$class.send(RemoteResourceOwner.scala:24)\n\tat org.jetbrains.jps.incremental.scala.remote.RemoteServer.send(RemoteServer.scala:12)\n\tat org.jetbrains.jps.incremental.scala.remote.RemoteServer.compile(RemoteServer.scala:17)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1$$anonfun$apply$2.apply(ScalaBuilder.scala:47)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1$$anonfun$apply$2.apply(ScalaBuilder.scala:41)\n\tat scala.util.Either$RightProjection.map(Either.scala:535)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1.apply(ScalaBuilder.scala:41)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1$$anonfun$apply$1.apply(ScalaBuilder.scala:40)\n\tat scala.util.Either$RightProjection.flatMap(Either.scala:522)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1.apply(ScalaBuilder.scala:40)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$$anonfun$compile$1.apply(ScalaBuilder.scala:39)\n\tat scala.util.Either$RightProjection.flatMap(Either.scala:522)\n\tat org.jetbrains.jps.incremental.scala.ScalaBuilder$.compile(ScalaBuilder.scala:39)\n\tat org.jetbrains.jps.incremental.scala.IdeaIncrementalBuilder.build(IdeaIncrementalBuilder.scala:86)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.runModuleLevelBuilders(IncProjectBuilder.java:1238)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.runBuildersForChunk(IncProjectBuilder.java:912)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.buildTargetsChunk(IncProjectBuilder.java:984)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.buildChunkIfAffected(IncProjectBuilder.java:871)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.buildChunks(IncProjectBuilder.java:696)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.runBuild(IncProjectBuilder.java:387)\n\tat org.jetbrains.jps.incremental.IncProjectBuilder.build(IncProjectBuilder.java:194)\n\tat org.jetbrains.jps.cmdline.BuildRunner.runBuild(BuildRunner.java:137)\n\tat org.jetbrains.jps.cmdline.BuildSession.runBuild(BuildSession.java:294)\n\tat org.jetbrains.jps.cmdline.BuildSession.run(BuildSession.java:125)\n\tat org.jetbrains.jps.cmdline.BuildMain$MyMessageHandler$1.run(BuildMain.java:232)\n\tat org.jetbrains.jps.service.impl.SharedThreadPoolImpl$1.run(SharedThreadPoolImpl.java:44)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nPlease perform full project rebuild (Build | Rebuild Project)\n```\n\n調べた結果ファイアウォールの設定で解決できる模様\n\nコントロールパネル -> システムとセキュリティ -> Windowsファイアウォールによるプログラムの許可\n\n- JAVAの構成\n- Intellij IDEA Community Edition\n\nを追加します\n\n![text](develop_for_win01.PNG \"alt\")\n\nドメイン、ホーム、パブリックすべてに対して許可をします\n\n![text](develop_for_win02.PNG \"alt\")\n\nrunさせてみます\n\n無事起動できました\n\n![text](develop_for_win03.PNG \"alt\")\n\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        },
        {
          "title": "[B] php update作業",
          "date": "2015-07-14",
          "slug": "php/20150714_php_update",
          "url": "http://localhost:8001/php/20150714_php_update",
          "section": "php/20150714_php_update",
          "tags": ["php"],
          "text": "# php update作業\n\n* 5.3.10 -> 5.6.10\n\nもはや、化石と化したシステムのメンテ\n\n特にフレームワークを使っているわけでも難しいことをやっているわけではないので特に問題はなかったけど、色々作業はしたのでそのときのメモ\n\n# テスト環境\n\n* コンパイルオプションの確認\n\n```\n$ php -i | grep configure\nConfigure Command =>  './configure'\n```\n\n何も指定してない\n\n```\nyum install BZip2\n```\n\n* ソースの取得\n\n```\nwget http://jp2.php.net/get/php-5.6.10.tar.gz/from/this/mirror\ntar xvf php-5.6.10.tar.gz\ncd php-5.6.10\n./configure\nmake test\nmake install\nphp -version\nPHP 5.6.10 (cli) (built: Jun 23 2015 12:19:32)\nCopyright (c) 1997-2015 The PHP Group\nZend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies\n```\n\n* Apache再起動、動作確認\n\nテスト環境は特に何も苦労なし\n\n# 本番\n\nconfigureオプションを確認\n\n```\n$ php -i | grep configure |  sed -e \"s/'//g\"\nConfigure Command =>  ./configure  --build=i686-redhat-linux-gnu --host=i686-redhat-linux-gnu --target=i386-redhat-linux-gnu --program-prefix= --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include --libdir=/usr/lib --libexecdir=/usr/libexec --localstatedir=/var --sharedstatedir=/usr/com --mandir=/usr/share/man --infodir=/usr/share/info --cache-file=../config.cache --with-libdir=lib --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --disable-debug --with-pic --disable-rpath --without-pear --with-bz2 --with-exec-dir=/usr/bin --with-freetype-dir=/usr --with-png-dir=/usr --with-xpm-dir=/usr --enable-gd-native-ttf --with-t1lib=/usr --without-gdbm --with-gettext --with-gmp --with-iconv --with-jpeg-dir=/usr --with-openssl --with-zlib --with-layout=GNU --enable-exif --enable-ftp --enable-magic-quotes --enable-sockets --with-kerberos --enable-ucd-snmp-hack --enable-shmop --enable-calendar --with-libxml-dir=/usr --enable-xml --with-system-tzdata --with-mhash --enable-force-cgi-redirect --libdir=/usr/lib/php --enable-pcntl --with-imap=shared --with-imap-ssl --enable-mbstring=shared --enable-mbregex --with-gd=shared --enable-bcmath=shared --enable-dba=shared --with-db4=/usr --with-xmlrpc=shared --with-ldap=shared --with-ldap-sasl --enable-mysqlnd=shared --with-mysql=shared,mysqlnd --with-mysqli=shared,mysqlnd --with-mysql-sock=/var/lib/mysql/mysql.sock --with-oci8=shared,instantclient,/usr/lib/oracle/11.2/client/lib,11.2 --with-pdo-oci=shared,instantclient,/usr,11.2 --with-interbase=shared,/usr/lib/firebird --with-pdo-firebird=shared,/usr/lib/firebird --enable-dom=shared --with-pgsql=shared --enable-wddx=shared --with-snmp=shared,/usr --enable-soap=shared --with-xsl=shared,/usr --enable-xmlreader=shared --enable-xmlwriter=shared --with-curl=shared,/usr --enable-fastcgi --enable-pdo=shared --with-pdo-odbc=shared,unixODBC,/usr --with-pdo-mysql=shared,mysqlnd --with-pdo-pgsql=shared,/usr --with-pdo-sqlite=shared,/usr --with-pdo-dblib=shared,/usr --without-sqlite3 --with-sqlite=shared,/usr --enable-json=shared --enable-zip=shared --without-readline --with-libedit --with-pspell=shared --enable-phar=shared --with-mcrypt=shared,/usr --with-tidy=shared,/usr --with-mssql=shared,/usr --enable-sysvmsg=shared --enable-sysvshm=shared --enable-sysvsem=shared --enable-posix=shared --with-unixODBC=shared,/usr --enable-fileinfo=shared --enable-intl=shared --with-icu-dir=/usr --with-enchant=shared,/usr --with-recode=shared,/usr\n```\n\n(ﾟдﾟ;)\n\nなんか色々付けている…\n\nそもそもテスト環境と環境違うのも微妙ということで、テスト環境でも同一コンパイルオプションでインストールできるように試行錯誤してみた\n\n------------------------------\n* エラー\n\n```\nPlease reinstall the BZip2 distribution\n```\n\n* bzip2\n\n```\nyum install -y bzip2 bzip2-devel\n```\n\n------------------------------\n* エラー\n\n```\nPlease reinstall the libcurl distribution\n```\n\n* curl\n\n```\nyum install -y curl-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Cannot find enchant\n```\n\n* enchant\n\n```\nyum install -y enchant-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: jpeglib.h not found\n```\n\n* libjpeg\n\n```\nyum install -y libjpeg-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: png.h not found.\n```\n\n* libpng\n\n```\nyum install -y libpng-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: xpm.h not found.\n```\n\n* libXpm\n\n```\nyum install -y libXpm-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: freetype-config not found.\n```\n\n* freetype\n\n```\nyum install -y freetype-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Your t1lib distribution is not installed correctly. Please reinstall it.\n```\n\n* t1lib\n\n```\nyum install -y t1lib\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Unable to locate gmp.h\n```\n\n* gmp\n\n```\nyum install -y gmp-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: utf8_mime2text() has new signature, but U8T_CANONICAL is missing. This should not happen. Check config.log for additional information.\n```\n\n* libc-client\n\n```\nyum install -y libc-client-devel\n```\n\n- 参考\n[U8T_CANONICAL is missing.](https://www.softel.co.jp/blogs/tech/archives/3450 \"alt\")\n\n------------------------------\n* エラー\n\n```\nconfigure: error: libgds, libib_util or libfbclient not found! Check config.log for more information.\n```\n\n* freebird\n\n```\nyum install firebird-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Unable to detect ICU prefix or /usr/bin/icu-config failed. Please verify ICU install prefix and make sure icu-config works.\n```\n\n* libicu\n\n```\nyum install libicu-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: ICU version 4.0 or later is required\n```\n\nyumでインストールできるicuのバージョンが古いのでソースからインストールする\n\n* libicu(source)\n\n```\nwget http://download.icu-project.org/files/icu4c/51.2/icu4c-51_2-src.tgz\ntar -zxvf icu4c-51_2-src.tgz\ncd icu/source\n./configure\nmake\nmake install\n```\n\n* コンパイルオプションを変更\n\n```\n- --with-icu-dir=/usr\n+ --with-icu-dir=/usr/local\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: mcrypt.h not found. Please reinstall libmcrypt.\n```\n\n* libmcrypt\n\n```\nyum install -y libmcrypt-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Directory /usr is not a FreeTDS installation directory\n```\n\n* freetds\n\n```\nyum install -y freetds-devel\n```\n\nここからfreetds,mssqlに関してのエラーが出てきてしばらく取り組んだものの解決せず、心折れました\n\nここまですでに数時間…\n\nそもそもテスト環境でconfigure option何も指定してないけどちゃんと動いているって時点で本番でもオプション付ける必要ないよねって結論にいたって単純に何もつけずにインストールしました\n\n動作確認でも問題なかったです\n\nどこかで誰かのお役に立てれば…\n\n",
          "objectID": "php/20150714_php_update",
          "_snippetResult": {
            "text": {
              "value": "enable-json=shared --enable-zip=shared --without-readline --with-libedit --with-pspell=shared --enable-phar=shared --with-mcrypt=shared,/usr --with-tidy=shared,/usr --with-__ais-highlight__ms__/ais-highlight__sql=shared,/usr --enable-sysvmsg=shared --enable-sysvshm=shared --enable-sysvsem=shared --enable-posix=shared --with-unixODBC=shared,/usr --enable-fileinfo=shared --enable-intl=shared",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "[B] php update作業",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2015-07-14",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "php/20150714_php_update",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/php/20150714_php_update",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "php/20150714_php_update",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "php", "matchLevel": "none", "matchedWords": [] }
            ],
            "text": {
              "value": "# php update作業\n\n* 5.3.10 -> 5.6.10\n\nもはや、化石と化したシステムのメンテ\n\n特にフレームワークを使っているわけでも難しいことをやっているわけではないので特に問題はなかったけど、色々作業はしたのでそのときのメモ\n\n# テスト環境\n\n* コンパイルオプションの確認\n\n```\n$ php -i | grep configure\nConfigure Command =>  './configure'\n```\n\n何も指定してない\n\n```\nyum install BZip2\n```\n\n* ソースの取得\n\n```\nwget http://jp2.php.net/get/php-5.6.10.tar.gz/from/this/mirror\ntar xvf php-5.6.10.tar.gz\ncd php-5.6.10\n./configure\nmake test\nmake install\nphp -version\nPHP 5.6.10 (cli) (built: Jun 23 2015 12:19:32)\nCopyright (c) 1997-2015 The PHP Group\nZend Engine v2.6.0, Copyright (c) 1998-2015 Zend Technologies\n```\n\n* Apache再起動、動作確認\n\nテスト環境は特に何も苦労なし\n\n# 本番\n\nconfigureオプションを確認\n\n```\n$ php -i | grep configure |  sed -e \"s/'//g\"\nConfigure Command =>  ./configure  --build=i686-redhat-linux-gnu --host=i686-redhat-linux-gnu --target=i386-redhat-linux-gnu --program-prefix= --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include --libdir=/usr/lib --libexecdir=/usr/libexec --localstatedir=/var --sharedstatedir=/usr/com --mandir=/usr/share/man --infodir=/usr/share/info --cache-file=../config.cache --with-libdir=lib --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --disable-debug --with-pic --disable-rpath --without-pear --with-bz2 --with-exec-dir=/usr/bin --with-freetype-dir=/usr --with-png-dir=/usr --with-xpm-dir=/usr --enable-gd-native-ttf --with-t1lib=/usr --without-gdbm --with-gettext --with-gmp --with-iconv --with-jpeg-dir=/usr --with-openssl --with-zlib --with-layout=GNU --enable-exif --enable-ftp --enable-magic-quotes --enable-sockets --with-kerberos --enable-ucd-snmp-hack --enable-shmop --enable-calendar --with-libxml-dir=/usr --enable-xml --with-system-tzdata --with-mhash --enable-force-cgi-redirect --libdir=/usr/lib/php --enable-pcntl --with-imap=shared --with-imap-ssl --enable-mbstring=shared --enable-mbregex --with-gd=shared --enable-bcmath=shared --enable-dba=shared --with-db4=/usr --with-xmlrpc=shared --with-ldap=shared --with-ldap-sasl --enable-mysqlnd=shared --with-mysql=shared,mysqlnd --with-mysqli=shared,mysqlnd --with-mysql-sock=/var/lib/mysql/mysql.sock --with-oci8=shared,instantclient,/usr/lib/oracle/11.2/client/lib,11.2 --with-pdo-oci=shared,instantclient,/usr,11.2 --with-interbase=shared,/usr/lib/firebird --with-pdo-firebird=shared,/usr/lib/firebird --enable-dom=shared --with-pgsql=shared --enable-wddx=shared --with-snmp=shared,/usr --enable-soap=shared --with-xsl=shared,/usr --enable-xmlreader=shared --enable-xmlwriter=shared --with-curl=shared,/usr --enable-fastcgi --enable-pdo=shared --with-pdo-odbc=shared,unixODBC,/usr --with-pdo-mysql=shared,mysqlnd --with-pdo-pgsql=shared,/usr --with-pdo-sqlite=shared,/usr --with-pdo-dblib=shared,/usr --without-sqlite3 --with-sqlite=shared,/usr --enable-json=shared --enable-zip=shared --without-readline --with-libedit --with-pspell=shared --enable-phar=shared --with-mcrypt=shared,/usr --with-tidy=shared,/usr --with-__ais-highlight__ms__/ais-highlight__sql=shared,/usr --enable-sysvmsg=shared --enable-sysvshm=shared --enable-sysvsem=shared --enable-posix=shared --with-unixODBC=shared,/usr --enable-fileinfo=shared --enable-intl=shared --with-icu-dir=/usr --with-enchant=shared,/usr --with-recode=shared,/usr\n```\n\n(ﾟдﾟ;)\n\nなんか色々付けている…\n\nそもそもテスト環境と環境違うのも微妙ということで、テスト環境でも同一コンパイルオプションでインストールできるように試行錯誤してみた\n\n------------------------------\n* エラー\n\n```\nPlease reinstall the BZip2 distribution\n```\n\n* bzip2\n\n```\nyum install -y bzip2 bzip2-devel\n```\n\n------------------------------\n* エラー\n\n```\nPlease reinstall the libcurl distribution\n```\n\n* curl\n\n```\nyum install -y curl-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Cannot find enchant\n```\n\n* enchant\n\n```\nyum install -y enchant-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: jpeglib.h not found\n```\n\n* libjpeg\n\n```\nyum install -y libjpeg-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: png.h not found.\n```\n\n* libpng\n\n```\nyum install -y libpng-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: xpm.h not found.\n```\n\n* libXpm\n\n```\nyum install -y libXpm-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: freetype-config not found.\n```\n\n* freetype\n\n```\nyum install -y freetype-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Your t1lib distribution is not installed correctly. Please reinstall it.\n```\n\n* t1lib\n\n```\nyum install -y t1lib\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Unable to locate gmp.h\n```\n\n* gmp\n\n```\nyum install -y gmp-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: utf8_mime2text() has new signature, but U8T_CANONICAL is missing. This should not happen. Check config.log for additional information.\n```\n\n* libc-client\n\n```\nyum install -y libc-client-devel\n```\n\n- 参考\n[U8T_CANONICAL is missing.](https://www.softel.co.jp/blogs/tech/archives/3450 \"alt\")\n\n------------------------------\n* エラー\n\n```\nconfigure: error: libgds, libib_util or libfbclient not found! Check config.log for more information.\n```\n\n* freebird\n\n```\nyum install firebird-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Unable to detect ICU prefix or /usr/bin/icu-config failed. Please verify ICU install prefix and make sure icu-config works.\n```\n\n* libicu\n\n```\nyum install libicu-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: ICU version 4.0 or later is required\n```\n\nyumでインストールできるicuのバージョンが古いのでソースからインストールする\n\n* libicu(source)\n\n```\nwget http://download.icu-project.org/files/icu4c/51.2/icu4c-51_2-src.tgz\ntar -zxvf icu4c-51_2-src.tgz\ncd icu/source\n./configure\nmake\nmake install\n```\n\n* コンパイルオプションを変更\n\n```\n- --with-icu-dir=/usr\n+ --with-icu-dir=/usr/local\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: mcrypt.h not found. Please reinstall libmcrypt.\n```\n\n* libmcrypt\n\n```\nyum install -y libmcrypt-devel\n```\n\n------------------------------\n* エラー\n\n```\nconfigure: error: Directory /usr is not a FreeTDS installation directory\n```\n\n* freetds\n\n```\nyum install -y freetds-devel\n```\n\nここからfreetds,__ais-highlight__ms__/ais-highlight__sqlに関してのエラーが出てきてしばらく取り組んだものの解決せず、心折れました\n\nここまですでに数時間…\n\nそもそもテスト環境でconfigure option何も指定してないけどちゃんと動いているって時点で本番でもオプション付ける必要ないよねって結論にいたって単純に何もつけずにインストールしました\n\n動作確認でも問題なかったです\n\nどこかで誰かのお役に立てれば…\n\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        },
        {
          "title": "Cloud Dataflowを使ってみる",
          "date": "2020-04-28",
          "slug": "gcp/dataflow_startup",
          "url": "http://localhost:8001/gcp/dataflow_startup",
          "section": "gcp/dataflow_startup",
          "tags": ["GoogleCloudPlatform", "Dataflow", "Apache Beam", "Python"],
          "text": "# Cloud Dataflowを使ってみる\n\nとりあえず触ってみようという感じのノリで使ってみた\n\nPython自体初学なので勉強含めてやってみる\n\n## Cloud Dataflow\n\n[Dataflow: ストリーム処理とバッチ処理  |  Google Cloud](https://cloud.google.com/dataflow?hl=ja)\n\n[https://cloud.google.com/dataflow?hl=ja:embed:cite]\n\nETLなどで使う感じ\n\nAWSだとGlueみたいな感じの立ち位置なのかな?\n\n中身はApache BeamでDataflowではApache Beamの実行環境のプロビジョニングをフルマネージドで行ってくれる\n\nまた、Beam自体は同じコードでストリーム処理とバッチ処理を両方対応できるらしい\n\n今回はバッチで試してみる\n\n## ローカルで試してみる\n\nまずはexampleのwordcountから\n\nhttps://github.com/apache/beam.git\n\nからチェックアウトしてローカルで実行してみる\n\nソースは下記\n\n[beam/wordcount.py at master · apache/beam](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/wordcount.py)\n\n```python\n#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n\"\"\"A word-counting workflow.\"\"\"\n\n# pytype: skip-file\n\nimport argparse\nimport logging\nimport re\n\nimport apache_beam as beam\nfrom apache_beam.io import ReadFromText\nfrom apache_beam.io import WriteToText\nfrom apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.options.pipeline_options import SetupOptions\n\n\nclass WordExtractingDoFn(beam.DoFn):\n  \"\"\"Parse each line of input text into words.\"\"\"\n  def process(self, element):\n    \"\"\"Returns an iterator over the words of this element.\n    The element is a line of text.  If the line is blank, note that, too.\n    Args:\n      element: the element being processed\n    Returns:\n      The processed element.\n    \"\"\"\n    return re.findall(r'[\\w\\']+', element, re.UNICODE)\n\n\ndef run(argv=None, save_main_session=True):\n  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--input',\n      dest='input',\n      default='gs://dataflow-samples/shakespeare/kinglear.txt',\n      help='Input file to process.')\n  parser.add_argument(\n      '--output',\n      dest='output',\n      required=True,\n      help='Output file to write results to.')\n  known_args, pipeline_args = parser.parse_known_args(argv)\n\n  # We use the save_main_session option because one or more DoFn's in this\n  # workflow rely on global context (e.g., a module imported at module level).\n  pipeline_options = PipelineOptions(pipeline_args)\n  pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n\n  # The pipeline will be run on exiting the with block.\n  with beam.Pipeline(options=pipeline_options) as p:\n\n    # Read the text file[pattern] into a PCollection.\n    lines = p | 'Read' >> ReadFromText(known_args.input)\n\n    counts = (\n        lines\n        | 'Split' >> (beam.ParDo(WordExtractingDoFn()).with_output_types(str))\n        | 'PairWIthOne' >> beam.Map(lambda x: (x, 1))\n        | 'GroupAndSum' >> beam.CombinePerKey(sum))\n\n    # Format the counts into a PCollection of strings.\n    def format_result(word, count):\n      return '%s: %d' % (word, count)\n\n    output = counts | 'Format' >> beam.MapTuple(format_result)\n\n    # Write the output using a \"Write\" transform that has side effects.\n    # pylint: disable=expression-not-assigned\n    output | 'Write' >> WriteToText(known_args.output)\n\n\nif __name__ == '__main__':\n  logging.getLogger().setLevel(logging.INFO)\n  run()\n```\n\n```shell\npip install apache-beam\npython ./beam/sdks/python/apache_beam/examples/wordcount.py --input ./beam/README.md --output word-count --runner DirectRunner\n```\n\n- 結果\n\n```\nLicensed: 1\nto: 10\nthe: 36\nApache: 12\nSoftware: 1\nFoundation: 1\nASF: 2\nunder: 5\none: 1\nor: 9\nmore: 2\ncontributor: 1\nlicense: 1\nagreements: 1\nSee: 4\nNOTICE: 1\nfile: 3\ndistributed: 6\n.....\n.....\n.....\n.....\n```\n\n`--runner DirectRunner`でローカル実行できる\n\nとても簡単\n\n## 中身を読む\n### オプションの受け渡し\n\n読んでいくとサンプルで動かした`--input`,`--output`はスクリプト側で用意したオプション\n\n```python\ndef run(argv=None, save_main_session=True):\n...\n...\n    known_args, pipeline_args = parser.parse_known_args(argv)\n```\n\n`argparse`の`parse_known_args`が`argparse`で定義したオプションとそれ以外のオプションを分けて代入してくれる\n\n`pipeline_args`に代入されたオプション（例だと`--runner`）は次のコードでbeamのオプションとして渡される\n\n```python\npipeline_options = PipelineOptions(pipeline_args)\npipeline_options.view_as(SetupOptions).save_main_session = save_main_session\np = beam.Pipeline(options=pipeline_options)\n```\n\nなのでargparseで定義したオプション以外のオプションはbeamのオプションとしてそのまま渡せるようになっている\n\nこの方法はおもしろいなと思った、Wrapperなどを作るときに使えそう\n\n### パイプライン処理\n\n```python\n  p = beam.Pipeline(options=pipeline_options)\n  lines = p | 'read' >> ReadFromText(known_args.input)\n\n  counts = (\n      lines\n      | 'split' >>\n      (beam.ParDo(WordExtractingDoFn()).with_output_types(unicode))\n      | 'pair_with_one' >> beam.Map(lambda x: (x, 1))\n      | 'group' >> beam.GroupByKey()\n      | 'count' >> beam.Map(count_ones))\n```\n\n`p`はPipelineオブジェクトでそこからパイプで次の処理を書いていく\n\nパイプで次の処理に流すと戻り値が`PCollection`になる\n\n`PCollection`にさらにパイプで次の処理に流すということができるのでどんどん処理をつなげていくことができる\n\nサンプルの`|`の後single quoteで囲っている箇所で処理に名前をつけられる\n\nDataflowのGUI上では次ような感じで表示される\n\n![alt](dataflow_startup02.png)\n\n変換処理は関数やクラスを定義して渡してもよいしlambdaで書いても大丈夫\n\n実際にちょっと変更して動かしてみたりすると理解しやすいかも\n\n書いてみるとRxJSでごちゃごちゃやる感覚に近く「これはうっかりするとメンテナンスがつらいやつかもなー」などと思ったりした\n\n## デプロイ\n\n最初CLIでデプロイどうやるんだって思っていたがそもそもbeam自体の `--runner`オプションで実行環境を指定するのでどこでコマンドを打つかを決めるだけだった\n\nなので本番環境の場合はどこでコマンド実行するというのを決めたらそこにソース上げてPythonコマンドでスクリプトをたたくだけでよい\n\nrunnerに関しては種類が結構あり、それぞれ対応しているメソッドが違ったりするようなので次の表で確認する必要がある\n\n[Apache Beam Capability Matrix](https://beam.apache.org/documentation/runners/capability-matrix/)\n\n[https://beam.apache.org/documentation/runners/capability-matrix/:embed:cite]\n\nローカルで実行する場合は`DirectRunner`,Dataflow上で実行する場合は`DataflowRunner`\n\n今まで経験したことのないパターンだったのでちょっと戸惑ったがこれはこれでよい気がする\n\n## 書いてみる\n\n書いたのはシェアなどの数を最終的にBigQueryに突っ込むコードを書いた\n\n結構長くなってしまったので解説などは割愛する\n\n[shared-count/aggregator.py at master · swfz/shared-count](https://github.com/swfz/shared-count/blob/master/aggregator/aggregator.py)\n\n今回は↑を書くにあたってのTipsを書いていく\n\n### GCSからの読み込み\n\n`ReadFromText`でGCSのURLを指定すればOK\n\n```python\ndata = p | 'READ' >> ReadFromText('gs://hoge/fuga/*')\n```\n\nテキスト読み込みでは改行区切りの単位でデータが扱われる\n\nJSONL（1行1行がJSON）のフォーマットでGCSへ置いて毎度`json.loads(str)`でパースする\n\n### BigQueryへの書き込み\n\n[Google BigQuery I/O connector](https://beam.apache.org/documentation/io/built-in/google-bigquery/)\n\n[https://beam.apache.org/documentation/io/built-in/google-bigquery/:embed:cite]\n\nこのあたりを参考にとりあえずいれてみる\n\n- sample.py\n\n```python\nimport apache_beam as beam\nfrom apache_beam.options.pipeline_options import PipelineOptions\n\np = beam.Pipeline(options=PipelineOptions())\nquotes = p | beam.Create([\n    {\n        'source': 'Mahatma Gandhi', 'quote': 'My life is my message.'\n    },\n    {\n        'source': 'Yoda', 'quote': \"Do, or do not. There is no 'try'.\"\n    },\n])\n\ntable_spec = 'hoge-000000:sample.sample'\ntable_schema = 'source:STRING, quote:STRING'\n\nquotes | beam.io.WriteToBigQuery(\n        table_spec,\n        schema=table_schema,\n        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED\n        )\n\np.run().wait_until_finish()\n```\n\nはいった\n\n![alt](dataflow_startup01.png)\n\nドキュメントにもあるがBigQueryのテーブルスキーマを定義する必要がある模様\n\nよしなにやってくれるわけではないみたいで少し面倒だった\n\n## 遭遇したエラーなど\n### 権限エラー\n\n`DataflowRunner`を使用中に発生した\n\nサービスアカウントに対象の操作権限がないパターン\n\nJobの実行には`dataflow.jobs.create`の権限が必要\n\n```\n\"(3b95fecb5f54e1ed): Could not create workflow; user does not have write access to project: hoge-000000 Causes: (3b95fecb5f54e142): Permission 'dataflow.jobs.create' denied on project: 'hoge-000000'\",\n```\n\n実行環境のマネージをするためComputeEngineへのアクセスも必要\n\n```\n\"(84ad1a753d8294d1): The workflow could not be created. Causes: (84ad1a753d8296f2): Unable to get machine type information for machine type n1-standard-1 in zone us-central1-f because of insufficient permissions. Please refer to https://cloud.google.com/dataflow/access-control#creating_jobs and make sure you have sufficient permissions.\",\n```\n\n### モジュール読み込み\n\n```\n  File \"fuga.py\", line 29, in process\nNameError: name 'pvalue' is not defined [while running 'DivideService/ParDo(ExtractService)']\n\nNote: imports, functions and other variables defined in the global context of your __main__ file of your Dataflow pipeline are, by default, not available in the worker execution environment, and such references will cause a NameError, unless the --save_main_session pipel\nine option is set to True. Please see https://cloud.google.com/dataflow/faq#how-do-i-handle-nameerrors for additional documentation on configuring your worker execution environment.\n```\n\nsave_main_sessionを有効にしろっていわれているようなので次の修正を行った\n\n```diff\n- def run(argv=None, save_main_session=False):\n+ def run(argv=None, save_main_session=True):\n```\n\nimportをどこに書くかでも解決できる模様\n\n### 自作モジュールの読み込み\n\n`modules/bq_schema.py`というファイルを用意してBigQueryのテーブルスキーマを読み込んでいた\n\nローカル実行時はうまく言っていたがDataflow上で実行するとエラーが発生した\n\n```\nModuleNotFoundError: No module named 'bq_schema'\n```\n\n`__init__.py`を設置すればよいらしい\n\nmodulesディレクトリに`__init__.py`を設置、実行ディレクトリに`setup.py`を設置して対応した\n\nこのあたり正直良く理解できてないけどPythonでは慣習なのかな\n\n[python - Dataflow/apache beam: manage custom module dependencies - Stack Overflow](https://stackoverflow.com/questions/51763406/dataflow-apache-beam-manage-custom-module-dependencies)\n\n[https://stackoverflow.com/questions/51763406/dataflow-apache-beam-manage-custom-module-dependencies:embed:cite]\n\n[Managing Python Pipeline Dependencies](https://beam.apache.org/documentation/sdks/python-pipeline-dependencies/#multiple-file-dependencies)\n\n[https://beam.apache.org/documentation/sdks/python-pipeline-dependencies/#multiple-file-dependencies:embed:cite]\n\n- 参考\n\n[Python の __init__.py とは何なのか - Qiita](https://qiita.com/msi/items/d91ea3900373ff8b09d7)\n\n[https://qiita.com/msi/items/d91ea3900373ff8b09d7:embed:cite]\n\n### BigQueryスキーマ\n\n```\n2020-04-13 12:49:27.448 JSTWorkflow failed. Causes: S10:WriteBookmarkToBigQuery/WriteToBigQuery/NativeWrite failed., BigQuery import job \"dataflow_job_18028366815374964034\" failed., BigQuery creation of import job for table \"bookmark\" in dataset \"blog_data\" in project \"hoge-000000\" failed., BigQuery execution failed., HTTP transport error: Message: Invalid value for: ARRAY<STRING> is not a valid value HTTP Code: 400\n```\n\nhttps://stackoverflow.com/questions/44401235/spark-bigquery-connector-writing-array-type-causes-exception-invalid-value-f\n\n配列データを入れる必要があったので`type=ARRAY<STRING>`と書いたら怒られたので`type=STRING,mode=REPEATED`として対応した\n\n## まとめ\n\nとりあえず動かしてみて実際に使ってみた\n\n- ローカル実行がとても楽\n    - runnerオプションで処理自体の実行場所を指定する\n        - そのためローカルで実行したとしても処理自体は`Dataflow`で処理するみたいな使い方ができる\n        - あくまでDataflowはbeamの実行環境を提供するだけ\n\n- Pythonの基礎教養がない状態でやったので結構基礎周りでもつまずいた\n    - 勉強になった、ある程度読めるようにはなった\n\n- この手のサービスを使って効果が出そうなほどの大量データを処理するみたいなパターンでは使えてないため今後試してみたい\n- ストリーム処理といえば自分はRx系のイメージがあったので流れは理解しやすかった\n    - 細かな挙動までは把握できていないので今後調べる\n",
          "objectID": "gcp/dataflow_startup",
          "_snippetResult": {
            "text": {
              "value": "sdks/python-pipeline-dependencies/#multiple-file-dependencies:embed:cite]\n\n- 参考\n\n[Python の __init__.py とは何なのか - Qiita](https://qiita.com/__ais-highlight__ms__/ais-highlight__i/items/d91ea3900373ff8b09d7)\n\n[https://qiita.com/__ais-highlight__ms__/ais-highlight__i/items/d91ea3900373ff8b09d7:embed:cite]\n\n### BigQueryスキーマ\n\n```\n2020-04-13 12:49:27.448 JSTWorkflow failed",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "title": {
              "value": "Cloud Dataflowを使ってみる",
              "matchLevel": "none",
              "matchedWords": []
            },
            "date": {
              "value": "2020-04-28",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "gcp/dataflow_startup",
              "matchLevel": "none",
              "matchedWords": []
            },
            "url": {
              "value": "http://localhost:8001/gcp/dataflow_startup",
              "matchLevel": "none",
              "matchedWords": []
            },
            "section": {
              "value": "gcp/dataflow_startup",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "GoogleCloudPlatform",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "Dataflow", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "Apache Beam",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "Python", "matchLevel": "none", "matchedWords": [] }
            ],
            "text": {
              "value": "# Cloud Dataflowを使ってみる\n\nとりあえず触ってみようという感じのノリで使ってみた\n\nPython自体初学なので勉強含めてやってみる\n\n## Cloud Dataflow\n\n[Dataflow: ストリーム処理とバッチ処理  |  Google Cloud](https://cloud.google.com/dataflow?hl=ja)\n\n[https://cloud.google.com/dataflow?hl=ja:embed:cite]\n\nETLなどで使う感じ\n\nAWSだとGlueみたいな感じの立ち位置なのかな?\n\n中身はApache BeamでDataflowではApache Beamの実行環境のプロビジョニングをフルマネージドで行ってくれる\n\nまた、Beam自体は同じコードでストリーム処理とバッチ処理を両方対応できるらしい\n\n今回はバッチで試してみる\n\n## ローカルで試してみる\n\nまずはexampleのwordcountから\n\nhttps://github.com/apache/beam.git\n\nからチェックアウトしてローカルで実行してみる\n\nソースは下記\n\n[beam/wordcount.py at master · apache/beam](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/wordcount.py)\n\n```python\n#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n\"\"\"A word-counting workflow.\"\"\"\n\n# pytype: skip-file\n\nimport argparse\nimport logging\nimport re\n\nimport apache_beam as beam\nfrom apache_beam.io import ReadFromText\nfrom apache_beam.io import WriteToText\nfrom apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.options.pipeline_options import SetupOptions\n\n\nclass WordExtractingDoFn(beam.DoFn):\n  \"\"\"Parse each line of input text into words.\"\"\"\n  def process(self, element):\n    \"\"\"Returns an iterator over the words of this element.\n    The element is a line of text.  If the line is blank, note that, too.\n    Args:\n      element: the element being processed\n    Returns:\n      The processed element.\n    \"\"\"\n    return re.findall(r'[\\w\\']+', element, re.UNICODE)\n\n\ndef run(argv=None, save_main_session=True):\n  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--input',\n      dest='input',\n      default='gs://dataflow-samples/shakespeare/kinglear.txt',\n      help='Input file to process.')\n  parser.add_argument(\n      '--output',\n      dest='output',\n      required=True,\n      help='Output file to write results to.')\n  known_args, pipeline_args = parser.parse_known_args(argv)\n\n  # We use the save_main_session option because one or more DoFn's in this\n  # workflow rely on global context (e.g., a module imported at module level).\n  pipeline_options = PipelineOptions(pipeline_args)\n  pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n\n  # The pipeline will be run on exiting the with block.\n  with beam.Pipeline(options=pipeline_options) as p:\n\n    # Read the text file[pattern] into a PCollection.\n    lines = p | 'Read' >> ReadFromText(known_args.input)\n\n    counts = (\n        lines\n        | 'Split' >> (beam.ParDo(WordExtractingDoFn()).with_output_types(str))\n        | 'PairWIthOne' >> beam.Map(lambda x: (x, 1))\n        | 'GroupAndSum' >> beam.CombinePerKey(sum))\n\n    # Format the counts into a PCollection of strings.\n    def format_result(word, count):\n      return '%s: %d' % (word, count)\n\n    output = counts | 'Format' >> beam.MapTuple(format_result)\n\n    # Write the output using a \"Write\" transform that has side effects.\n    # pylint: disable=expression-not-assigned\n    output | 'Write' >> WriteToText(known_args.output)\n\n\nif __name__ == '__main__':\n  logging.getLogger().setLevel(logging.INFO)\n  run()\n```\n\n```shell\npip install apache-beam\npython ./beam/sdks/python/apache_beam/examples/wordcount.py --input ./beam/README.md --output word-count --runner DirectRunner\n```\n\n- 結果\n\n```\nLicensed: 1\nto: 10\nthe: 36\nApache: 12\nSoftware: 1\nFoundation: 1\nASF: 2\nunder: 5\none: 1\nor: 9\nmore: 2\ncontributor: 1\nlicense: 1\nagreements: 1\nSee: 4\nNOTICE: 1\nfile: 3\ndistributed: 6\n.....\n.....\n.....\n.....\n```\n\n`--runner DirectRunner`でローカル実行できる\n\nとても簡単\n\n## 中身を読む\n### オプションの受け渡し\n\n読んでいくとサンプルで動かした`--input`,`--output`はスクリプト側で用意したオプション\n\n```python\ndef run(argv=None, save_main_session=True):\n...\n...\n    known_args, pipeline_args = parser.parse_known_args(argv)\n```\n\n`argparse`の`parse_known_args`が`argparse`で定義したオプションとそれ以外のオプションを分けて代入してくれる\n\n`pipeline_args`に代入されたオプション（例だと`--runner`）は次のコードでbeamのオプションとして渡される\n\n```python\npipeline_options = PipelineOptions(pipeline_args)\npipeline_options.view_as(SetupOptions).save_main_session = save_main_session\np = beam.Pipeline(options=pipeline_options)\n```\n\nなのでargparseで定義したオプション以外のオプションはbeamのオプションとしてそのまま渡せるようになっている\n\nこの方法はおもしろいなと思った、Wrapperなどを作るときに使えそう\n\n### パイプライン処理\n\n```python\n  p = beam.Pipeline(options=pipeline_options)\n  lines = p | 'read' >> ReadFromText(known_args.input)\n\n  counts = (\n      lines\n      | 'split' >>\n      (beam.ParDo(WordExtractingDoFn()).with_output_types(unicode))\n      | 'pair_with_one' >> beam.Map(lambda x: (x, 1))\n      | 'group' >> beam.GroupByKey()\n      | 'count' >> beam.Map(count_ones))\n```\n\n`p`はPipelineオブジェクトでそこからパイプで次の処理を書いていく\n\nパイプで次の処理に流すと戻り値が`PCollection`になる\n\n`PCollection`にさらにパイプで次の処理に流すということができるのでどんどん処理をつなげていくことができる\n\nサンプルの`|`の後single quoteで囲っている箇所で処理に名前をつけられる\n\nDataflowのGUI上では次ような感じで表示される\n\n![alt](dataflow_startup02.png)\n\n変換処理は関数やクラスを定義して渡してもよいしlambdaで書いても大丈夫\n\n実際にちょっと変更して動かしてみたりすると理解しやすいかも\n\n書いてみるとRxJSでごちゃごちゃやる感覚に近く「これはうっかりするとメンテナンスがつらいやつかもなー」などと思ったりした\n\n## デプロイ\n\n最初CLIでデプロイどうやるんだって思っていたがそもそもbeam自体の `--runner`オプションで実行環境を指定するのでどこでコマンドを打つかを決めるだけだった\n\nなので本番環境の場合はどこでコマンド実行するというのを決めたらそこにソース上げてPythonコマンドでスクリプトをたたくだけでよい\n\nrunnerに関しては種類が結構あり、それぞれ対応しているメソッドが違ったりするようなので次の表で確認する必要がある\n\n[Apache Beam Capability Matrix](https://beam.apache.org/documentation/runners/capability-matrix/)\n\n[https://beam.apache.org/documentation/runners/capability-matrix/:embed:cite]\n\nローカルで実行する場合は`DirectRunner`,Dataflow上で実行する場合は`DataflowRunner`\n\n今まで経験したことのないパターンだったのでちょっと戸惑ったがこれはこれでよい気がする\n\n## 書いてみる\n\n書いたのはシェアなどの数を最終的にBigQueryに突っ込むコードを書いた\n\n結構長くなってしまったので解説などは割愛する\n\n[shared-count/aggregator.py at master · swfz/shared-count](https://github.com/swfz/shared-count/blob/master/aggregator/aggregator.py)\n\n今回は↑を書くにあたってのTipsを書いていく\n\n### GCSからの読み込み\n\n`ReadFromText`でGCSのURLを指定すればOK\n\n```python\ndata = p | 'READ' >> ReadFromText('gs://hoge/fuga/*')\n```\n\nテキスト読み込みでは改行区切りの単位でデータが扱われる\n\nJSONL（1行1行がJSON）のフォーマットでGCSへ置いて毎度`json.loads(str)`でパースする\n\n### BigQueryへの書き込み\n\n[Google BigQuery I/O connector](https://beam.apache.org/documentation/io/built-in/google-bigquery/)\n\n[https://beam.apache.org/documentation/io/built-in/google-bigquery/:embed:cite]\n\nこのあたりを参考にとりあえずいれてみる\n\n- sample.py\n\n```python\nimport apache_beam as beam\nfrom apache_beam.options.pipeline_options import PipelineOptions\n\np = beam.Pipeline(options=PipelineOptions())\nquotes = p | beam.Create([\n    {\n        'source': 'Mahatma Gandhi', 'quote': 'My life is my message.'\n    },\n    {\n        'source': 'Yoda', 'quote': \"Do, or do not. There is no 'try'.\"\n    },\n])\n\ntable_spec = 'hoge-000000:sample.sample'\ntable_schema = 'source:STRING, quote:STRING'\n\nquotes | beam.io.WriteToBigQuery(\n        table_spec,\n        schema=table_schema,\n        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED\n        )\n\np.run().wait_until_finish()\n```\n\nはいった\n\n![alt](dataflow_startup01.png)\n\nドキュメントにもあるがBigQueryのテーブルスキーマを定義する必要がある模様\n\nよしなにやってくれるわけではないみたいで少し面倒だった\n\n## 遭遇したエラーなど\n### 権限エラー\n\n`DataflowRunner`を使用中に発生した\n\nサービスアカウントに対象の操作権限がないパターン\n\nJobの実行には`dataflow.jobs.create`の権限が必要\n\n```\n\"(3b95fecb5f54e1ed): Could not create workflow; user does not have write access to project: hoge-000000 Causes: (3b95fecb5f54e142): Permission 'dataflow.jobs.create' denied on project: 'hoge-000000'\",\n```\n\n実行環境のマネージをするためComputeEngineへのアクセスも必要\n\n```\n\"(84ad1a753d8294d1): The workflow could not be created. Causes: (84ad1a753d8296f2): Unable to get machine type information for machine type n1-standard-1 in zone us-central1-f because of insufficient permissions. Please refer to https://cloud.google.com/dataflow/access-control#creating_jobs and make sure you have sufficient permissions.\",\n```\n\n### モジュール読み込み\n\n```\n  File \"fuga.py\", line 29, in process\nNameError: name 'pvalue' is not defined [while running 'DivideService/ParDo(ExtractService)']\n\nNote: imports, functions and other variables defined in the global context of your __main__ file of your Dataflow pipeline are, by default, not available in the worker execution environment, and such references will cause a NameError, unless the --save_main_session pipel\nine option is set to True. Please see https://cloud.google.com/dataflow/faq#how-do-i-handle-nameerrors for additional documentation on configuring your worker execution environment.\n```\n\nsave_main_sessionを有効にしろっていわれているようなので次の修正を行った\n\n```diff\n- def run(argv=None, save_main_session=False):\n+ def run(argv=None, save_main_session=True):\n```\n\nimportをどこに書くかでも解決できる模様\n\n### 自作モジュールの読み込み\n\n`modules/bq_schema.py`というファイルを用意してBigQueryのテーブルスキーマを読み込んでいた\n\nローカル実行時はうまく言っていたがDataflow上で実行するとエラーが発生した\n\n```\nModuleNotFoundError: No module named 'bq_schema'\n```\n\n`__init__.py`を設置すればよいらしい\n\nmodulesディレクトリに`__init__.py`を設置、実行ディレクトリに`setup.py`を設置して対応した\n\nこのあたり正直良く理解できてないけどPythonでは慣習なのかな\n\n[python - Dataflow/apache beam: manage custom module dependencies - Stack Overflow](https://stackoverflow.com/questions/51763406/dataflow-apache-beam-manage-custom-module-dependencies)\n\n[https://stackoverflow.com/questions/51763406/dataflow-apache-beam-manage-custom-module-dependencies:embed:cite]\n\n[Managing Python Pipeline Dependencies](https://beam.apache.org/documentation/sdks/python-pipeline-dependencies/#multiple-file-dependencies)\n\n[https://beam.apache.org/documentation/sdks/python-pipeline-dependencies/#multiple-file-dependencies:embed:cite]\n\n- 参考\n\n[Python の __init__.py とは何なのか - Qiita](https://qiita.com/__ais-highlight__ms__/ais-highlight__i/items/d91ea3900373ff8b09d7)\n\n[https://qiita.com/__ais-highlight__ms__/ais-highlight__i/items/d91ea3900373ff8b09d7:embed:cite]\n\n### BigQueryスキーマ\n\n```\n2020-04-13 12:49:27.448 JSTWorkflow failed. Causes: S10:WriteBookmarkToBigQuery/WriteToBigQuery/NativeWrite failed., BigQuery import job \"dataflow_job_18028366815374964034\" failed., BigQuery creation of import job for table \"bookmark\" in dataset \"blog_data\" in project \"hoge-000000\" failed., BigQuery execution failed., HTTP transport error: Message: Invalid value for: ARRAY<STRING> is not a valid value HTTP Code: 400\n```\n\nhttps://stackoverflow.com/questions/44401235/spark-bigquery-connector-writing-array-type-causes-exception-invalid-value-f\n\n配列データを入れる必要があったので`type=ARRAY<STRING>`と書いたら怒られたので`type=STRING,mode=REPEATED`として対応した\n\n## まとめ\n\nとりあえず動かしてみて実際に使ってみた\n\n- ローカル実行がとても楽\n    - runnerオプションで処理自体の実行場所を指定する\n        - そのためローカルで実行したとしても処理自体は`Dataflow`で処理するみたいな使い方ができる\n        - あくまでDataflowはbeamの実行環境を提供するだけ\n\n- Pythonの基礎教養がない状態でやったので結構基礎周りでもつまずいた\n    - 勉強になった、ある程度読めるようにはなった\n\n- この手のサービスを使って効果が出そうなほどの大量データを処理するみたいなパターンでは使えてないため今後試してみたい\n- ストリーム処理といえば自分はRx系のイメージがあったので流れは理解しやすかった\n    - 細かな挙動までは把握できていないので今後調べる\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            }
          }
        }
      ],
      "nbHits": 8,
      "page": 0,
      "nbPages": 1,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "exhaustive": { "nbHits": true, "typo": true },
      "query": "ms",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&page=0&query=ms&tagFilters=",
      "index": "hatenablog",
      "renderingContent": {},
      "processingTimeMS": 11,
      "processingTimingsMS": {
        "afterFetch": {
          "format": { "highlighting": 4, "snippeting": 6, "total": 11 },
          "total": 11
        },
        "total": 11
      }
    },
    {
      "hits": [
        {
          "url": "https://til.swfz.io//entries/msw_mock_svg/",
          "text": "\n本ブログでPixelaのグラフを表示させるようにした\n\n表示するだけなら下記にあるようにiframeで呼び出すだけでOK\n\n[草グラフを iframe タグで簡単に埋め込む（Pixela v1.12.1） - えいのうにっき](https://blog.a-know.me/entry/2019/06/16/210915)\n\nが、Gatsbyなどで開発しているときなどは特にリクエストを外部に送る必要がないためURLを出し分けするなりモックするなどできたら良いなと思っていた\n\nこれができていればuseEffectでミスって無限ループしてしまったときなども特に心配せずに開発できる\n\nmswを使えば外部リクエストをモックできるので行けそう?だったがiframeの中身のコンテンツのモックはできないようなのでSVGを表示する方法にする\n\nということでmswを使ってSVGをモックするようにしてみた\n\n## install\n\n[Install - Getting Started - Mock Service Worker Docs](https://mswjs.io/docs/getting-started/install)\n\n基本的にはドキュメントを見て進めるでOKそう\n\n```shell\nyarn add --dev msw\nmkdir src/mocks\ntouch src/mocks/handlers.ts\n```\n\npublicディレクトリに作成する\n\ngatsbyなので`static/`\n\n```\nnpx msw init static/ --save\n```\n\nすると`static/mockServiceWorker.js`というファイルが生成される\n\n\n## svgファイルをモックする\n\n必要な修正をする\n\n- gatsby-browser.js\n\n```javascript\nconst startWorker = async () => {\n  const { worker } = require(\"./src/mocks/browser\")\n  await worker.start({\n    ServiceWorker: {\n      url: \"/pixela-mock\",\n    },\n  })\n}\n\nexport const onClientEntry = () => {\n  if (process.env.NODE_ENV === \"development\") {\n    startWorker()\n  }\n}\n```\n\nGatsbyのレンダリング初期にモック処理ができるか調べてみた\n\n[Gatsbyドキュメント Doc -> Recipes ざっくりまとめ - 奇をてらったテクノロジー](https://kiotera-tech.com/gatsby_doc_recipes_summary)\n\n[https://kiotera-tech.com/gatsby_doc_recipes_summary:embed:cite]\n\nGatsbyのライフサイクル`onClientEntry`を使うことで可能っぽい\n\n`onClientEntry`の処理時に`startWorker`を動かすようにした\n\nこのライフサイクルを考慮せず`startWorker`を書いてしまうとタイミングによってはモックされたりされなかったり…という現象に見舞われた\n\n- src/mocks/browser.js\n\n```javascript\n// src/mocks/browser.js\nimport { setupWorker } from 'msw'\nimport { handlers } from './handler'\n// This configures a Service Worker with the given request handlers.\nexport const worker = setupWorker(...handlers)\n```\n\n- src/mocks/handler.ts\n\n```typescript\nimport { rest } from 'msw'\nimport svgImage from './pixela.svg'\n\nexport const handlers = [\n  rest.get('https://pixe.la/v1/users/swfz/graphs/til-pageviews', async (req, res, ctx) => {\n    const svgBuffer = await fetch(svgImage).then((res) => res.arrayBuffer())\n\n    return res(ctx.status(200), ctx.body(svgBuffer))\n  }),\n  rest.post('https://undefined-1.algolianet.com/1/indexes/*/queries', (req, res, ctx) => {\n    return res(ctx.status(200), ctx.json({results: {hits: []}}))\n  })\n]\n```\n\nsvgファイルは一度curlなり何なりでローカルに持ってきて保存しておく→`./pixela.svg`\n\nおまけでalgoliaへのリクエストも開発時はほとんど使わないので定義した\n\n## SVGのモック処理\n\nsvgをモックするのどうすれば良いのかと思ったが\n\n画像と同じような感じでOKだったので`arrayBuffer`を使う\n\n[Possible to mock an img src url? · Issue #461 · mswjs/msw](https://github.com/mswjs/msw/issues/461)\n\nモックできているかどうかの確認はモック用のSVGはPixelaの色を変えてからローカルに保存したのでdev用は赤、本番は青といった感じで別れている\n\n## まとめ\n\nmswを使って開発時はpixelaへのSVGリクエストをモックして開発時はアクセスが行かないようにした\n\nリクエスト先のURLを出し分けせずにモックできるのは非常に体験が良い\n\n外部のサービスやツールを使っていてsandbox用とかで分けられていない場合などいろんな用途に使えそう\n\n他にも用途いろいろありそうなので使っていこうと思った",
          "date": "2021-12-29",
          "title": "mswでSVGをモックする",
          "tags": ["JavaScript", "TypeScript", "Gatsby", "msw"],
          "description": "Pixelaを題材としてモックしてみた",
          "slug": "/entries/msw_mock_svg/",
          "timeToRead": 3,
          "objectID": "75a9abd2-0b34-54b0-b919-36e1513da0ed",
          "_snippetResult": {
            "text": {
              "value": "ような感じでOKだったので`arrayBuffer`を使う\n\n[Possible to mock an img src url? · Issue #461 · __ais-highlight__ms__/ais-highlight__wjs/__ais-highlight__ms__/ais-highlight__w](https://github.com/__ais-highlight__ms__/ais-highlight__wjs/__ais-highlight__ms__/ais-highlight__w/issues/461)\n\nモックできているかどうかの確認は",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/__ais-highlight__ms__/ais-highlight__w_mock_svg/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "text": {
              "value": "\n本ブログでPixelaのグラフを表示させるようにした\n\n表示するだけなら下記にあるようにiframeで呼び出すだけでOK\n\n[草グラフを iframe タグで簡単に埋め込む（Pixela v1.12.1） - えいのうにっき](https://blog.a-know.me/entry/2019/06/16/210915)\n\nが、Gatsbyなどで開発しているときなどは特にリクエストを外部に送る必要がないためURLを出し分けするなりモックするなどできたら良いなと思っていた\n\nこれができていればuseEffectでミスって無限ループしてしまったときなども特に心配せずに開発できる\n\n__ais-highlight__ms__/ais-highlight__wを使えば外部リクエストをモックできるので行けそう?だったがiframeの中身のコンテンツのモックはできないようなのでSVGを表示する方法にする\n\nということで__ais-highlight__ms__/ais-highlight__wを使ってSVGをモックするようにしてみた\n\n## install\n\n[Install - Getting Started - Mock Service Worker Docs](https://__ais-highlight__ms__/ais-highlight__wjs.io/docs/getting-started/install)\n\n基本的にはドキュメントを見て進めるでOKそう\n\n```shell\nyarn add --dev __ais-highlight__ms__/ais-highlight__w\nmkdir src/mocks\ntouch src/mocks/handlers.ts\n```\n\npublicディレクトリに作成する\n\ngatsbyなので`static/`\n\n```\nnpx __ais-highlight__ms__/ais-highlight__w init static/ --save\n```\n\nすると`static/mockServiceWorker.js`というファイルが生成される\n\n\n## svgファイルをモックする\n\n必要な修正をする\n\n- gatsby-browser.js\n\n```javascript\nconst startWorker = async () => {\n  const { worker } = require(\"./src/mocks/browser\")\n  await worker.start({\n    ServiceWorker: {\n      url: \"/pixela-mock\",\n    },\n  })\n}\n\nexport const onClientEntry = () => {\n  if (process.env.NODE_ENV === \"development\") {\n    startWorker()\n  }\n}\n```\n\nGatsbyのレンダリング初期にモック処理ができるか調べてみた\n\n[Gatsbyドキュメント Doc -> Recipes ざっくりまとめ - 奇をてらったテクノロジー](https://kiotera-tech.com/gatsby_doc_recipes_summary)\n\n[https://kiotera-tech.com/gatsby_doc_recipes_summary:embed:cite]\n\nGatsbyのライフサイクル`onClientEntry`を使うことで可能っぽい\n\n`onClientEntry`の処理時に`startWorker`を動かすようにした\n\nこのライフサイクルを考慮せず`startWorker`を書いてしまうとタイミングによってはモックされたりされなかったり…という現象に見舞われた\n\n- src/mocks/browser.js\n\n```javascript\n// src/mocks/browser.js\nimport { setupWorker } from '__ais-highlight__ms__/ais-highlight__w'\nimport { handlers } from './handler'\n// This configures a Service Worker with the given request handlers.\nexport const worker = setupWorker(...handlers)\n```\n\n- src/mocks/handler.ts\n\n```typescript\nimport { rest } from '__ais-highlight__ms__/ais-highlight__w'\nimport svgImage from './pixela.svg'\n\nexport const handlers = [\n  rest.get('https://pixe.la/v1/users/swfz/graphs/til-pageviews', async (req, res, ctx) => {\n    const svgBuffer = await fetch(svgImage).then((res) => res.arrayBuffer())\n\n    return res(ctx.status(200), ctx.body(svgBuffer))\n  }),\n  rest.post('https://undefined-1.algolianet.com/1/indexes/*/queries', (req, res, ctx) => {\n    return res(ctx.status(200), ctx.json({results: {hits: []}}))\n  })\n]\n```\n\nsvgファイルは一度curlなり何なりでローカルに持ってきて保存しておく→`./pixela.svg`\n\nおまけでalgoliaへのリクエストも開発時はほとんど使わないので定義した\n\n## SVGのモック処理\n\nsvgをモックするのどうすれば良いのかと思ったが\n\n画像と同じような感じでOKだったので`arrayBuffer`を使う\n\n[Possible to mock an img src url? · Issue #461 · __ais-highlight__ms__/ais-highlight__wjs/__ais-highlight__ms__/ais-highlight__w](https://github.com/__ais-highlight__ms__/ais-highlight__wjs/__ais-highlight__ms__/ais-highlight__w/issues/461)\n\nモックできているかどうかの確認はモック用のSVGはPixelaの色を変えてからローカルに保存したのでdev用は赤、本番は青といった感じで別れている\n\n## まとめ\n\n__ais-highlight__ms__/ais-highlight__wを使って開発時はpixelaへのSVGリクエストをモックして開発時はアクセスが行かないようにした\n\nリクエスト先のURLを出し分けせずにモックできるのは非常に体験が良い\n\n外部のサービスやツールを使っていてsandbox用とかで分けられていない場合などいろんな用途に使えそう\n\n他にも用途いろいろありそうなので使っていこうと思った",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-12-29",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__ms__/ais-highlight__wでSVGをモックする",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "tags": [
              {
                "value": "JavaScript",
                "matchLevel": "none",
                "matchedWords": []
              },
              {
                "value": "TypeScript",
                "matchLevel": "none",
                "matchedWords": []
              },
              { "value": "Gatsby", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "__ais-highlight__ms__/ais-highlight__w",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["ms"]
              }
            ],
            "description": {
              "value": "Pixelaを題材としてモックしてみた",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/__ais-highlight__ms__/ais-highlight__w_mock_svg/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/jest_with_msw/",
          "text": "\n開発用に定義したmswの設定をJestでも使いたい案件\n\n参考のまんまだけどめちゃくちゃ簡単だった\n\nテスト用のファイルに下記のように書くだけ\n\n- search.tsx\n\n```tsx\nimport { handlers } from \"../../mocks/handler\"\ndescribe(\"Search\", () => {\n  const user = userEvent.setup()\n  const server = setupServer(...handlers)\n\n  beforeEach(() => {\n    server.listen()\n  })\n\n  afterEach(() => {\n    server.close()\n  })\n\n  it(\"検索UIのテスト\", async () => {\n    // mswでのモックレスポンスが適用される\n    .....\n    .....\n    .....\n    .....\n  })\n})\n```\n\n- handler.ts\n\n```ts\nimport { rest } from \"msw\"\nimport { setupServer } from \"msw/node\"\n\nexport const handlers = [\n  rest.post(\"https://example.com/*\", (req, res, ctx) => {\n    return res(\n      ctx.status(200),\n      ctx.json({})\n    )\n  }),\n]\n```\n\n`setupServer`で事前定義した`handlers`を読ませ`beforeEach`で各テストの実行前にサーバ起動する\n\n終わったら落とすようにしている\n\nこれだけでよい\n\nとても楽\n\n開発時とテスト時で同じ設定を使えるのもメンテナンス上とてもよい\n\n外部へのリクエストが発生する機能はどんどん活用していくモチベーションが上がった\n\n### 参考\n- [Jest + @testing-library/react + mswのtips - Qiita](https://qiita.com/shibukawa/items/4d431ee4f98c80b682ec)\n",
          "date": "2022-08-19",
          "title": "mswのモックをjestのテストでも使う",
          "tags": ["Jest", "msw", "TypeScript"],
          "description": "開発時と同様",
          "slug": "/entries/jest_with_msw/",
          "timeToRead": 1,
          "objectID": "3cb05eab-dd49-525f-9761-98eaccf45fa7",
          "_snippetResult": {
            "text": {
              "value": "ト\", async () => {\n    // __ais-highlight__ms__/ais-highlight__wでのモックレスポンスが適用される\n    .....\n    .....\n    .....\n    .....\n  })\n})\n```\n\n- handler.ts\n\n```ts\nimport { rest } from \"__ais-highlight__ms__/ais-highlight__w\"\nimport { setupServer } from \"__ais-highlight__ms__/ais-highlight__w/node\"\n\nexport const handlers = [\n  rest.post(\"https://example.com/*\", (req, res, ctx) => {\n    return res(\n      ctx.status(200),\n      ctx.json({})\n    )\n  }),\n]\n```\n\n`setupServer",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/jest_with___ais-highlight__ms__/ais-highlight__w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "text": {
              "value": "\n開発用に定義した__ais-highlight__ms__/ais-highlight__wの設定をJestでも使いたい案件\n\n参考のまんまだけどめちゃくちゃ簡単だった\n\nテスト用のファイルに下記のように書くだけ\n\n- search.tsx\n\n```tsx\nimport { handlers } from \"../../mocks/handler\"\ndescribe(\"Search\", () => {\n  const user = userEvent.setup()\n  const server = setupServer(...handlers)\n\n  beforeEach(() => {\n    server.listen()\n  })\n\n  afterEach(() => {\n    server.close()\n  })\n\n  it(\"検索UIのテスト\", async () => {\n    // __ais-highlight__ms__/ais-highlight__wでのモックレスポンスが適用される\n    .....\n    .....\n    .....\n    .....\n  })\n})\n```\n\n- handler.ts\n\n```ts\nimport { rest } from \"__ais-highlight__ms__/ais-highlight__w\"\nimport { setupServer } from \"__ais-highlight__ms__/ais-highlight__w/node\"\n\nexport const handlers = [\n  rest.post(\"https://example.com/*\", (req, res, ctx) => {\n    return res(\n      ctx.status(200),\n      ctx.json({})\n    )\n  }),\n]\n```\n\n`setupServer`で事前定義した`handlers`を読ませ`beforeEach`で各テストの実行前にサーバ起動する\n\n終わったら落とすようにしている\n\nこれだけでよい\n\nとても楽\n\n開発時とテスト時で同じ設定を使えるのもメンテナンス上とてもよい\n\n外部へのリクエストが発生する機能はどんどん活用していくモチベーションが上がった\n\n### 参考\n- [Jest + @testing-library/react + __ais-highlight__ms__/ais-highlight__wのtips - Qiita](https://qiita.com/shibukawa/items/4d431ee4f98c80b682ec)\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2022-08-19",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "__ais-highlight__ms__/ais-highlight__wのモックをjestのテストでも使う",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "tags": [
              { "value": "Jest", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "__ais-highlight__ms__/ais-highlight__w",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["ms"]
              },
              {
                "value": "TypeScript",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "開発時と同様",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/jest_with___ais-highlight__ms__/ais-highlight__w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/algolia_mock_with_msw/",
          "text": "\nAlgoliaの検索リクエストをmswでモックした\n\n開発時は検索用のAPIキーを登録せずにインデックスへのアクセスもしないようにすれば良くない？\n\n空レスポンスを返すようにしておけば良くない？\n\nみたいな話はあるものの、検索にかかるUI部分を開発するならある程度実際にリクエストした時のレスポンスが欲しくなる\n\nかと言ってAlgoliaに毎度リクエストさせてしまうと無料枠がどんどん減っていく…\n\nということで、mswで解決した\n\n## やっていること\n- 実際のレスポンスデータをdev toolsのNetworkからレスポンス内容を取得してきてJSONに保存\n    - 特定文字列(`BigQuery`)を順次入力した場合のレスポンスを逐次取得\n        - `B`と入力した際のレスポンス\n        - `Bi`と入力した際のレスポンス\n        - `Big`と入力した際のレスポンス\n        - `BigQ`と入力した際のレスポンス\n        - `BigQu`と入力した際のレスポンス\n        - `BigQue`と入力した際のレスポンス\n        - `BigQuer`と入力した際のレスポンス\n        - `BigQuery`と入力した際のレスポンス\n- 先工程で保存したJSONをmswを用いて返すように設定する\n\n「検索文字列の変化によっって返ってくる件数や内容が変わる」というのを再現したかったので固定値ではあるが検索文字列が変化した場合は文字数にあったレスポンスがmsw経由で返るようにした\n\n実際のコードは下記\n\n- handler.ts\n\n```typescript\nimport { rest } from \"msw\"\nimport query0Words from \"./algolia-search-response-0-words.json\"\nimport query1Words from \"./algolia-search-response-1-words.json\"\nimport query2Words from \"./algolia-search-response-2-words.json\"\nimport query3Words from \"./algolia-search-response-3-words.json\"\nimport query4Words from \"./algolia-search-response-4-words.json\"\nimport query5Words from \"./algolia-search-response-5-words.json\"\nimport query6Words from \"./algolia-search-response-6-words.json\"\nimport query7Words from \"./algolia-search-response-7-words.json\"\nimport query8Words from \"./algolia-search-response-8-words.json\"\n\nexport const handlers = [\n  rest.post(\"https://*.algolia.net/1/indexes/*/queries\", (req, res, ctx) => {\n    const empty = query0Words\n\n    const wordCountResponseMap = [\n      empty,       // 空\n      query1Words, // B\n      query2Words, // Bi\n      query3Words, // Big\n      query4Words, // BigQ\n      query5Words, // BigQu\n      query6Words, // BigQue\n      query7Words, // BigQuer\n      query8Words, // BigQuery\n    ]\n\n    const bodyString = req.body as string\n\n    if (bodyString.length === 0) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    const body = JSON.parse(bodyString)\n    const params = [\n      ...new URLSearchParams(body.requests[0].params).entries(),\n    ].reduce((obj, e) => ({ ...obj, [e[0]]: e[1] }), {} as { query: string })\n\n    if (\n      !params.query ||\n      params.query.length === 0 ||\n      params.query.length > wordCountResponseMap.length\n    ) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    return res(\n      ctx.status(200),\n      ctx.json(wordCountResponseMap[params.query.length])\n    )\n  }),\n]\n```\n\n`import`している実際のレスポンスを保存したJSONはAlgoliaでの設定などにより変わるのでここでは割愛する\n\nAlgoliaのレスポンスを完全再現はできないので次のような挙動にしている\n\n<!-- textlint-disable prh -->\n- どの文字列を入力したとしても開発時は`BigQuery`と入力した場合のレスポンスを返す\n- 検索文字列の入力文字数によってモック用のレスポンスを返す\n    - 1文字入力時は`B`が入力された時のモック用レスポンスを返す\n    - 2文字入力時は`Bi`が入力された時のモック用レスポンスを返す\n    - 3文字入力時は`Big`が入力された時のモック用レスポンスを返す\n    - 8文字まで同様\n- 検索文字列が用意している文字列以上入力された場合は何も文字を入力していない場合のレスポンスを返す(`query0Words`)\n<!-- textlint-enable prh -->\n\nこれで検索UIの開発はかなり捗ったのでメモとして残しておく\n",
          "date": "2022-08-12",
          "title": "Algoliaのレスポンスをmswでモックして開発ではダミーレスポンスを扱う",
          "tags": ["Algolia", "msw", "TypeScript"],
          "description": "実際のJSONを用意する",
          "slug": "/entries/algolia_mock_with_msw/",
          "timeToRead": 3,
          "objectID": "c8728ebf-22ac-5299-ba20-c595cab71ff1",
          "_snippetResult": {
            "text": {
              "value": "\nAlgoliaの検索リクエストを__ais-highlight__ms__/ais-highlight__wでモックした\n\n開発時は検索用のAPIキーを登録せずにインデックスへのアクセスもしな",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/algolia_mock_with___ais-highlight__ms__/ais-highlight__w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "text": {
              "value": "\nAlgoliaの検索リクエストを__ais-highlight__ms__/ais-highlight__wでモックした\n\n開発時は検索用のAPIキーを登録せずにインデックスへのアクセスもしないようにすれば良くない？\n\n空レスポンスを返すようにしておけば良くない？\n\nみたいな話はあるものの、検索にかかるUI部分を開発するならある程度実際にリクエストした時のレスポンスが欲しくなる\n\nかと言ってAlgoliaに毎度リクエストさせてしまうと無料枠がどんどん減っていく…\n\nということで、__ais-highlight__ms__/ais-highlight__wで解決した\n\n## やっていること\n- 実際のレスポンスデータをdev toolsのNetworkからレスポンス内容を取得してきてJSONに保存\n    - 特定文字列(`BigQuery`)を順次入力した場合のレスポンスを逐次取得\n        - `B`と入力した際のレスポンス\n        - `Bi`と入力した際のレスポンス\n        - `Big`と入力した際のレスポンス\n        - `BigQ`と入力した際のレスポンス\n        - `BigQu`と入力した際のレスポンス\n        - `BigQue`と入力した際のレスポンス\n        - `BigQuer`と入力した際のレスポンス\n        - `BigQuery`と入力した際のレスポンス\n- 先工程で保存したJSONを__ais-highlight__ms__/ais-highlight__wを用いて返すように設定する\n\n「検索文字列の変化によっって返ってくる件数や内容が変わる」というのを再現したかったので固定値ではあるが検索文字列が変化した場合は文字数にあったレスポンスが__ais-highlight__ms__/ais-highlight__w経由で返るようにした\n\n実際のコードは下記\n\n- handler.ts\n\n```typescript\nimport { rest } from \"__ais-highlight__ms__/ais-highlight__w\"\nimport query0Words from \"./algolia-search-response-0-words.json\"\nimport query1Words from \"./algolia-search-response-1-words.json\"\nimport query2Words from \"./algolia-search-response-2-words.json\"\nimport query3Words from \"./algolia-search-response-3-words.json\"\nimport query4Words from \"./algolia-search-response-4-words.json\"\nimport query5Words from \"./algolia-search-response-5-words.json\"\nimport query6Words from \"./algolia-search-response-6-words.json\"\nimport query7Words from \"./algolia-search-response-7-words.json\"\nimport query8Words from \"./algolia-search-response-8-words.json\"\n\nexport const handlers = [\n  rest.post(\"https://*.algolia.net/1/indexes/*/queries\", (req, res, ctx) => {\n    const empty = query0Words\n\n    const wordCountResponseMap = [\n      empty,       // 空\n      query1Words, // B\n      query2Words, // Bi\n      query3Words, // Big\n      query4Words, // BigQ\n      query5Words, // BigQu\n      query6Words, // BigQue\n      query7Words, // BigQuer\n      query8Words, // BigQuery\n    ]\n\n    const bodyString = req.body as string\n\n    if (bodyString.length === 0) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    const body = JSON.parse(bodyString)\n    const params = [\n      ...new URLSearchParams(body.requests[0].params).entries(),\n    ].reduce((obj, e) => ({ ...obj, [e[0]]: e[1] }), {} as { query: string })\n\n    if (\n      !params.query ||\n      params.query.length === 0 ||\n      params.query.length > wordCountResponseMap.length\n    ) {\n      return res(ctx.status(200), ctx.json(empty))\n    }\n\n    return res(\n      ctx.status(200),\n      ctx.json(wordCountResponseMap[params.query.length])\n    )\n  }),\n]\n```\n\n`import`している実際のレスポンスを保存したJSONはAlgoliaでの設定などにより変わるのでここでは割愛する\n\nAlgoliaのレスポンスを完全再現はできないので次のような挙動にしている\n\n<!-- textlint-disable prh -->\n- どの文字列を入力したとしても開発時は`BigQuery`と入力した場合のレスポンスを返す\n- 検索文字列の入力文字数によってモック用のレスポンスを返す\n    - 1文字入力時は`B`が入力された時のモック用レスポンスを返す\n    - 2文字入力時は`Bi`が入力された時のモック用レスポンスを返す\n    - 3文字入力時は`Big`が入力された時のモック用レスポンスを返す\n    - 8文字まで同様\n- 検索文字列が用意している文字列以上入力された場合は何も文字を入力していない場合のレスポンスを返す(`query0Words`)\n<!-- textlint-enable prh -->\n\nこれで検索UIの開発はかなり捗ったのでメモとして残しておく\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2022-08-12",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Algoliaのレスポンスを__ais-highlight__ms__/ais-highlight__wでモックして開発ではダミーレスポンスを扱う",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "tags": [
              { "value": "Algolia", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "__ais-highlight__ms__/ais-highlight__w",
                "matchLevel": "full",
                "fullyHighlighted": false,
                "matchedWords": ["ms"]
              },
              {
                "value": "TypeScript",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "実際のJSONを用意する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/algolia_mock_with___ais-highlight__ms__/ais-highlight__w/",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "timeToRead": {
              "value": "3",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/ansible_with_python3/",
          "text": "\r\nなんとなくAnsibleの実行環境をPython3にして実行してみたら見事エラーで死亡したのでその際の対応ログ\r\n\r\n```\r\nfatal: [localhost]: FAILED! => {\"msg\": \"The conditional check 'ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"' failed. The error was: error while evaluating conditional (ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"): 'dict object' has no attribute 'has_key'\\n\\nThe error appears to be in '/usr/local/src/ansible/roles/common/tasks/redhat.yml': line 63, column 3, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n\\n- name: disable SELinux\\n  ^ here\\n\"}\r\n```\r\n\r\nhas_keyがない\r\n\r\nということで\r\n\r\nPython3での実行に対応するには\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ 'CI' in ansible_env\r\n```\r\n\r\nもしくは\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ ansible_env.get('CI', None)\r\n```\r\n\r\nの対応が必要\r\n\r\n",
          "date": "2020-06-24",
          "title": "Python3でAnsibleを実行する際のエラー対応",
          "tags": ["Ansible", "Python"],
          "description": "has_key",
          "slug": "/entries/ansible_with_python3/",
          "timeToRead": 1,
          "objectID": "6014c47b-213e-502d-a64d-ce386474aedf",
          "_snippetResult": {
            "text": {
              "value": "\r\nなんとなくAnsibleの実行環境をPython3にして実行してみたら見事エラーで死亡したのでその際の対応ログ\r\n\r\n```\r\nfatal: [localhost]: FAILED! => {\"__ais-highlight__ms__/ais-highlight__g\": \"The conditional",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/ansible_with_python3/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\r\nなんとなくAnsibleの実行環境をPython3にして実行してみたら見事エラーで死亡したのでその際の対応ログ\r\n\r\n```\r\nfatal: [localhost]: FAILED! => {\"__ais-highlight__ms__/ais-highlight__g\": \"The conditional check 'ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"' failed. The error was: error while evaluating conditional (ansible_env.has_key('CI') and ansible_env.CI != \\\"true\\\"): 'dict object' has no attribute 'has_key'\\n\\nThe error appears to be in '/usr/local/src/ansible/roles/common/tasks/redhat.yml': line 63, column 3, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n\\n- name: disable SELinux\\n  ^ here\\n\"}\r\n```\r\n\r\nhas_keyがない\r\n\r\nということで\r\n\r\nPython3での実行に対応するには\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ 'CI' in ansible_env\r\n```\r\n\r\nもしくは\r\n\r\n```diff\r\n- ansible_env.has_key('CI')\r\n+ ansible_env.get('CI', None)\r\n```\r\n\r\nの対応が必要\r\n\r\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2020-06-24",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Python3でAnsibleを実行する際のエラー対応",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Ansible", "matchLevel": "none", "matchedWords": [] },
              { "value": "Python", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "has_key",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/ansible_with_python3/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/docker_compose_dns/",
          "text": "\n新しい開発環境ではAnsibleでローカル環境を作るようにしているが次のようにansibleの`get_url`実行に失敗してしまっていた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"Failed to connect to objects.githubusercontent.com at port 443: [Errno -5] No address associated with hostname\"}\n```\n\n名前解決ができていないという状態のようだったのでDNSサーバを指定してあげれば良い\n\n- docker-compose.yml\n\n```yaml\nversion: \"3\"\nservices:\n  app:\n    build:\n      context: ./ansible\n    dns:\n      - 8.8.8.8\n```\n\n上記のように`dns`を指定することで解決した\n\n",
          "date": "2022-01-10",
          "title": "Docker環境でAnsibleのget_url実行が失敗する",
          "tags": ["Docker", "docker-compose"],
          "description": "docker-composeでDNSの指定",
          "slug": "/entries/docker_compose_dns/",
          "timeToRead": 1,
          "objectID": "ce38bab6-5daa-5658-8137-b6c2ec1c60c5",
          "_snippetResult": {
            "text": {
              "value": "ようにansibleの`get_url`実行に失敗してしまっていた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"__ais-highlight__ms__/ais-highlight__g\": \"Failed to connect to objects.githubusercontent.com at port 443: [Errno -5] No address associated with hostname\"}\n```\n\n名前解決ができ",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/docker_compose_dns/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n新しい開発環境ではAnsibleでローカル環境を作るようにしているが次のようにansibleの`get_url`実行に失敗してしまっていた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"__ais-highlight__ms__/ais-highlight__g\": \"Failed to connect to objects.githubusercontent.com at port 443: [Errno -5] No address associated with hostname\"}\n```\n\n名前解決ができていないという状態のようだったのでDNSサーバを指定してあげれば良い\n\n- docker-compose.yml\n\n```yaml\nversion: \"3\"\nservices:\n  app:\n    build:\n      context: ./ansible\n    dns:\n      - 8.8.8.8\n```\n\n上記のように`dns`を指定することで解決した\n\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2022-01-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Docker環境でAnsibleのget_url実行が失敗する",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Docker", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "docker-compose",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "docker-composeでDNSの指定",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/docker_compose_dns/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/require_ca_certificate_in_ansible_centos7/",
          "text": "\nCentOS7のイメージ中でAnsibleを使って`get_url`でGitをソースからインストールしている処理があったがそこで問題が発生していた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"dest\": \"/tmp/git-2.33.0.tar.gz\", \"elapsed\": 0, \"msg\": \"Request failed: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)>\", \"url\": \"https://www.kernel.org/pub/software/scm/git/git-2.33.0.tar.gz\"}\n```\n\n証明書関連かーというのはすぐ分かるが、じゃどうすれば良いのってことで\n\nAnsibleだとrequestsかcertificateモジュールを更新すればよいのかと思って更新してみたものの解決されず\n\n証明書リストを追加すればOK?みたいな感じで探していたら次の記事に助けられた\n\n[Let's EncryptのルートCA期限切れで OpenSSL 1.0.2が思わぬ事故を起こす件 | ワルブリックス株式会社](https://www.walbrix.co.jp/article/openssl-102-letsencrypt-crisis.html)\n\n`www.kernel.org`を見に行ったらLet's Encryptと`ISRG Root X1`の組み合わせだった\n\n最新のOSバージョンでは解決しているとのことだったので今一度更新してから試そうとしてみた\n\ndockerでイメージビルドするときは最新を指定してたはずなのでどうかなと思ったもののいったん`yum update`で更新して試してみた\n\n```\n$ yum update\n===============================================================================================================================================================================\n Package                                       Arch                              Version                                              Repository                          Size\n===============================================================================================================================================================================\nUpdating:\n bind-license                                  noarch                            32:9.11.4-26.P2.el7_9.7                              updates                             91 k\n ca-certificates                               noarch                            2021.2.50-72.el7_9                                   updates                            379 k\n centos-release                                x86_64                            7-9.2009.1.el7.centos                                updates                             27 k\n coreutils                                     x86_64                            8.22-24.el7_9.2                                      updates                            3.3 M\n device-mapper                                 x86_64                            7:1.02.170-6.el7_9.5                                 updates                            297 k\n device-mapper-libs                            x86_64                            7:1.02.170-6.el7_9.5                                 updates                            325 k\n epel-release                                  noarch                            7-14                                                 epel                                15 k\n glib2                                         x86_64                            2.56.1-9.el7_9                                       updates                            2.5 M\n glibc                                         x86_64                            2.17-325.el7_9                                       updates                            3.6 M\n glibc-common                                  x86_64                            2.17-325.el7_9                                       updates                             12 M\n glibc-devel                                   x86_64                            2.17-325.el7_9                                       updates                            1.1 M\n glibc-headers                                 x86_64                            2.17-325.el7_9                                       updates                            691 k\n kernel-headers                                x86_64                            3.10.0-1160.45.1.el7                                 updates                            9.0 M\n kpartx                                        x86_64                            0.4.9-135.el7_9                                      updates                             81 k\n libblkid                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            183 k\n libmount                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            185 k\n libsmartcols                                  x86_64                            2.23.2-65.el7_9.1                                    updates                            143 k\n libuuid                                       x86_64                            2.23.2-65.el7_9.1                                    updates                             84 k\n nspr                                          x86_64                            4.32.0-1.el7_9                                       updates                            127 k\n nss                                           x86_64                            3.67.0-3.el7_9                                       updates                            882 k\n nss-softokn                                   x86_64                            3.67.0-3.el7_9                                       updates                            358 k\n nss-softokn-freebl                            x86_64                            3.67.0-3.el7_9                                       updates                            337 k\n nss-sysinit                                   x86_64                            3.67.0-3.el7_9                                       updates                             66 k\n nss-tools                                     x86_64                            3.67.0-3.el7_9                                       updates                            549 k\n nss-util                                      x86_64                            3.67.0-1.el7_9                                       updates                             79 k\n openldap                                      x86_64                            2.4.44-24.el7_9                                      updates                            356 k\n python                                        x86_64                            2.7.5-90.el7                                         updates                             96 k\n python-libs                                   x86_64                            2.7.5-90.el7                                         updates                            5.6 M\n rpm                                           x86_64                            4.11.3-46.el7_9                                      updates                            1.2 M\n rpm-build-libs                                x86_64                            4.11.3-46.el7_9                                      updates                            108 k\n rpm-libs                                      x86_64                            4.11.3-46.el7_9                                      updates                            279 k\n rpm-python                                    x86_64                            4.11.3-46.el7_9                                      updates                             84 k\n sudo                                          x86_64                            1.8.23-10.el7_9.2                                    updates                            843 k\n systemd                                       x86_64                            219-78.el7_9.3                                       updates                            5.1 M\n systemd-libs                                  x86_64                            219-78.el7_9.3                                       updates                            418 k\n tzdata                                        noarch                            2021c-1.el7                                          updates                            502 k\n util-linux                                    x86_64                            2.23.2-65.el7_9.1                                    updates                            2.0 M\n vim-minimal                                   x86_64                            2:7.4.629-8.el7_9                                    updates                            443 k\n\nTransaction Summary\n===============================================================================================================================================================================\nUpgrade  38 Packages\n```\n\nこのあとでのansible実行は問題なく実行できた\n\nということでこの中のどれかのパッケージを更新すれば問題なさそうという感じ\n\n`ca-certificates`かな?CA証明書のリスト\n\nということで`ca-certificates`のみlatestにするようなAnsibleを書いて再実行したところ無事成功した\n\n※参考の記事中にもよく読んだら`ca-certificate`パッケージを上げると書いてあった\n\nパッケージすべてlatestだと勝手に更新されて失敗してしまったりしたら困るよねっていう認識だったが逆にlatestのほうが良いものもあるんだなというのが今回の気付きでした\n\n最近ちょいちょいこのパータンにはまっている気がするので残しておく",
          "date": "2021-11-10",
          "title": "CentOS7でAnsible実行時にCERTIFICATE_VERIFY_FAILED",
          "tags": ["Ansible", "CentOS7", "Python"],
          "description": "ca-certificateを更新",
          "slug": "/entries/require_ca_certificate_in_ansible_centos7/",
          "timeToRead": 4,
          "objectID": "a5491716-3045-589f-b0d9-63fd56de439c",
          "_snippetResult": {
            "text": {
              "value": "で問題が発生していた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"dest\": \"/tmp/git-2.33.0.tar.gz\", \"elapsed\": 0, \"__ais-highlight__ms__/ais-highlight__g\": \"Request failed: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)>\", \"url\": \"https://www.kernel.org/pub/software/scm/git/git",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/require_ca_certificate_in_ansible_centos7/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\nCentOS7のイメージ中でAnsibleを使って`get_url`でGitをソースからインストールしている処理があったがそこで問題が発生していた\n\n```\nfatal: [localhost]: FAILED! => {\"changed\": false, \"dest\": \"/tmp/git-2.33.0.tar.gz\", \"elapsed\": 0, \"__ais-highlight__ms__/ais-highlight__g\": \"Request failed: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)>\", \"url\": \"https://www.kernel.org/pub/software/scm/git/git-2.33.0.tar.gz\"}\n```\n\n証明書関連かーというのはすぐ分かるが、じゃどうすれば良いのってことで\n\nAnsibleだとrequestsかcertificateモジュールを更新すればよいのかと思って更新してみたものの解決されず\n\n証明書リストを追加すればOK?みたいな感じで探していたら次の記事に助けられた\n\n[Let's EncryptのルートCA期限切れで OpenSSL 1.0.2が思わぬ事故を起こす件 | ワルブリックス株式会社](https://www.walbrix.co.jp/article/openssl-102-letsencrypt-crisis.html)\n\n`www.kernel.org`を見に行ったらLet's Encryptと`ISRG Root X1`の組み合わせだった\n\n最新のOSバージョンでは解決しているとのことだったので今一度更新してから試そうとしてみた\n\ndockerでイメージビルドするときは最新を指定してたはずなのでどうかなと思ったもののいったん`yum update`で更新して試してみた\n\n```\n$ yum update\n===============================================================================================================================================================================\n Package                                       Arch                              Version                                              Repository                          Size\n===============================================================================================================================================================================\nUpdating:\n bind-license                                  noarch                            32:9.11.4-26.P2.el7_9.7                              updates                             91 k\n ca-certificates                               noarch                            2021.2.50-72.el7_9                                   updates                            379 k\n centos-release                                x86_64                            7-9.2009.1.el7.centos                                updates                             27 k\n coreutils                                     x86_64                            8.22-24.el7_9.2                                      updates                            3.3 M\n device-mapper                                 x86_64                            7:1.02.170-6.el7_9.5                                 updates                            297 k\n device-mapper-libs                            x86_64                            7:1.02.170-6.el7_9.5                                 updates                            325 k\n epel-release                                  noarch                            7-14                                                 epel                                15 k\n glib2                                         x86_64                            2.56.1-9.el7_9                                       updates                            2.5 M\n glibc                                         x86_64                            2.17-325.el7_9                                       updates                            3.6 M\n glibc-common                                  x86_64                            2.17-325.el7_9                                       updates                             12 M\n glibc-devel                                   x86_64                            2.17-325.el7_9                                       updates                            1.1 M\n glibc-headers                                 x86_64                            2.17-325.el7_9                                       updates                            691 k\n kernel-headers                                x86_64                            3.10.0-1160.45.1.el7                                 updates                            9.0 M\n kpartx                                        x86_64                            0.4.9-135.el7_9                                      updates                             81 k\n libblkid                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            183 k\n libmount                                      x86_64                            2.23.2-65.el7_9.1                                    updates                            185 k\n libsmartcols                                  x86_64                            2.23.2-65.el7_9.1                                    updates                            143 k\n libuuid                                       x86_64                            2.23.2-65.el7_9.1                                    updates                             84 k\n nspr                                          x86_64                            4.32.0-1.el7_9                                       updates                            127 k\n nss                                           x86_64                            3.67.0-3.el7_9                                       updates                            882 k\n nss-softokn                                   x86_64                            3.67.0-3.el7_9                                       updates                            358 k\n nss-softokn-freebl                            x86_64                            3.67.0-3.el7_9                                       updates                            337 k\n nss-sysinit                                   x86_64                            3.67.0-3.el7_9                                       updates                             66 k\n nss-tools                                     x86_64                            3.67.0-3.el7_9                                       updates                            549 k\n nss-util                                      x86_64                            3.67.0-1.el7_9                                       updates                             79 k\n openldap                                      x86_64                            2.4.44-24.el7_9                                      updates                            356 k\n python                                        x86_64                            2.7.5-90.el7                                         updates                             96 k\n python-libs                                   x86_64                            2.7.5-90.el7                                         updates                            5.6 M\n rpm                                           x86_64                            4.11.3-46.el7_9                                      updates                            1.2 M\n rpm-build-libs                                x86_64                            4.11.3-46.el7_9                                      updates                            108 k\n rpm-libs                                      x86_64                            4.11.3-46.el7_9                                      updates                            279 k\n rpm-python                                    x86_64                            4.11.3-46.el7_9                                      updates                             84 k\n sudo                                          x86_64                            1.8.23-10.el7_9.2                                    updates                            843 k\n systemd                                       x86_64                            219-78.el7_9.3                                       updates                            5.1 M\n systemd-libs                                  x86_64                            219-78.el7_9.3                                       updates                            418 k\n tzdata                                        noarch                            2021c-1.el7                                          updates                            502 k\n util-linux                                    x86_64                            2.23.2-65.el7_9.1                                    updates                            2.0 M\n vim-minimal                                   x86_64                            2:7.4.629-8.el7_9                                    updates                            443 k\n\nTransaction Summary\n===============================================================================================================================================================================\nUpgrade  38 Packages\n```\n\nこのあとでのansible実行は問題なく実行できた\n\nということでこの中のどれかのパッケージを更新すれば問題なさそうという感じ\n\n`ca-certificates`かな?CA証明書のリスト\n\nということで`ca-certificates`のみlatestにするようなAnsibleを書いて再実行したところ無事成功した\n\n※参考の記事中にもよく読んだら`ca-certificate`パッケージを上げると書いてあった\n\nパッケージすべてlatestだと勝手に更新されて失敗してしまったりしたら困るよねっていう認識だったが逆にlatestのほうが良いものもあるんだなというのが今回の気付きでした\n\n最近ちょいちょいこのパータンにはまっている気がするので残しておく",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-11-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "CentOS7でAnsible実行時にCERTIFICATE_VERIFY_FAILED",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Ansible", "matchLevel": "none", "matchedWords": [] },
              { "value": "CentOS7", "matchLevel": "none", "matchedWords": [] },
              { "value": "Python", "matchLevel": "none", "matchedWords": [] }
            ],
            "description": {
              "value": "ca-certificateを更新",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/require_ca_certificate_in_ansible_centos7/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "4",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/toc_bookmarklet/",
          "text": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (msg) => { console.log(msg) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + body + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(msg)%20=>%20{%20console.log(msg)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(body)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
          "date": "2021-06-10",
          "title": "TOCを抽出するためのブックマークレット",
          "tags": ["Bookmarklet"],
          "description": "TOC",
          "slug": "/entries/toc_bookmarklet/",
          "timeToRead": 1,
          "objectID": "49593c1a-0da8-5fdf-ad6b-84aa473c7dbf",
          "_snippetResult": {
            "text": {
              "value": "ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (__ais-highlight__ms__/ais-highlight__g) => { console.log(__ais-highlight__ms__/ais-highlight__g) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC' + body + '');\n    d.close();\n  };\n\n  const toc = Array",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/toc_bookmarklet/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n他の記事はどのような構成なんだろう？\n\n記事書くときにどのような流れが良いのかなー？\n\nと考えることがあったのでTOCを収集して傾向などを見つけてみようと思ったので掲題のブックマークレットを書いた\n\n- toc.js\n\n```javascript\n(() => {\n  const log = (__ais-highlight__ms__/ais-highlight__g) => { console.log(__ais-highlight__ms__/ais-highlight__g) };\n  log('start extract toc');\n\n  const o = (body) => {\n    const d = window.open().document;\n    d.writeln('TOC<br /><textarea cols=\"100\" rows=\"30\">' + body + '</textarea>');\n    d.close();\n  };\n\n  const toc = Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e => {\n    const n = e.tagName.replace(\"H\",\"\");\n    return `${\"#\".repeat(n)} ${e.textContent}`;\n  }).join(\"\\n\");\n  log(toc);\n  o(toc);\n})();\n```\n\nブックマークに登録するときは次のように1行にしてスペースはエスケープする\n\n```javascript\njavascript:(()%20=>%20{%20const%20log%20=%20(__ais-highlight__ms__/ais-highlight__g)%20=>%20{%20console.log(__ais-highlight__ms__/ais-highlight__g)%20};%20log('start%20extract%20toc');%20const%20o%20=%20(body)%20=>%20{%20const%20d%20=%20window.open().document;%20d.writeln('TOC<br%20/><textarea%20cols=\"100\"%20rows=\"30\">'%20+%20body%20+%20'</textarea>');%20d.close();%20};%20const%20toc%20=%20Array.from(document.querySelectorAll('h1,h2,h3,h4')).map(e%20=>%20{%20const%20n%20=%20e.tagName.replace(\"H\",\"\");%20return%20`${\"#\".repeat(n)}%20${e.textContent}`;%20}).join(\"\\n\");%20log(toc);%20o(toc);%20})();\n```\n\nこんな感じの出力が得られる\n\n```\n## WSL側\n## Xlaunch\n## WSL側\n### 参考：\n```\n\nなお、対象ページでタイトル以外にも`h2`などを付けているとその情報も入ってきてしまう\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-06-10",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "TOCを抽出するためのブックマークレット",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              {
                "value": "Bookmarklet",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "TOC",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/toc_bookmarklet/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "1",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        },
        {
          "url": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
          "text": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 ms)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 ms)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
          "date": "2021-07-19",
          "title": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
          "tags": ["Jest", "Gatsby", "TestingLibrary"],
          "description": "jsdom使う",
          "slug": "/entries/introduction_jest_and_testing_library_to_gatsby/",
          "timeToRead": 2,
          "objectID": "6fca825c-1e53-5398-b057-6f44e9a29349",
          "_snippetResult": {
            "text": {
              "value": "拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 __ais-highlight__ms__/ais-highlight__)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string",
              "matchLevel": "full"
            }
          },
          "_highlightResult": {
            "url": {
              "value": "https://til.swfz.io//entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "text": {
              "value": "\n基本的には下記を見ながら進めることで問題なかった\n\n[Unit Testing | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/unit-testing/)\n\n[Testing React Components | Gatsby](https://www.gatsbyjs.com/docs/how-to/testing/testing-react-components/)\n\n進めていたら途中で詰まった\n\n- src/components/__tests__/header.ts\n\n```typescript\nimport React from \"react\"\nimport {render, screen} from \"@testing-library/react\"\nimport '@testing-library/jest-dom/extend-expect'\n\nconst Title = () => <h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>;\n\ndescribe(\"Bio\", () => {\n  it(\"renders correctly\", () => {\n    const { getByTestId } = render(<Title />);\n    expect(getByTestId(\"hero-title\")).toHaveTextContent(\"Gatsby is awesome!\");\n  })\n})\n```\n\n```\n❯ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n FAIL  src/components/__tests__/header.ts\n  ● Test suite failed to run\n\n    SyntaxError: /home/user/til/src/components/__tests__/header.ts: Unexpected token, expected \",\" (7:25)\n\n       6 |\n    >  7 | const Title = () => (<h1 data-testid=\"hero-title\">Gatsby is awesome!</h1>);\n         |                          ^\n       8 |\n       9 | describe(\"Bio\", () => {\n```\n\nタグの解釈がうまく行かない？\n\nTypeScript関連のようだがよくわからんということでうだうだ調べていた\n\nよく考えれば分かることだがTypeScriptなのにReactの記法が書いてあるのでそりゃそうなるよねって感じだった\n\n拡張子を`ts` -> `tsx`にして次に進めた\n\n```\n FAIL  src/components/__tests__/header.tsx\n  Bio\n    ✕ renders correctly (2 __ais-highlight__ms__/ais-highlight__)\n\n  ● Bio › renders correctly\n                                                                                                                                                                                                    The error below may be caused by using the wrong test environment, see https://jestjs.io/docs/configuration#testenvironment-string.\n    Consider using the \"jsdom\" test environment.\n```\n\nデフォルトのテスト環境が`node`である\n\nレンダリングなどをするテストの場合は`jsdom`環境に変更してあげる必要がある\n\n変更はテストファイルの先頭にコメントを入れることで可能\n\n[Jestの設定 · Jest](https://jestjs.io/ja/docs/configuration#testenvironment-string)\n\n全体に適用する場合は `jest.config.js`に項目を追加する\n\n- jest.config.js\n\n```javascript\nmodule.exports = {\n  .....\n  .....\n  .....\n  testEnvironment: 'jsdom',\n}\n```\n\n\n```\n$ yarn test\nyarn run v1.22.10\n$ jest --config ./jest.config.js\n PASS  src/components/__tests__/header.tsx\n  Bio\n    ✓ renders correctly (23 __ais-highlight__ms__/ais-highlight__)\n\nTest Suites: 1 passed, 1 total\nTests:       1 passed, 1 total\nSnapshots:   0 total\nTime:        1.013 s, estimated 2 s\nRan all test suites.\nDone in 2.31s.\n```\n\nこれで動くところまで持っていけたのでテスト書くぞ\n",
              "matchLevel": "full",
              "fullyHighlighted": false,
              "matchedWords": ["ms"]
            },
            "date": {
              "value": "2021-07-19",
              "matchLevel": "none",
              "matchedWords": []
            },
            "title": {
              "value": "Gatsbyのブログにjestとreact-testing-libraryを入れてテスト可能にする",
              "matchLevel": "none",
              "matchedWords": []
            },
            "tags": [
              { "value": "Jest", "matchLevel": "none", "matchedWords": [] },
              { "value": "Gatsby", "matchLevel": "none", "matchedWords": [] },
              {
                "value": "TestingLibrary",
                "matchLevel": "none",
                "matchedWords": []
              }
            ],
            "description": {
              "value": "jsdom使う",
              "matchLevel": "none",
              "matchedWords": []
            },
            "slug": {
              "value": "/entries/introduction_jest_and_testing_library_to_gatsby/",
              "matchLevel": "none",
              "matchedWords": []
            },
            "timeToRead": {
              "value": "2",
              "matchLevel": "none",
              "matchedWords": []
            }
          }
        }
      ],
      "nbHits": 8,
      "page": 0,
      "nbPages": 1,
      "hitsPerPage": 20,
      "exhaustiveNbHits": true,
      "exhaustiveTypo": true,
      "exhaustive": { "nbHits": true, "typo": true },
      "query": "ms",
      "params": "facets=%5B%5D&highlightPostTag=__%2Fais-highlight__&highlightPreTag=__ais-highlight__&page=0&query=ms&tagFilters=",
      "index": "til",
      "renderingContent": {},
      "processingTimeMS": 4,
      "processingTimingsMS": {
        "afterFetch": {
          "format": { "highlighting": 1, "snippeting": 2, "total": 4 },
          "total": 4
        },
        "total": 4
      }
    }
  ]
}
